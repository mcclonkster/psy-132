# 10_learning


---
## Why It Matters: Learning | Introduction to Psychology

- url_title:: "Why It Matters: Learning | Introduction to Psychology"
  url_source:: https://courses.lumenlearning.com/waymaker-psychology/chapter/introduction-11/
![A photograph shows a baby turtle moving across sand toward the ocean. A photograph shows a young child standing on a surfboard in a small wave.](https://s3-us-west-2.amazonaws.com/courses-images-archive-read-only/wp-content/uploads/sites/902/2015/02/23224750/CNX_Psych_06_00_Turtles.jpg)

**Figure 1**. Loggerhead sea turtle hatchlings are born knowing how to find the ocean and how to swim. Unlike the sea turtle, humans must learn how to swim (and surf). (credit “turtle”: modification of work by Becky Skiba, USFWS; credit “surfer”: modification of work by Mike Baird)

The summer sun shines brightly on a deserted stretch of beach. Suddenly, a tiny grey head emerges from the sand, then another and another. Soon the beach is teeming with loggerhead sea turtle hatchlings (Figure 1). Although only minutes old, the hatchlings know exactly what to do. Their flippers are not very efficient for moving across the hot sand, yet they continue onward, instinctively. Some are quickly snapped up by gulls circling overhead and others become lunch for hungry ghost crabs that dart out of their holes. Despite these dangers, the hatchlings are driven to leave the safety of their nest and find the ocean.

Not far down this same beach, Ben and his son, Julian, paddle out into the ocean on surfboards. A wave approaches. Julian crouches on his board, then jumps up and rides the wave for a few seconds before losing his balance. He emerges from the water in time to watch his father ride the face of the wave.

Unlike baby sea turtles, which know how to find the ocean and swim with no help from their parents, we are not born knowing how to swim (or surf). Yet we humans pride ourselves on our ability to learn. In fact, over thousands of years and across cultures, we have created institutions devoted entirely to learning. But have you ever asked yourself how exactly it is that we learn? What processes are at work as we come to know what we know? This module focuses on the primary ways in which learning occurs.

Module References

### Candela Citations

---

## Introduction to Classical Conditioning | Introduction to Psychology

- url_title:: "Introduction to Classical Conditioning | Introduction to Psychology"
  url_source:: https://courses.lumenlearning.com/waymaker-psychology/chapter/outcome-classical-conditioning/
## What you’ll learn to do: explain learning and the process of classical conditioning

[![decorative image](https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2017/04/11014319/dog-580466_1920.jpg)](https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2017/04/11014319/dog-580466_1920.jpg)

In this section, you’ll learn about learning. It might not be “learning” as you typically think of the word, because we’re not talking about going to school, or studying, or even effortfully trying to remember something. Instead, you’ll see that one of the main types of behavioral learning that we do is simply through an automatic process of association, known as classical conditioning. In classical conditioning, organisms learn to associate events that repeatedly happen together, and researchers study how a reflexive response to a stimulus can be mapped to a different stimulus—by training an association between the two stimuli. Ivan Pavlov’s experiments show how stimulus-response bonds are formed. Watson, the founder of behaviorism, was greatly influenced by Pavlov’s work. He tested humans by conditioning fear in an infant known as Little Albert. His findings suggest that classical conditioning can explain how some fears develop.

### Learning Objectives

-   Recognize and define three basic forms of learning—classical conditioning, operant conditioning, and observational learning
-   Explain how classical conditioning occurs
-   Identify the NS, UCS, UCR, CS, and CR in classical conditioning situations
-   Describe the processes of acquisition, extinction, spontaneous recovery, generalization, and discrimination

### Candela Citations

---

## Introduction to Operant Conditioning | Introduction to Psychology

- url_title:: "Introduction to Operant Conditioning | Introduction to Psychology"
  url_source:: https://courses.lumenlearning.com/waymaker-psychology/chapter/outcome-operant-conditioning/
## What you’ll learn to do: explain operant conditioning, reinforcement, and punishment

You’ve already learned about classical conditioning, or conditioning by association. This section will focus on operant conditioning, which emphasizes reinforcement for behaviors. In operant conditioning, the motivation for a behavior happens _after_ the behavior is demonstrated. An animal or a human receives a consequence (reinforcer or punisher) after performing a specific behavior. You’ll learn that all types of reinforcement (positive or negative) _increase_ the likelihood of a behavioral response, while all types of punishment _decrease_ the likelihood of a behavioral response.

### Watch IT

Watch this video for a review of classical conditioning and an introduction of operant conditioning to help you differentiate between the two types of learning.

You can [view the transcript for “The difference between classical and operant conditioning – Peggy Andover” here (opens in new window)](https://oerfiles.s3-us-west-2.amazonaws.com/Psychology/Transcriptions/TheDifferenceBetweenClassicalAndOperantConditioningPeggyAndover.txt).

### Learning Objectives

-   Define and give examples of operant conditioning
-   Explain the difference between reinforcement and punishment (including positive and negative reinforcement and positive and negative punishment)
-   Define shaping
-   Differentiate between primary and secondary reinforcers
-   Distinguish between reinforcement schedules

### Candela Citations

CC licensed content, Original

-   **Provided by**: Lumen Learning. **License**: _[CC BY: Attribution](https://creativecommons.org/licenses/by/4.0/)_

All rights reserved content

-   The difference between classical and operant conditioning . **Authored by**: Peggy Andover. **Provided by**: TedED. **Located at**: [https://www.youtube.com/watch?v=H6LEcM0E0io](https://www.youtube.com/watch?v=H6LEcM0E0io). **License**: _Other_. **License Terms**: Standard YouTube License

---

## Introduction to Other Types of Learning

- url_title:: "Introduction to Other Types of Learning"
  url_source:: https://courses.lumenlearning.com/waymaker-psychology/chapter/outcome-other-types-of-learning/
## What you’ll learn to do: describe latent learning and observational learning

[![decorative image](https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2017/03/06215233/Traquair_House_Maze.jpg)](https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2017/03/06215233/Traquair_House_Maze.jpg)

Classical and operant conditioning are responsible for a good bit of the behaviors we learn and develop, but certainly there are other things we learn simply through observation and thought. Latent learning is a form of learning that occurs without any obvious reinforcement of the behavior or associations that are learned.

According to Albert Bandura, learning can occur by watching others and then modeling what they do or say. This is known as observational learning. There are specific steps in the process of modeling that must be followed if learning is to be successful. These steps include attention, retention, reproduction, and motivation. Through modeling, Bandura has shown that children learn many things both good and bad simply by watching their parents, siblings, and others. What have you learned by observation?

### Learning Objectives

-   Explain latent learning and cognitive maps
-   Describe Edward Tolman’s experiment on latent learning
-   Explain observational learning and the steps in the modeling process
-   Describe the process and results of Albert Bandura’s bobo doll experiment

### Candela Citations

CC licensed content, Original

-   Observational Learning. **Authored by**: OpenStax College. **Located at**: [https://openstax.org/books/psychology-2e/pages/6-4-observational-learning-modeling](https://openstax.org/books/psychology-2e/pages/6-4-observational-learning-modeling). **License**: _[CC BY: Attribution](https://creativecommons.org/licenses/by/4.0/)_. **License Terms**: Download for free at https://openstax.org/books/psychology-2e/pages/1-introduction

CC licensed content, Shared previously

-   Traquair House Maze. **Authored by**: marsroverdriver. **Located at**: [https://en.wikipedia.org/wiki/File:Traquair\_House\_Maze.jpg](https://en.wikipedia.org/wiki/File:Traquair_House_Maze.jpg). **License**: _[CC BY: Attribution](https://creativecommons.org/licenses/by/4.0/)_
-   Latent Learning. **Provided by**: Boundless. **Located at**: [https://www.boundless.com/psychology/textbooks/boundless-psychology-textbook/learning-7/cognitive-approaches-to-learning-48/latent-learning-202-12737/](https://www.boundless.com/psychology/textbooks/boundless-psychology-textbook/learning-7/cognitive-approaches-to-learning-48/latent-learning-202-12737/). **Project**: Boundless Psychology. **License**: _[CC BY-SA: Attribution-ShareAlike](https://creativecommons.org/licenses/by-sa/4.0/)_

---

## What Is Learning? | Introduction to Psychology

- url_title:: "What Is Learning? | Introduction to Psychology"
  url_source:: https://courses.lumenlearning.com/waymaker-psychology/chapter/what-is-learning/
### Learning Objectives

-   Recognize and define three basic forms of learning—classical conditioning, operant conditioning, and observational learning

Birds build nests and migrate as winter approaches. Infants suckle at their mother’s breast. Dogs shake water off wet fur. Salmon swim upstream to spawn, and spiders spin intricate webs. What do these seemingly unrelated behaviors have in common? They all are _unlearned_ behaviors. Both instincts and reflexes are innate (unlearned) behaviors that organisms are born with. **Reflexes** are a motor or neural reaction to a specific stimulus in the environment. They tend to be simpler than instincts, involve the activity of specific body parts and systems (e.g., the knee-jerk reflex and the contraction of the pupil in bright light), and involve more primitive centers of the central nervous system (e.g., the spinal cord and the medulla). In contrast, **instincts** are innate behaviors that are triggered by a broader range of events, such as maturation and the change of seasons. They are more complex patterns of behavior, involve movement of the organism as a whole (e.g., sexual activity and migration), and involve higher brain centers.

Both reflexes and instincts help an organism adapt to its environment and do not have to be learned. For example, every healthy human baby has a sucking reflex, present at birth. Babies are born knowing how to suck on a nipple, whether artificial (from a bottle) or human. Nobody teaches the baby to suck, just as no one teaches a sea turtle hatchling to move toward the ocean.

Learning, like reflexes and instincts, allows an organism to adapt to its environment. But unlike instincts and reflexes, learned behaviors involve change and experience: learning is a relatively permanent change in behavior or knowledge that results from experience. In contrast to the innate behaviors discussed above, **learning** involves acquiring knowledge and skills through experience. Looking back at our surfing scenario, Julian will have to spend much more time training with his surfboard before he learns how to ride the waves like his father.

Learning to surf, as well as any complex learning process (e.g., learning about the discipline of psychology), involves a complex interaction of conscious and unconscious processes. Learning has traditionally been studied in terms of its simplest components—the associations our minds automatically make between events. Our minds have a natural tendency to connect events that occur closely together or in sequence. **Associative learning** occurs when an organism makes connections between stimuli or events that occur together in the environment. You will see that associative learning is central to all three basic learning processes discussed in this module; classical conditioning tends to involve unconscious processes, operant conditioning tends to involve conscious processes, and observational learning adds social and cognitive layers to all the basic associative processes, both conscious and unconscious. These learning processes will be discussed in detail later, but it is helpful to have a brief overview of each as you begin to explore how learning is understood from a psychological perspective.

In classical conditioning, also known as Pavlovian conditioning, organisms learn to associate events—or stimuli—that repeatedly happen together. We experience this process throughout our daily lives. For example, you might see a flash of lightning in the sky during a storm and then hear a loud boom of thunder. The sound of the thunder naturally makes you jump (loud noises have that effect by reflex). Because lightning reliably predicts the impending boom of thunder, you may associate the two and jump when you see lightning. Psychological researchers study this associative process by focusing on what can be seen and measured—behaviors. Researchers ask if one stimulus triggers a reflex, can we train a different stimulus to trigger that same reflex? In operant conditioning, organisms learn, again, to associate events—a behavior and its consequence (reinforcement or punishment). A pleasant consequence encourages more of that behavior in the future, whereas a punishment deters the behavior. Imagine you are teaching your dog, Hodor, to sit. You tell Hodor to sit, and give him a treat when he does. After repeated experiences, Hodor begins to associate the act of sitting with receiving a treat. He learns that the consequence of sitting is that he gets a doggie biscuit (Figure 1). Conversely, if the dog is punished when exhibiting a behavior, it becomes conditioned to avoid that behavior (e.g., receiving a small shock when crossing the boundary of an invisible electric fence).

![A photograph shows a dog standing at attention and smelling a treat in a person’s hand.](https://s3-us-west-2.amazonaws.com/courses-images-archive-read-only/wp-content/uploads/sites/902/2015/02/23224751/CNX_Psych_06_01_Dog.jpg)

**Figure 1**. In operant conditioning, a response is associated with a consequence. This dog has learned that certain behaviors result in receiving a treat. (credit: Crystal Rolfe)

Observational learning extends the effective range of both classical and operant conditioning. In contrast to classical and operant conditioning, in which learning occurs only through direct experience, observational learning is the process of watching others and then imitating what they do. A lot of learning among humans and other animals comes from observational learning. To get an idea of the extra effective range that observational learning brings, consider Ben and his son Julian from the introduction. How might observation help Julian learn to surf, as opposed to learning by trial and error alone? By watching his father, he can imitate the moves that bring success and avoid the moves that lead to failure. Can you think of something you have learned how to do after watching someone else?

All of the approaches covered in this module are part of a particular tradition in psychology, called behaviorism. However, these approaches you’ll be introduced to do not represent the entire study of learning. Separate traditions of learning have taken shape within different fields of psychology, such as memory and cognition, so you will find that other sections of this book will round out your understanding of the topic. Over time these traditions tend to converge. For example, in this module you will see how cognition has come to play a larger role in behaviorism, whose more extreme adherents once insisted that behaviors are triggered by the environment with no intervening thought.

### Watch It

For a sneak peek and overview of the main different types of learning, watch the CrashCourse psychology below. We’ll learn about each of these topics in greater depth throughout this module.

You can [view the transcript for “How to Train a Brain: Crash Course Psychology #11” here (opens in new window)](https://oerfiles.s3-us-west-2.amazonaws.com/Psychology/Transcriptions/HowToTrainABrainCrashCoursePsychology11.txt).

### Think It Over

-   What is your personal definition of learning? How do your ideas about learning compare with the definition of learning presented in this text?
-   What kinds of things have you learned through the process of classical conditioning? Operant conditioning? Observational learning? How did you learn them?

### Glossary

**associative learning:** form of learning that involves connecting certain stimuli or events that occur together in the environment (classical and operant conditioning)

**instinct:** unlearned knowledge, involving complex patterns of behavior; instincts are thought to be more prevalent in lower animals than in humans

**learning:** change in behavior or knowledge that is the result of experience

**reflex:** unlearned, automatic response by an organism to a stimulus in the environment

### Candela Citations

---

## Classical Conditioning | Introduction to Psychology

- url_title:: "Classical Conditioning | Introduction to Psychology"
  url_source:: https://courses.lumenlearning.com/waymaker-psychology/chapter/classical-conditioning/
### Learning Objectives

-   Explain how classical conditioning occurs
-   Identify the NS, UCS, UCR, CS, and CR in classical conditioning situations

Does the name Ivan Pavlov ring a bell? Even if you are new to the study of psychology, chances are that you have heard of Pavlov and his famous dogs.

Pavlov (1849–1936), a Russian scientist, performed extensive research on dogs and is best known for his experiments in classical conditioning (Figure 1). As we discussed briefly in the previous section, **classical conditioning** is a process by which we learn to associate stimuli and, consequently, to anticipate events.

![A portrait shows Ivan Pavlov.](https://s3-us-west-2.amazonaws.com/courses-images-archive-read-only/wp-content/uploads/sites/902/2015/02/23224753/CNX_Psych_06_02_Pavlov.jpg)

**Figure 1**. Ivan Pavlov’s research on the digestive system of dogs unexpectedly led to his discovery of the learning process now known as classical conditioning.

Pavlov came to his conclusions about how learning occurs completely by accident. Pavlov was a physiologist, not a psychologist. Physiologists study the life processes of organisms, from the molecular level to the level of cells, organ systems, and entire organisms. Pavlov’s area of interest was the digestive system (Hunt, 2007). In his studies with dogs, Pavlov measured the amount of saliva produced in response to various foods. Over time, Pavlov (1927) observed that the dogs began to salivate not only at the taste of food, but also at the sight of food, at the sight of an empty food bowl, and even at the sound of the laboratory assistants’ footsteps. Salivating to food in the mouth is reflexive, so no learning is involved. However, dogs don’t naturally salivate at the sight of an empty bowl or the sound of footsteps.

These unusual responses intrigued Pavlov, and he wondered what accounted for what he called the dogs’ “psychic secretions” (Pavlov, 1927). To explore this phenomenon in an objective manner, Pavlov designed a series of carefully controlled experiments to see which stimuli would cause the dogs to salivate. He was able to train the dogs to salivate in response to stimuli that clearly had nothing to do with food, such as the sound of a bell, a light, and a touch on the leg. Through his experiments, Pavlov realized that an organism has two types of responses to its environment: (1) unconditioned (unlearned) responses, or reflexes, and (2) conditioned (learned) responses.

In Pavlov’s experiments, the dogs salivated each time meat powder was presented to them. The meat powder in this situation was an **unconditioned stimulus (UCS)**: a stimulus that elicits a reflexive response in an organism. The dogs’ salivation was an **unconditioned response (UCR)**: a natural (unlearned) reaction to a given stimulus. Before conditioning, think of the dogs’ stimulus and response like this:

Meat powder (UCS) → Salivation (UCR)

In classical conditioning, a **neutral stimulus** is presented immediately before an unconditioned stimulus. Pavlov would sound a tone (like ringing a bell) and then give the dogs the meat powder (Figure 2). The tone was the neutral stimulus (NS), which is a stimulus that does not naturally elicit a response. Prior to conditioning, the dogs did not salivate when they just heard the tone because the tone had no association for the dogs. Quite simply this pairing means:

Tone (NS) + Meat Powder (UCS) → Salivation (UCR)

When Pavlov paired the tone with the meat powder over and over again, the previously neutral stimulus (the tone) also began to elicit salivation from the dogs. Thus, the neutral stimulus became the **conditioned stimulus (CS)**, which is a stimulus that elicits a response after repeatedly being paired with an unconditioned stimulus. Eventually, the dogs began to salivate to the tone alone, just as they previously had salivated at the sound of the assistants’ footsteps. The behavior caused by the conditioned stimulus is called the **conditioned response (CR)**. In the case of Pavlov’s dogs, they had learned to associate the tone (CS) with being fed, and they began to salivate (CR) in anticipation of food.

Tone (CS) → Salivation (CR)

![Two illustrations are labeled “before conditioning” and show a dog salivating over a dish of food, and a dog not salivating while a bell is rung. An illustration labeled “during conditioning” shows a dog salivating over a bowl of food while a bell is rung. An illustration labeled “after conditioning” shows a dog salivating while a bell is rung.](https://s3-us-west-2.amazonaws.com/courses-images-archive-read-only/wp-content/uploads/sites/902/2015/02/23224754/CNX_Psych_06_02_Classical.jpg)

**Figure 2**. Before conditioning, an unconditioned stimulus (food) produces an unconditioned response (salivation), and a neutral stimulus (bell) does not produce a response. During conditioning, the unconditioned stimulus (food) is presented repeatedly just after the presentation of the neutral stimulus (bell). After conditioning, the neutral stimulus alone produces a conditioned response (salivation), thus becoming a conditioned stimulus.

### Try It

See if you can identify all of the “parts” of a classical conditioning situation in the following questions.  

### Watch It

View the following video to learn more about Pavlov and his dogs:

## Real World Application of Classical Conditioning

How does classical conditioning work in the real world? Consider the case of Moisha, who was diagnosed with cancer. When she received her first chemotherapy treatment, she vomited shortly after the chemicals were injected. In fact, every trip to the doctor for chemotherapy treatment shortly after the drugs were injected, she vomited. Moisha’s treatment was a success and her cancer went into remission. Now, when she visits her oncologist’s office every 6 months for a check-up, she becomes nauseous. In this case, the chemotherapy drugs are the unconditioned stimulus (UCS), vomiting is the unconditioned response (UCR), the doctor’s office is the conditioned stimulus (CS) after being paired with the UCS, and nausea is the conditioned response (CR). Let’s assume that the chemotherapy drugs that Moisha takes are given through a syringe injection. After entering the doctor’s office, Moisha sees a syringe, and then gets her medication. In addition to the doctor’s office, Moisha will learn to associate the syringe with the medication and will respond to syringes with nausea. This is an example of higher-order (or second-order) conditioning, when the conditioned stimulus (the doctor’s office) serves to condition another stimulus (the syringe). It is hard to achieve anything above second-order conditioning. For example, if someone rang a bell every time Moisha received a syringe injection of chemotherapy drugs in the doctor’s office, Moisha likely will never get sick in response to the bell.

Consider another example of classical conditioning. Let’s say you have a cat named Tiger, who is quite spoiled. You keep her food in a separate cabinet, and you also have a special electric can opener that you use only to open cans of cat food. For every meal, Tiger hears the distinctive sound of the electric can opener (“zzhzhz”) and then gets her food. Tiger quickly learns that when she hears “zzhzhz” she is about to get fed. What do you think Tiger does when she hears the electric can opener? She will likely get excited and run to where you are preparing her food. This is an example of classical conditioning. In this case, what are the UCS, CS, UCR, and CR?

What if the cabinet holding Tiger’s food becomes squeaky? In that case, Tiger hears “squeak” (the cabinet), “zzhzhz” (the electric can opener), and then she gets her food. Tiger will learn to get excited when she hears the “squeak” of the cabinet. Pairing a new neutral stimulus (“squeak”) with the conditioned stimulus (“zzhzhz”) is called higher-order conditioning, or second-order conditioning. This means you are using the conditioned stimulus of the can opener to condition another stimulus: the squeaky cabinet (Figure 3). It is hard to achieve anything above second-order conditioning. For example, if you ring a bell, open the cabinet (“squeak”), use the can opener (“zzhzhz”), and then feed Tiger, Tiger will likely never get excited when hearing the bell alone.

![A diagram is labeled “Higher-Order / Second-Order Conditioning” and has three rows. The first row shows an electric can opener labeled “conditioned stimulus (CS)” followed by a plus sign and then a dish of food labeled “unconditioned stimulus (UCS)” followed by an equal sign and a picture of a salivating cat labeled “unconditioned response (UCR).” The second row shows a squeaky cabinet door labeled “second-order stimulus” followed by a plus sign and then an electric can opener labeled “conditioned stimulus (CS)” followed by an equal sign and a picture of a salivating cat labeled “conditioned response (CR).” The third row shows a squeaky cabinet door labeled “second-order stimulus” followed by an equal sign and a picture of a salivating cat labeled “conditioned response (CR).”](https://s3-us-west-2.amazonaws.com/courses-images-archive-read-only/wp-content/uploads/sites/902/2015/02/23224756/CNX_Psych_06_02_SecondOrdrn.jpg)

**Figure 3**. In higher-order conditioning, an established conditioned stimulus is paired with a new neutral stimulus (the second-order stimulus), so that eventually the new stimulus also elicits the conditioned response, without the initial conditioned stimulus being presented.

### Everyday Connection: Classical Conditioning at Stingray City

![A photograph shows a woman standing in the ocean holding a stingray.](https://s3-us-west-2.amazonaws.com/courses-images-archive-read-only/wp-content/uploads/sites/902/2015/02/23224757/CNX_Psych_06_02_Stingray.jpg)

**Figure 4**. Kate holds a southern stingray at Stingray City in the Cayman Islands. These stingrays have been classically conditioned to associate the sound of a boat motor with food provided by tourists. (credit: Kathryn Dumper)

Kate and her husband Scott recently vacationed in the Cayman Islands, and booked a boat tour to Stingray City, where they could feed and swim with the southern stingrays. The boat captain explained how the normally solitary stingrays have become accustomed to interacting with humans. About 40 years ago, fishermen began to clean fish and conch (unconditioned stimulus) at a particular sandbar near a barrier reef, and large numbers of stingrays would swim in to eat (unconditioned response) what the fishermen threw into the water; this continued for years. By the late 1980s, word of the large group of stingrays spread among scuba divers, who then started feeding them by hand. Over time, the southern stingrays in the area were classically conditioned much like Pavlov’s dogs. When they hear the sound of a boat engine (neutral stimulus that becomes a conditioned stimulus), they know that they will get to eat (conditioned response).

As soon as Kate and Scott reached Stingray City, over two dozen stingrays surrounded their tour boat. The couple slipped into the water with bags of squid, the stingrays’ favorite treat. The swarm of stingrays bumped and rubbed up against their legs like hungry cats (Figure 4). Kate and Scott were able to feed, pet, and even kiss (for luck) these amazing creatures. Then all the squid was gone, and so were the stingrays.

Classical conditioning also applies to humans, even babies. For example, Sara buys formula in blue canisters for her six-month-old daughter, Angelina. Whenever Sara takes out a formula container, Angelina gets excited, tries to reach toward the food, and most likely salivates. Why does Angelina get excited when she sees the formula canister? What are the UCS, CS, UCR, and CR here?

So far, all of the examples have involved food, but classical conditioning extends beyond the basic need to be fed. Consider our earlier example of a dog whose owners install an invisible electric dog fence. A small electrical shock (unconditioned stimulus) elicits discomfort (unconditioned response). When the unconditioned stimulus (shock) is paired with a neutral stimulus (the edge of a yard), the dog associates the discomfort (unconditioned response) with the edge of the yard (conditioned stimulus) and stays within the set boundaries.

### Watch It

For a humorous look at conditioning, you can [watch an example from the television show _The Office_](https://vimeo.com/35754924). Jim conducts an experiment in which he offers Dwight a breath mint every time Jim’s computer makes a specific sound. After repeating this several times, he eventually conditions Dwight to automatically expect a breath mint upon hearing that sound.  See if you can identify the NS, UCS, UCR, CS, and CR.

### Try It

Review the classical conditioning concepts yet again by walking through Pavlov’s research in the following interactive:

### Think It Over

Can you think of an example in your life of how classical conditioning has produced a positive emotional response, such as happiness or excitement? How about a negative emotional response, such as fear, anxiety, or anger?

### Glossary

**classical conditioning:** learning in which the stimulus or experience occurs before the behavior and then gets paired or associated with the behavior

**conditioned response (CR):** response caused by the conditioned stimulus

**conditioned stimulus (CS):** stimulus that elicits a response due to its being paired with an unconditioned stimulus

**higher-order conditioning:** (also, second-order conditioning) using a conditioned stimulus to condition a neutral stimulus

**neutral stimulus (NS):** stimulus that does not initially elicit a response

**unconditioned response (UCR):** natural (unlearned) behavior to a given stimulus

**unconditioned stimulus (UCS):** stimulus that elicits a reflexive response

### Candela Citations

CC licensed content, Original

-   Modification and adaptation, addition of tutorial. **Provided by**: Lumen Learning. **License**: _[CC BY: Attribution](https://creativecommons.org/licenses/by/4.0/)_
-   Classical conditioning interactive. **Authored by**: Jessica Traylor for Lumen Learning. **Provided by**: Lumen Learning. **License**: _[CC BY: Attribution](https://creativecommons.org/licenses/by/4.0/)_

CC licensed content, Shared previously

-   Classical Conditioning. **Authored by**: OpenStax College. **Located at**: [https://openstax.org/books/psychology-2e/pages/6-2-classical-conditioning](https://openstax.org/books/psychology-2e/pages/6-2-classical-conditioning). **License**: _[CC BY: Attribution](https://creativecommons.org/licenses/by/4.0/)_. **License Terms**: Download for free at https://openstax.org/books/psychology-2e/pages/1-introduction

All rights reserved content

-   Classical Conditioning - Ivan Pavlov. **Authored by**: BullyingNewsVideos. **Located at**: [https://www.youtube.com/watch?v=hhqumfpxuzI](https://www.youtube.com/watch?v=hhqumfpxuzI). **License**: _Other_. **License Terms**: Standard YouTube License
-   The Office Classical Conditioning. **Authored by**: Susann Stanley. **Provided by**: Vimeo. **Located at**: [https://vimeo.com/35754924](https://vimeo.com/35754924). **License**: _All Rights Reserved_

---

## Latent Learning | Introduction to Psychology

- url_title:: "Latent Learning | Introduction to Psychology"
  url_source:: https://courses.lumenlearning.com/waymaker-psychology/chapter/reading-cognition-and-latent-learning/
### Learning Objectives

-   Explain latent learning and cognitive maps

Strict behaviorists like Watson and Skinner focused exclusively on studying behavior rather than cognition (such as thoughts and expectations). In fact, Skinner was such a staunch believer that cognition didn’t matter that his ideas were considered **radical behaviorism**. Skinner considered the mind a “black box”—something completely unknowable—and, therefore, something not to be studied. However, another behaviorist, Edward C. Tolman, had a different opinion. Tolman’s experiments with rats demonstrated that organisms can learn even if they do not receive immediate reinforcement (Tolman & Honzik, 1930; Tolman, Ritchie, & Kalish, 1946). This finding was in conflict with the prevailing idea at the time that reinforcement must be immediate in order for learning to occur, thus suggesting a cognitive aspect to learning.

**Latent learning** is a form of learning that is not immediately expressed in an overt response. It occurs without any obvious reinforcement of the behavior or associations that are learned. Latent learning is not readily apparent to the researcher because it is not shown behaviorally until there is sufficient motivation. This type of learning broke the constraints of behaviorism, which stated that processes must be directly observable and that learning was the direct consequence of conditioning to stimuli.

In the experiments, Tolman placed hungry rats in a maze with no reward for finding their way through it. He also studied a comparison group that was rewarded with food at the end of the maze. As the unreinforced rats explored the maze, they developed a **cognitive map**: a mental picture of the layout of the maze (Figure 1). After 10 sessions in the maze without reinforcement, food was placed in a goal box at the end of the maze. As soon as the rats became aware of the food, they were able to find their way through the maze quickly, just as quickly as the comparison group, which had been rewarded with food all along. This is known as latent learning: learning that occurs but is not observable in behavior until there is a reason to demonstrate it.

![An illustration shows three rats in a maze, with a starting point and food at the end.](https://s3-us-west-2.amazonaws.com/courses-images-archive-read-only/wp-content/uploads/sites/902/2015/02/23224812/CNX_Psych_06_03_Ratmaze.jpg)

**Figure 1**. Psychologist Edward Tolman found that rats use cognitive maps to navigate through a maze. Have you ever worked your way through various levels on a video game? You learned when to turn left or right, move up or down. In that case you were relying on a cognitive map, just like the rats in a maze. (credit: modification of work by “FutUndBeidl”/Flickr)

Latent learning also occurs in humans. Children may learn by watching the actions of their parents but only demonstrate it at a later date, when the learned material is needed. For example, suppose that Ravi’s dad drives him to school every day. In this way, Ravi learns the route from his house to his school, but he’s never driven there himself, so he has not had a chance to demonstrate that he’s learned the way. One morning Ravi’s dad has to leave early for a meeting, so he can’t drive Ravi to school. Instead, Ravi follows the same route on his bike that his dad would have taken in the car. This demonstrates latent learning. Ravi had learned the route to school, but had no need to demonstrate this knowledge earlier.

### Everyday Connection: This Place Is Like a Maze

Have you ever gotten lost in a building and couldn’t find your way back out? While that can be frustrating, you’re not alone. At one time or another we’ve all gotten lost in places like a museum, hospital, or university library. Whenever we go someplace new, we build a mental representation—or cognitive map—of the location, as Tolman’s rats built a cognitive map of their maze. However, some buildings are confusing because they include many areas that look alike or have short lines of sight. Because of this, it’s often difficult to predict what’s around a corner or decide whether to turn left or right to get out of a building. Psychologist Laura Carlson (2010) suggests that what we place in our cognitive map can impact our success in navigating through the environment. She suggests that paying attention to specific features upon entering a building, such as a picture on the wall, a fountain, a statue, or an escalator, adds information to our cognitive map that can be used later to help find our way out of the building.

### Glossary

**cognitive map:** mental picture of the layout of the environment

**latent learning:** learning that occurs, but it may not be evident until there is a reason to demonstrate it

### Candela Citations

CC licensed content, Shared previously

-   Operant Conditioning. **Authored by**: OpenStax College. **Located at**: [https://openstax.org/books/psychology-2e/pages/6-3-operant-conditioning](https://openstax.org/books/psychology-2e/pages/6-3-operant-conditioning). **License**: _[CC BY: Attribution](https://creativecommons.org/licenses/by/4.0/)_. **License Terms**: Download for free at https://openstax.org/books/psychology-2e/pages/1-introduction
-   Latent Learning. **Provided by**: Boundless. **Located at**: [https://www.boundless.com/psychology/textbooks/boundless-psychology-textbook/learning-7/cognitive-approaches-to-learning-48/latent-learning-202-12737/](https://www.boundless.com/psychology/textbooks/boundless-psychology-textbook/learning-7/cognitive-approaches-to-learning-48/latent-learning-202-12737/). **License**: _[CC BY-SA: Attribution-ShareAlike](https://creativecommons.org/licenses/by-sa/4.0/)_

---

## Observational Learning | Introduction to Psychology

- url_title:: "Observational Learning | Introduction to Psychology"
  url_source:: https://courses.lumenlearning.com/waymaker-psychology/chapter/observational-learning-modeling/
### Learning Objectives

-   Explain observational learning and the steps in the modeling process

Previous sections of this chapter focused on classical and operant conditioning, which are forms of associative learning. In **observational learning**, we learn by watching others and then imitating, or modeling, what they do or say. For instance, have you ever gone to YouTube to find a video showing you how to do something? The individuals performing the imitated behavior are called **models**. Research suggests that this imitative learning involves a specific type of neuron, called a mirror neuron (Hickock, 2010; Rizzolatti, Fadiga, Fogassi, & Gallese, 2002; Rizzolatti, Fogassi, & Gallese, 2006).

Humans and other animals are capable of observational learning. As you will see, the phrase “monkey see, monkey do” really is accurate (Figure 1). The same could be said about other animals. For example, in a study of social learning in chimpanzees, researchers gave juice boxes with straws to two groups of captive chimpanzees. The first group dipped the straw into the juice box, and then sucked on the small amount of juice at the end of the straw. The second group sucked through the straw directly, getting much more juice. When the first group, the “dippers,” observed the second group, “the suckers,” what do you think happened? All of the “dippers” in the first group switched to sucking through the straws directly. By simply observing the other chimps and modeling their behavior, they learned that this was a more efficient method of getting juice (Yamamoto, Humle, and Tanaka, 2013).

![A photograph shows a person drinking from a water bottle, and a monkey next to the person drinking water from a bottle in the same manner.](https://s3-us-west-2.amazonaws.com/courses-images-archive-read-only/wp-content/uploads/sites/902/2015/02/23224815/CNX_Psych_06_04_Monkey.jpg)

**Figure 1**. This spider monkey learned to drink water from a plastic bottle by seeing the behavior modeled by a human. (credit: U.S. Air Force, Senior Airman Kasey Close)

Imitation is much more obvious in humans, but is imitation really the sincerest form of flattery? Consider Claire’s experience with observational learning. Claire’s nine-year-old son, Jay, was getting into trouble at school and was defiant at home. Claire feared that Jay would end up like her brothers, two of whom were in prison. One day, after yet another bad day at school and another negative note from the teacher, Claire, at her wit’s end, beat her son with a belt to get him to behave. Later that night, as she put her children to bed, Claire witnessed her four-year-old daughter, Anna, take a belt to her teddy bear and whip it. Claire was horrified, realizing that Anna was imitating her mother. It was then that Claire knew she wanted to discipline her children in a different manner.

Like Tolman, whose experiments with rats suggested a cognitive component to learning, psychologist Albert Bandura’s ideas about learning were different from those of strict behaviorists. Bandura and other researchers proposed a brand of behaviorism called **social learning theory**, which took cognitive processes into account. According to Bandura, pure behaviorism could not explain why learning can take place in the absence of external reinforcement. He felt that internal mental states must also have a role in learning and that observational learning involves much more than imitation. In imitation, a person simply copies what the model does. Observational learning is much more complex. According to Lefrançois (2012) there are several ways that observational learning can occur: You learn a new response. After watching your coworker get chewed out by your boss for coming in late, you start leaving home 10 minutes earlier so that you won’t be late. You choose whether or not to imitate the model depending on what you saw happen to the model. Remember Julian and his father? When learning to surf, Julian might watch how his father pops up successfully on his surfboard and then attempt to do the same thing. On the other hand, Julian might learn not to touch a hot stove after watching his father get burned on a stove. You learn a general rule that you can apply to other situations.

Bandura identified three kinds of models: live, verbal, and symbolic. A live model demonstrates a behavior in person, as when Ben stood up on his surfboard so that Julian could see how he did it. A verbal instructional model does not perform the behavior, but instead explains or describes the behavior, as when a soccer coach tells his young players to kick the ball with the side of the foot, not with the toe. A symbolic model can be fictional characters or real people who demonstrate behaviors in books, movies, television shows, video games, or Internet sources (Figure 2).

![Photograph A shows a yoga instructor demonstrating a yoga pose while a group of students observes her and copies the pose. Photo B shows a child watching television.](https://s3-us-west-2.amazonaws.com/courses-images-archive-read-only/wp-content/uploads/sites/902/2015/02/23224816/CNX_Psych_06_04_Yoga.jpg)

**Figure 2**. (a) Yoga students learn by observation as their yoga instructor demonstrates the correct stance and movement for her students (live model). (b) Models don’t have to be present for learning to occur: through symbolic modeling, this child can learn a behavior by watching someone demonstrate it on television. (credit a: modification of work by Tony Cecala; credit b: modification of work by Andrew Hyde)

### Link to Learning

Latent learning and modeling are used all the time in the world of marketing and advertising. [This commercial](https://www.youtube.com/watch?v=5j5Xr1t6DJc) played for months across the New York, New Jersey, and Connecticut areas, Derek Jeter—an award-winning baseball player for the New York Yankees, is advertising a Ford. The commercial aired in a part of the country where Jeter is an incredibly well-known athlete. He is wealthy, and considered very loyal and good looking. What message are the advertisers sending by having him featured in the ad? How effective do you think it is?

## Steps in the Modeling Process

Of course, we don’t learn a behavior simply by observing a model. Bandura described specific steps in the process of modeling that must be followed if learning is to be successful: attention, retention, reproduction, and motivation. First, you must be focused on what the model is doing—you have to pay attention. Next, you must be able to retain, or remember, what you observed; this is retention. Then, you must be able to perform the behavior that you observed and committed to memory; this is reproduction. Finally, you must have motivation. You need to want to copy the behavior, and whether or not you are motivated depends on what happened to the model. If you saw that the model was reinforced for her behavior, you will be more motivated to copy her. This is known as vicarious reinforcement. On the other hand, if you observed the model being punished, you would be less motivated to copy her. This is called vicarious punishment. For example, imagine that four-year-old Allison watched her older sister Kaitlyn playing in their mother’s makeup, and then saw Kaitlyn get a time out when their mother came in. After their mother left the room, Allison was tempted to play in the make-up, but she did not want to get a time-out from her mother. What do you think she did? Once you actually demonstrate the new behavior, the reinforcement you receive plays a part in whether or not you will repeat the behavior.

Bandura researched modeling behavior, particularly children’s modeling of adults’ aggressive and violent behaviors (Bandura, Ross, & Ross, 1961). He conducted an experiment with a five-foot inflatable doll that he called a Bobo doll. In the experiment, children’s aggressive behavior was influenced by whether the teacher was punished for her behavior. In one scenario, a teacher acted aggressively with the doll, hitting, throwing, and even punching the doll, while a child watched. There were two types of responses by the children to the teacher’s behavior. When the teacher was punished for her bad behavior, the children decreased their tendency to act as she had. When the teacher was praised or ignored (and not punished for her behavior), the children imitated what she did, and even what she said. They punched, kicked, and yelled at the doll.

### Watch It

Watch the following to see a portion of the famous Bobo doll experiment, including an interview with Albert Bandura.

You can [view the transcript for “Albert Bandura Bobo Doll experiment.mp4” here (opens in new window)](https://oerfiles.s3-us-west-2.amazonaws.com/Psychology/Transcriptions/AlbertBanduraBoboDollExperiment.txt).

What are the implications of this study? Bandura concluded that we watch and learn, and that this learning can have both prosocial and antisocial effects. Prosocial (positive) models can be used to encourage socially acceptable behavior. Parents in particular should take note of this finding. If you want your children to read, then read to them. Let them see you reading. Keep books in your home. Talk about your favorite books. If you want your children to be healthy, then let them see you eat right and exercise, and spend time engaging in physical fitness activities together. The same holds true for qualities like kindness, courtesy, and honesty. The main idea is that children observe and learn from their parents, even their parents’ morals, so be consistent and toss out the old adage “Do as I say, not as I do,” because children tend to copy what you do instead of what you say. Besides parents, many public figures, such as Martin Luther King, Jr. and Mahatma Gandhi, are viewed as prosocial models who are able to inspire global social change. Can you think of someone who has been a prosocial model in your life?

![A photograph shows two children playing a video game and pointing a gun-like object toward a screen.](https://s3-us-west-2.amazonaws.com/courses-images-archive-read-only/wp-content/uploads/sites/902/2015/02/23224818/CNX_Psych_06_04_Videogames.jpg)

**Figure 3**. Can video games make us violent? Psychological researchers study this topic. (credit: “woodleywonderworks”/Flickr)

The antisocial effects of observational learning are also worth mentioning. As you saw from the example of Claire at the beginning of this section, her daughter viewed Claire’s aggressive behavior and copied it. Research suggests that this may help to explain why abused children often grow up to be abusers themselves (Murrell, Christoff, & Henning, 2007). In fact, about 30% of abused children become abusive parents (U.S. Department of Health & Human Services, 2013). We tend to do what we know. Abused children, who grow up witnessing their parents deal with anger and frustration through violent and aggressive acts, often learn to behave in that manner themselves. Sadly, it’s a vicious cycle that’s difficult to break.

Some studies suggest that violent television shows, movies, and video games may also have antisocial effects (Figure 3) although further research needs to be done to understand the correlational and causational aspects of media violence and behavior. Some studies have found a link between viewing violence and aggression seen in children (Anderson & Gentile, 2008; Kirsch, 2010; Miller, Grabell, Thomas, Bermann, & Graham-Bermann, 2012). These findings may not be surprising, given that a child graduating from high school has been exposed to around 200,000 violent acts including murder, robbery, torture, bombings, beatings, and rape through various forms of media (Huston et al., 1992). Not only might viewing media violence affect aggressive behavior by teaching people to act that way in real life situations, but it has also been suggested that repeated exposure to violent acts also desensitizes people to it. Psychologists are working to understand this dynamic.

### what do you think?

## **Violent Media and Aggression**

Does watching violent media or playing violent video games cause aggression? Albert Bandura’s early studies suggested television violence increased aggression in children, and more recent studies support these findings. For example, research by Craig Anderson and colleagues (Anderson, Bushman, Donnerstein, Hummer, & Warbuten, 2015; Anderson et al., 2010; Bushman et al., 2016) found extensive evidence to suggest a causal link between hours of exposure to violent media and aggressive thoughts and behaviors. However, studies by Christopher Ferguson and others suggests that while there may be a link between violent media exposure and aggression, research to date has not accounted for other risk factors for aggression including mental health and family life (Ferguson, 2011; Gentile, 2016). What do you think?

### Link to Learning

Watch the Crash Course video _[The Bobo Beatdown](https://www.youtube.com/watch?v=128Ts5r9NRE)_ for further explanation on observational learning.

### Think It Over

What is something you have learned how to do after watching someone else?

### Glossary

**model:** person who performs a behavior that serves as an example (in observational learning)

**observational learning:** type of learning that occurs by watching others

**vicarious punishment:** process where the observer sees the model punished, making the observer less likely to imitate the model’s behavior

**vicarious reinforcement:** process where the observer sees the model rewarded, making the observer more likely to imitate the model’s behavior

### Candela Citations

CC licensed content, Shared previously

-   Psychology. **Authored by**: OpenStax College. **Located at**: [https://openstax.org/books/psychology-2e/pages/6-4-observational-learning-modeling](https://openstax.org/books/psychology-2e/pages/6-4-observational-learning-modeling). **License**: _[CC BY: Attribution](https://creativecommons.org/licenses/by/4.0/)_. **License Terms**: Download for free at https://openstax.org/books/psychology-2e/pages/1-introduction
-   Albert Bandura Bobo Doll experiment. **Authored by**: kpharden. **Located at**: [https://www.youtube.com/watch?v=Z0iWpSNu3NU](https://www.youtube.com/watch?v=Z0iWpSNu3NU). **License**: _[CC BY: Attribution](https://creativecommons.org/licenses/by/4.0/)_. **License Terms**: Download for free at http://cnx.org/contents/4abf04bf-93a0-45c3-9cbc-2cefd46e68cc@5.48
-   Modification and adaptation. **Provided by**: Lumen Learning. **License**: _[CC BY: Attribution](https://creativecommons.org/licenses/by/4.0/)_

---

## Operant Conditioning | Introduction to Psychology

- url_title:: "Operant Conditioning | Introduction to Psychology"
  url_source:: https://courses.lumenlearning.com/waymaker-psychology/chapter/reading-operant-conditioning/
### Learning Objectives

-   Define and give examples of operant conditioning

The previous section of this module focused on the type of associative learning known as classical conditioning. Remember that in classical conditioning, something in the environment triggers a reflex automatically, and researchers train the organism to react to a different stimulus. Now we turn to the second type of associative learning, operant conditioning. In **operant conditioning**, organisms learn to associate a behavior and its consequence (Table 1). A pleasant consequence makes that behavior more likely to be repeated in the future. For example, Spirit, a dolphin at the National Aquarium in Baltimore, does a flip in the air when her trainer blows a whistle. The consequence is that she gets a fish.

<table><caption>Table 1. Classical and Operant Conditioning Compared</caption><tbody><tr><td aria-label="no value"></td><th scope="col">Classical Conditioning</th><th scope="col">Operant Conditioning</th></tr><tr><th scope="row">Conditioning approach</th><td>An unconditioned stimulus (such as food) is paired with a neutral stimulus (such as a bell). The neutral stimulus eventually becomes the conditioned stimulus, which brings about the conditioned response (salivation).</td><td>The target behavior is followed by reinforcement or punishment to either strengthen or weaken it, so that the learner is more likely to exhibit the desired behavior in the future.</td></tr><tr><th scope="row">Stimulus timing</th><td>The stimulus occurs immediately before the response.</td><td>The stimulus (either reinforcement or punishment) occurs soon after the response.</td></tr></tbody></table>

Psychologist B. F. Skinner saw that classical conditioning is limited to existing behaviors that are reflexively elicited, and it doesn’t account for new behaviors such as riding a bike. He proposed a theory about how such behaviors come about. Skinner believed that behavior is motivated by the consequences we receive for the behavior: the reinforcements and punishments. His idea that learning is the result of consequences is based on the **law of effect**, which was first proposed by psychologist Edward Thorndike. According to the law of effect, behaviors that are followed by consequences that are satisfying to the organism are more likely to be repeated, and behaviors that are followed by unpleasant consequences are less likely to be repeated (Thorndike, 1911). Essentially, if an organism does something that brings about a desired result, the organism is more likely to do it again. If an organism does something that does not bring about a desired result, the organism is less likely to do it again. An example of the law of effect is in employment. One of the reasons (and often the main reason) we show up for work is because we get paid to do so. If we stop getting paid, we will likely stop showing up—even if we love our job.

Working with Thorndike’s law of effect as his foundation, Skinner began conducting scientific experiments on animals (mainly rats and pigeons) to determine how organisms learn through operant conditioning (Skinner, 1938). He placed these animals inside an operant conditioning chamber, which has come to be known as a “Skinner box” (Figure 1). A Skinner box contains a lever (for rats) or disk (for pigeons) that the animal can press or peck for a food reward via the dispenser. Speakers and lights can be associated with certain behaviors. A recorder counts the number of responses made by the animal.

![A photograph shows B.F. Skinner. An illustration shows a rat in a Skinner box: a chamber with a speaker, lights, a lever, and a food dispenser.](https://s3-us-west-2.amazonaws.com/courses-images-archive-read-only/wp-content/uploads/sites/902/2015/02/23224804/CNX_Psych_06_03_Skinnerbox_n.jpg)

**Figure 1**. (a) B. F. Skinner developed operant conditioning for systematic study of how behaviors are strengthened or weakened according to their consequences. (b) In a Skinner box, a rat presses a lever in an operant conditioning chamber to receive a food reward. (credit a: modification of work by “Silly rabbit”/Wikimedia Commons)

### Watch IT

Watch the following clip to learn more about operant conditioning and to watch an interview with Skinner as he talks about conditioning pigeons.

<span data-mce-type="bookmark" style="display: inline-block; width: 0px; overflow: hidden; line-height: 0;" class="mce\_SELRES\_start">﻿</span>

You can [view the transcript for “Operant conditioning” here (opens in new window)](https://oerfiles.s3-us-west-2.amazonaws.com/Psychology/Transcriptions/OperantConditioning_transcript.txt).

### Glossary

**law of effect:** behavior that is followed by consequences satisfying to the organism will be repeated and behaviors that are followed by unpleasant consequences will be discouraged

**operant conditioning:** form of learning in which the stimulus/experience happens after the behavior is demonstrated

### Candela Citations

---

## Processes in Classical Conditioning | Introduction to Psychology

- url_title:: "Processes in Classical Conditioning | Introduction to Psychology"
  url_source:: https://courses.lumenlearning.com/waymaker-psychology/chapter/reading-processes-in-classical-conditioning/
### Learning Objectives

-   Describe the processes of acquisition, extinction, spontaneous recovery, generalization, and discrimination

Now that you know how classical conditioning works and have seen several examples, let’s take a look at some of the general processes involved. In classical conditioning, the initial period of learning is known as acquisition, when an organism learns to connect a neutral stimulus and an unconditioned stimulus. During **acquisition**, the neutral stimulus begins to elicit the conditioned response, and eventually the neutral stimulus becomes a conditioned stimulus capable of eliciting the conditioned response by itself. Timing is important for conditioning to occur. Typically, there should only be a brief interval between presentation of the conditioned stimulus and the unconditioned stimulus. Depending on what is being conditioned, sometimes this interval is as little as five seconds (Chance, 2009). However, with other types of conditioning, the interval can be up to several hours.

**Taste aversion** is a type of conditioning in which an interval of several hours may pass between the conditioned stimulus (something ingested) and the unconditioned stimulus (nausea or illness). Here’s how it works. Between classes, you and a friend grab a quick lunch from a food cart on campus. You share a dish of chicken curry and head off to your next class. A few hours later, you feel nauseous and become ill. Although your friend is fine and you determine that you have intestinal flu (the food is not the culprit), you’ve developed a taste aversion; the next time you are at a restaurant and someone orders curry, you immediately feel ill. While the chicken dish is not what made you sick, you are experiencing taste aversion: you’ve been conditioned to be averse to a food after a single, unpleasant experience.

How does this occur—conditioning based on a single instance and involving an extended time lapse between the event and the negative stimulus? Research into taste aversion suggests that this response may be an evolutionary adaptation designed to help organisms quickly learn to avoid harmful foods (Garcia & Rusiniak, 1980; Garcia & Koelling, 1966). Not only may this contribute to species survival via natural selection, but it may also help us develop strategies for challenges such as helping cancer patients through the nausea induced by certain treatments (Holmes, 1993; Jacobsen et al., 1993; Hutton, Baracos, & Wismer, 2007; Skolin et al., 2006). Garcia and Koelling (1966) showed not only that taste aversions could be conditioned, but also that there were biological constraints to learning. In their study, separate groups of rats were conditioned to associate either a flavor with illness, or lights and sounds with illness. Results showed that all rats exposed to flavor-illness pairings learned to avoid the flavor, but none of the rats exposed to lights and sounds with illness learned to avoid lights or sounds. This added evidence to the idea that classical conditioning could contribute to species survival by helping organisms learn to avoid stimuli that posed real dangers to health and welfare.

Robert Rescorla demonstrated how powerfully an organism can learn to predict the UCS from the CS. Take, for example, the following two situations. Ari’s dad always has dinner on the table every day at 6:00. Soraya’s mom switches it up so that some days they eat dinner at 6:00, some days they eat at 5:00, and other days they eat at 7:00. For Ari, 6:00 reliably and consistently predicts dinner, so Ari will likely start feeling hungry every day right before 6:00, even if he’s had a late snack. Soraya, on the other hand, will be less likely to associate 6:00 with dinner, since 6:00 does not always predict that dinner is coming. Rescorla, along with his colleague at Yale University, Alan Wagner, developed a mathematical formula that could be used to calculate the probability that an association would be learned given the ability of a conditioned stimulus to predict the occurrence of an unconditioned stimulus and other factors; today this is known as the Rescorla-Wagner model (Rescorla & Wagner, 1972)

Once we have established the connection between the unconditioned stimulus and the conditioned stimulus, how do we break that connection and get the dog, cat, or child to stop responding? In Tiger’s case, imagine what would happen if you stopped using the electric can opener for her food and began to use it only for human food. Now, Tiger would hear the can opener, but she would not get food. In classical conditioning terms, you would be giving the conditioned stimulus, but not the unconditioned stimulus. Pavlov explored this scenario in his experiments with dogs: sounding the tone without giving the dogs the meat powder. Soon the dogs stopped responding to the tone. **Extinction** is the decrease in the conditioned response when the unconditioned stimulus is no longer presented with the conditioned stimulus. When presented with the conditioned stimulus alone, the dog, cat, or other organism would show a weaker and weaker response, and finally no response. In classical conditioning terms, there is a gradual weakening and disappearance of the conditioned response.

What happens when learning is not used for a while—when what was learned lies dormant? As we just discussed, Pavlov found that when he repeatedly presented the bell (conditioned stimulus) without the meat powder (unconditioned stimulus), extinction occurred; the dogs stopped salivating to the bell. However, after a couple of hours of resting from this extinction training, the dogs again began to salivate when Pavlov rang the bell. What do you think would happen with Tiger’s behavior if your electric can opener broke, and you did not use it for several months? When you finally got it fixed and started using it to open Tiger’s food again, Tiger would remember the association between the can opener and her food—she would get excited and run to the kitchen when she heard the sound. The behavior of Pavlov’s dogs and Tiger illustrates a concept Pavlov called spontaneous recovery: the return of a previously extinguished conditioned response following a rest period (Figure 1).

[![A chart has an x-axis labeled “time” and a y-axis labeled “strength of CR;” there are four columns of graphed data. The first column is labeled “acquisition (CS + UCS) and the line rises steeply from the bottom to the top. The second column is labeled “Extinction (CS alone)” and the line drops rapidly from the top to the bottom. The third column is labeled “Pause” and has no line. The fourth column has a line that begins midway and drops sharply to the bottom. At the point where the line begins, it is labeled “Spontaneous recovery of CR”; the halfway point on the line is labeled “Extinction (CS alone).”](https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2016/11/30025615/f29b947cfc3a298595421b9e67bf0bdc40bc307c-300x166.jpeg)](https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2016/11/30025615/f29b947cfc3a298595421b9e67bf0bdc40bc307c.jpeg)

**Figure 1**. This is the curve of acquisition, extinction, and spontaneous recovery. The rising curve shows the conditioned response quickly getting stronger through the repeated pairing of the conditioned stimulus and the unconditioned stimulus (acquisition). Then the curve decreases, which shows how the conditioned response weakens when only the conditioned stimulus is presented (extinction). After a break or pause from conditioning, the conditioned response reappears (spontaneous recovery).

Of course, these processes also apply in humans. For example, let’s say that every day when you walk to campus, an ice cream truck passes your route. Day after day, you hear the truck’s music (neutral stimulus), so you finally stop and purchase a chocolate ice cream bar. You take a bite (unconditioned stimulus) and then your mouth waters (unconditioned response). This initial period of learning is known as acquisition, when you begin to connect the neutral stimulus (the sound of the truck) and the unconditioned stimulus (the taste of the chocolate ice cream in your mouth). During acquisition, the conditioned response gets stronger and stronger through repeated pairings of the conditioned stimulus and unconditioned stimulus. Several days (and ice cream bars) later, you notice that your mouth begins to water (conditioned response) as soon as you hear the truck’s musical jingle—even before you bite into the ice cream bar. Then one day you head down the street. You hear the truck’s music (conditioned stimulus), and your mouth waters (conditioned response). However, when you get to the truck, you discover that they are all out of ice cream. You leave disappointed. The next few days you pass by the truck and hear the music, but don’t stop to get an ice cream bar because you’re running late for class. You begin to salivate less and less when you hear the music, until by the end of the week, your mouth no longer waters when you hear the tune. This illustrates extinction. The conditioned response weakens when only the conditioned stimulus (the sound of the truck) is presented, without being followed by the unconditioned stimulus (chocolate ice cream in the mouth). Then the weekend comes. You don’t have to go to class, so you don’t pass the truck. Monday morning arrives and you take your usual route to campus. You round the corner and hear the truck again. What do you think happens? Your mouth begins to water again. Why? After a break from conditioning, the conditioned response reappears, which indicates spontaneous recovery.

Acquisition and extinction involve the strengthening and weakening, respectively, of a learned association. Two other learning processes—stimulus discrimination and stimulus generalization—are involved in determining which stimuli will trigger learned responses. Animals (including humans) need to distinguish between stimuli—for example, between sounds that predict a threatening event and sounds that do not—so that they can respond appropriately (such as running away if the sound is threatening). When an organism learns to respond differently to various stimuli that are similar, it is called **stimulus discrimination**. In classical conditioning terms, the organism demonstrates the conditioned response only to the conditioned stimulus. Pavlov’s dogs discriminated between the basic tone that sounded before they were fed and other tones (e.g., the doorbell), because the other sounds did not predict the arrival of food. Similarly, Tiger, the cat, discriminated between the sound of the can opener and the sound of the electric mixer. When the electric mixer is going, Tiger is not about to be fed, so she does not come running to the kitchen looking for food.

On the other hand, when an organism demonstrates the conditioned response to stimuli that are similar to the condition stimulus, it is called **stimulus generalization**, the opposite of stimulus discrimination. The more similar a stimulus is to the condition stimulus, the more likely the organism is to give the conditioned response. For instance, if the electric mixer sounds very similar to the electric can opener, Tiger may come running after hearing its sound. But if you do not feed her following the electric mixer sound, and you continue to feed her consistently after the electric can opener sound, she will quickly learn to discriminate between the two sounds (provided they are sufficiently dissimilar that she can tell them apart). In our other example, Moisha continued to feel ill whenever visiting other oncologists or other doctors in the same building as her oncologist.

## Classical Conditioning and Behaviorism

John B. Watson, shown in Figure 2, is considered the founder of behaviorism. Behaviorism is a school of thought that arose during the first part of the 20th century, which incorporates elements of Pavlov’s classical conditioning (Hunt, 2007). In stark contrast with Freud, who considered the reasons for behavior to be hidden in the unconscious, Watson championed the idea that all behavior can be studied as a simple stimulus-response reaction, without regard for internal processes. Watson argued that in order for psychology to become a legitimate science, it must shift its concern away from internal mental processes because mental processes cannot be seen or measured. Instead, he asserted that psychology must focus on outward observable behavior that can be measured.

![A photograph shows John B. Watson.](https://s3-us-west-2.amazonaws.com/courses-images-archive-read-only/wp-content/uploads/sites/902/2015/02/23224801/CNX_Psych_06_02_Watson.jpg)

**Figure 2**. John B. Watson used the principles of classical conditioning in the study of human emotion.

Watson’s ideas were influenced by Pavlov’s work. According to Watson, human behavior, just like animal behavior, is primarily the result of conditioned responses. Whereas Pavlov’s work with dogs involved the conditioning of reflexes, Watson believed the same principles could be extended to the conditioning of human emotions (Watson, 1919). Thus began Watson’s work with his graduate student Rosalie Rayner and a baby called Little Albert. Through their experiments with Little Albert, Watson and Rayner (1920) demonstrated how fears can be conditioned.

In 1920, Watson was the chair of the psychology department at Johns Hopkins University. Through his position at the university he came to meet Little Albert’s mother, Arvilla Merritte, who worked at a campus hospital (DeAngelis, 2010). Watson offered her a dollar to allow her son to be the subject of his experiments in classical conditioning. Through these experiments, Little Albert was exposed to and conditioned to fear certain things. Initially he was presented with various neutral stimuli, including a rabbit, a dog, a monkey, masks, cotton wool, and a white rat. He was not afraid of any of these things. Then Watson, with the help of Rayner, conditioned Little Albert to associate these stimuli with an emotion—fear. For example, Watson handed Little Albert the white rat, and Little Albert enjoyed playing with it. Then Watson made a loud sound, by striking a hammer against a metal bar hanging behind Little Albert’s head, each time Little Albert touched the rat. Little Albert was frightened by the sound—demonstrating a reflexive fear of sudden loud noises—and began to cry. Watson repeatedly paired the loud sound with the white rat. Soon Little Albert became frightened by the white rat alone. In this case, what are the UCS, CS, UCR, and CR? Days later, Little Albert demonstrated stimulus generalization—he became afraid of other furry things: a rabbit, a furry coat, and even a Santa Claus mask (Figure 3). Watson had succeeded in conditioning a fear response in Little Albert, thus demonstrating that emotions could become conditioned responses. It had been Watson’s intention to produce a phobia—a persistent, excessive fear of a specific object or situation— through conditioning alone, thus countering Freud’s view that phobias are caused by deep, hidden conflicts in the mind. However, there is no evidence that Little Albert experienced phobias in later years. Little Albert’s mother moved away, ending the experiment, and Little Albert himself died a few years later of unrelated causes. While Watson’s research provided new insight into conditioning, it would be considered unethical by today’s standards.

![A photograph shows a man wearing a mask with a white beard; his face is close to a baby who is crawling away. A caption reads, “Now he fears even Santa Claus.”](https://s3-us-west-2.amazonaws.com/courses-images-archive-read-only/wp-content/uploads/sites/902/2015/02/23224803/CNX_Psych_06_02_Santaclaus.jpg)

**Figure 3**. Through stimulus generalization, Little Albert came to fear furry things, including Watson in a Santa Claus mask.

### Link to Learning

View scenes from [John Watson’s experiment](https://www.youtube.com/watch?v=FMnhyGozLyE&list=TLijGHR5tdqJMrfg-LFJbKg-Qa4taw_Da-) in which Little Albert was conditioned to respond in fear to furry objects.

As you watch the video, look closely at Little Albert’s reactions and the manner in which Watson and Rayner present the stimuli before and after conditioning. Based on what you see, would you come to the same conclusions as the researchers?

### Everyday Connection: Advertising and Associative Learning

Advertising executives are pros at applying the principles of associative learning. Think about the car commercials you have seen on television. Many of them feature an attractive model. By associating the model with the car being advertised, you come to see the car as being desirable (Cialdini, 2008). You may be asking yourself, does this advertising technique actually work? According to Cialdini (2008), men who viewed a car commercial that included an attractive model later rated the car as being faster, more appealing, and better designed than did men who viewed an advertisement for the same car minus the model.

Have you ever noticed how quickly advertisers cancel contracts with a famous athlete following a scandal? As far as the advertiser is concerned, that athlete is no longer associated with positive feelings; therefore, the athlete cannot be used as an unconditioned stimulus to condition the public to associate positive feelings (the unconditioned response) with their product (the conditioned stimulus).

Now that you are aware of how associative learning works, see if you can find examples of these types of advertisements on television, in magazines, or on the Internet.

### Key Takeaways

**acquisition:** period of initial learning in classical conditioning in which a human or an animal begins to connect a neutral stimulus and an unconditioned stimulus so that the neutral stimulus will begin to elicit the conditioned response

**extinction:** decrease in the conditioned response when the unconditioned stimulus is no longer paired with the conditioned stimulus

**habituation:** when we learn not to respond to a stimulus that is presented repeatedly without change

**spontaneous recovery:** return of a previously extinguished conditioned response

**stimulus discrimination:** ability to respond differently to similar stimuli

**stimulus generalization:** demonstrating the conditioned response to stimuli that are similar to the conditioned stimulus

### Candela Citations

---

## Reinforcement and Punishment | Introduction to Psychology

- url_title:: "Reinforcement and Punishment | Introduction to Psychology"
  url_source:: https://courses.lumenlearning.com/waymaker-psychology/chapter/operant-conditioning/
### Learning Objectives

-   Explain the difference between reinforcement and punishment (including positive and negative reinforcement and positive and negative punishment)
-   Define shaping
-   Differentiate between primary and secondary reinforcers

In discussing operant conditioning, we use several everyday words—positive, negative, reinforcement, and punishment—in a specialized manner. In operant conditioning, positive and negative do not mean good and bad. Instead, _positive_ means you are adding something, and _negative_ means you are taking something away. _Reinforcement_ means you are increasing a behavior, and _punishment_ means you are decreasing a behavior. Reinforcement can be positive or negative, and punishment can also be positive or negative. All reinforcers (positive or negative) _increase_ the likelihood of a behavioral response. All punishers (positive or negative) _decrease_ the likelihood of a behavioral response. Now let’s combine these four terms: positive reinforcement, negative reinforcement, positive punishment, and negative punishment (Table 1).

<table><caption>Table 1. Positive and Negative Reinforcement and Punishment</caption><tbody><tr><th aria-label="no value"></th><th scope="col"><strong>Reinforcement</strong></th><th scope="col"><strong>Punishment</strong></th></tr><tr><th scope="row"><strong>Positive</strong></th><td>Something is <em data-effect="italics">added</em> to <em data-effect="italics">increase</em> the likelihood of a behavior.</td><td>Something is <em data-effect="italics">added</em> to <em data-effect="italics">decrease</em> the likelihood of a behavior.</td></tr><tr><th scope="row"><strong>Negative</strong></th><td>Something is <em data-effect="italics">removed</em> to <em data-effect="italics">increase</em> the likelihood of a behavior.</td><td>Something is <em data-effect="italics">removed</em> to <em data-effect="italics">decrease</em> the likelihood of a behavior.</td></tr></tbody></table>

## Reinforcement

The most effective way to teach a person or animal a new behavior is with positive reinforcement. In **positive reinforcement**, a desirable stimulus is added to increase a behavior.

For example, you tell your five-year-old son, Jerome, that if he cleans his room, he will get a toy. Jerome quickly cleans his room because he wants a new art set. Let’s pause for a moment. Some people might say, “Why should I reward my child for doing what is expected?” But in fact we are constantly and consistently rewarded in our lives. Our paychecks are rewards, as are high grades and acceptance into our preferred school. Being praised for doing a good job and for passing a driver’s test is also a reward. Positive reinforcement as a learning tool is extremely effective. It has been found that one of the most effective ways to increase achievement in school districts with below-average reading scores was to pay the children to read. Specifically, second-grade students in Dallas were paid $2 each time they read a book and passed a short quiz about the book. The result was a significant increase in reading comprehension (Fryer, 2010). What do you think about this program? If Skinner were alive today, he would probably think this was a great idea. He was a strong proponent of using operant conditioning principles to influence students’ behavior at school. In fact, in addition to the Skinner box, he also invented what he called a teaching machine that was designed to reward small steps in learning (Skinner, 1961)—an early forerunner of computer-assisted learning. His teaching machine tested students’ knowledge as they worked through various school subjects. If students answered questions correctly, they received immediate positive reinforcement and could continue; if they answered incorrectly, they did not receive any reinforcement. The idea was that students would spend additional time studying the material to increase their chance of being reinforced the next time (Skinner, 1961).

In **negative reinforcement**, an undesirable stimulus is removed to increase a behavior. For example, car manufacturers use the principles of negative reinforcement in their seatbelt systems, which go “beep, beep, beep” until you fasten your seatbelt. The annoying sound stops when you exhibit the desired behavior, increasing the likelihood that you will buckle up in the future. Negative reinforcement is also used frequently in horse training. Riders apply pressure—by pulling the reins or squeezing their legs—and then remove the pressure when the horse performs the desired behavior, such as turning or speeding up. The pressure is the negative stimulus that the horse wants to remove.

### Link to Learning

Watch this [clip from _The Big Bang Theory_](https://www.youtube.com/watch?v=LhI5h5JZi-U) to see Sheldon Cooper explain the commonly confused terms of negative reinforcement and punishment.

## Punishment

Many people confuse negative reinforcement with punishment in operant conditioning, but they are two very different mechanisms. Remember that reinforcement, even when it is negative, always increases a behavior. In contrast, **punishment** always decreases a behavior. In positive punishment, you add an undesirable stimulus to decrease a behavior. An example of **positive punishment** is scolding a student to get the student to stop texting in class. In this case, a stimulus (the reprimand) is added in order to decrease the behavior (texting in class). In **negative punishment**, you remove a pleasant stimulus to decrease a behavior. For example, when a child misbehaves, a parent can take away a favorite toy. In this case, a stimulus (the toy) is removed in order to decrease the behavior.

Punishment, especially when it is immediate, is one way to decrease undesirable behavior. For example, imagine your four year-old son, Brandon, hit his younger brother. You have Brandon write 50 times “I will not hit my brother” (positive punishment). Chances are he won’t repeat this behavior. While strategies like this are common today, in the past children were often subject to physical punishment, such as spanking. It’s important to be aware of some of the drawbacks in using physical punishment on children. First, punishment may teach fear. Brandon may become fearful of the hitting, but he also may become fearful of the person who delivered the punishment—you, his parent. Similarly, children who are punished by teachers may come to fear the teacher and try to avoid school (Gershoff et al., 2010). Consequently, most schools in the United States have banned corporal punishment. Second, punishment may cause children to become more aggressive and prone to antisocial behavior and delinquency (Gershoff, 2002). They see their parents resort to spanking when they become angry and frustrated, so, in turn, they may act out this same behavior when they become angry and frustrated. For example, because you spank Margot when you are angry with her for her misbehavior, she might start hitting her friends when they won’t share their toys.

While positive punishment can be effective in some cases, Skinner suggested that the use of punishment should be weighed against the possible negative effects. Today’s psychologists and parenting experts favor reinforcement over punishment—they recommend that you catch your child doing something good and reward them for it.

### Watch It

Make sure you understand the distinction between negative reinforcement and punishment in the following video:

You can [view the transcript for “Learning: Negative Reinforcement vs. Punishment” here (opens in new window)](https://oerfiles.s3-us-west-2.amazonaws.com/Psychology/Transcriptions/LearningNegativeReinforcementvsPunishment.txt).

Still confused? Watch the following short clip for another example and explanation of positive and negative reinforcement as well as positive and negative punishment.

You can [view the transcript for “Operant Conditioning” here (opens in new window)](https://oerfiles.s3-us-west-2.amazonaws.com/Psychology/Transcriptions/OperantConditioningRutherford.txt).

## Shaping

In his operant conditioning experiments, Skinner often used an approach called shaping. Instead of rewarding only the target behavior, in **shaping**, we reward successive approximations of a target behavior. Why is shaping needed? Remember that in order for reinforcement to work, the organism must first display the behavior. Shaping is needed because it is extremely unlikely that an organism will display anything but the simplest of behaviors spontaneously. In shaping, behaviors are broken down into many small, achievable steps. The specific steps used in the process are the following: Reinforce any response that resembles the desired behavior. Then reinforce the response that more closely resembles the desired behavior. You will no longer reinforce the previously reinforced response. Next, begin to reinforce the response that even more closely resembles the desired behavior. Continue to reinforce closer and closer approximations of the desired behavior. Finally, only reinforce the desired behavior.

Shaping is often used in teaching a complex behavior or chain of behaviors. Skinner used shaping to teach pigeons not only such relatively simple behaviors as pecking a disk in a Skinner box, but also many unusual and entertaining behaviors, such as turning in circles, walking in figure eights, and even playing ping pong; the technique is commonly used by animal trainers today. An important part of shaping is stimulus discrimination. Recall Pavlov’s dogs—he trained them to respond to the tone of a bell, and not to similar tones or sounds. This discrimination is also important in operant conditioning and in shaping behavior.

It’s easy to see how shaping is effective in teaching behaviors to animals, but how does shaping work with humans? Let’s consider parents whose goal is to have their child learn to clean his room. They use shaping to help him master steps toward the goal. Instead of performing the entire task, they set up these steps and reinforce each step. First, he cleans up one toy. Second, he cleans up five toys. Third, he chooses whether to pick up ten toys or put his books and clothes away. Fourth, he cleans up everything except two toys. Finally, he cleans his entire room.

## Primary and Secondary Reinforcers

Rewards such as stickers, praise, money, toys, and more can be used to reinforce learning. Let’s go back to Skinner’s rats again. How did the rats learn to press the lever in the Skinner box? They were rewarded with food each time they pressed the lever. For animals, food would be an obvious reinforcer.

What would be a good reinforce for humans? For your daughter Sydney, it was the promise of a toy if she cleaned her room. How about Joaquin, the soccer player? If you gave Joaquin a piece of candy every time he made a goal, you would be using a primary reinforcer. Primary reinforcers are reinforcers that have innate reinforcing qualities. These kinds of reinforcers are not learned. Water, food, sleep, shelter, sex, and touch, among others, are **primary reinforcers**. Pleasure is also a primary reinforcer. Organisms do not lose their drive for these things. For most people, jumping in a cool lake on a very hot day would be reinforcing and the cool lake would be innately reinforcing—the water would cool the person off (a physical need), as well as provide pleasure.

A **secondary reinforcer** has no inherent value and only has reinforcing qualities when linked with a primary reinforcer. Praise, linked to affection, is one example of a secondary reinforcer, as when you called out “Great shot!” every time Joaquin made a goal. Another example, money, is only worth something when you can use it to buy other things—either things that satisfy basic needs (food, water, shelter—all primary reinforcers) or other secondary reinforcers. If you were on a remote island in the middle of the Pacific Ocean and you had stacks of money, the money would not be useful if you could not spend it. What about the stickers on the behavior chart? They also are secondary reinforcers.

Sometimes, instead of stickers on a sticker chart, a token is used. Tokens, which are also secondary reinforcers, can then be traded in for rewards and prizes. Entire behavior management systems, known as token economies, are built around the use of these kinds of token reinforcers. Token economies have been found to be very effective at modifying behavior in a variety of settings such as schools, prisons, and mental hospitals. For example, a study by Cangi and Daly (2013) found that use of a token economy increased appropriate social behaviors and reduced inappropriate behaviors in a group of autistic school children. Autistic children tend to exhibit disruptive behaviors such as pinching and hitting. When the children in the study exhibited appropriate behavior (not hitting or pinching), they received a “quiet hands” token. When they hit or pinched, they lost a token. The children could then exchange specified amounts of tokens for minutes of playtime.

### Everyday Connection: Behavior Modification in Children

Parents and teachers often use behavior modification to change a child’s behavior. Behavior modification uses the principles of operant conditioning to accomplish behavior change so that undesirable behaviors are switched for more socially acceptable ones. Some teachers and parents create a sticker chart, in which several behaviors are listed (Figure 1). Sticker charts are a form of token economies, as described in the text. Each time children perform the behavior, they get a sticker, and after a certain number of stickers, they get a prize, or reinforcer. The goal is to increase acceptable behaviors and decrease misbehavior. Remember, it is best to reinforce desired behaviors, rather than to use punishment. In the classroom, the teacher can reinforce a wide range of behaviors, from students raising their hands, to walking quietly in the hall, to turning in their homework. At home, parents might create a behavior chart that rewards children for things such as putting away toys, brushing their teeth, and helping with dinner. In order for behavior modification to be effective, the reinforcement needs to be connected with the behavior; the reinforcement must matter to the child and be done consistently.

![A child placing stickers on a chart hanging on her wall.](https://s3-us-west-2.amazonaws.com/courses-images-archive-read-only/wp-content/uploads/sites/902/2015/02/23224805/CNX_Psych_06_03_Stickers.jpg)

**Figure 1**. Sticker charts are a form of positive reinforcement and a tool for behavior modification. Once this little girl earns a certain number of stickers for demonstrating a desired behavior, she will be rewarded with a trip to the ice cream parlor. (credit: Abigail Batchelder)

Time-out is another popular technique used in behavior modification with children. It operates on the principle of negative punishment. When a child demonstrates an undesirable behavior, she is removed from the desirable activity at hand (Figure 2). For example, say that Sophia and her brother Mario are playing with building blocks. Sophia throws some blocks at her brother, so you give her a warning that she will go to time-out if she does it again. A few minutes later, she throws more blocks at Mario. You remove Sophia from the room for a few minutes. When she comes back, she doesn’t throw blocks.

There are several important points that you should know if you plan to implement time-out as a behavior modification technique. First, make sure the child is being removed from a desirable activity and placed in a less desirable location. If the activity is something undesirable for the child, this technique will backfire because it is more enjoyable for the child to be removed from the activity. Second, the length of the time-out is important. The general rule of thumb is one minute for each year of the child’s age. Sophia is five; therefore, she sits in a time-out for five minutes. Setting a timer helps children know how long they have to sit in time-out. Finally, as a caregiver, keep several guidelines in mind over the course of a time-out: remain calm when directing your child to time-out; ignore your child during time-out (because caregiver attention may reinforce misbehavior); and give the child a hug or a kind word when time-out is over.

[![Photograph A shows several children climbing on playground equipment. Photograph B shows a child sitting alone on a bench.](https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2015/02/30164136/fc182656d0d3fddaaab2525040fa4dc752ba1249-300x151.jpeg)](https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2015/02/30164136/fc182656d0d3fddaaab2525040fa4dc752ba1249.jpeg)

**Figure 2**. Time-out is a popular form of negative punishment used by caregivers. When a child misbehaves, they are removed from a desirable activity in an effort to decrease the unwanted behavior. For example, (a) a child might be playing on the playground with friends and push another child; (b) the child who misbehaved would then be removed from the activity for a short period of time. (credit a: modification of work by Simone Ramella; credit b: modification of work by “Spring Dew”/Flickr)

### Try It

Review operant conditioning and the differences between reinforcement and punishment in the following interactive:

### Think It Over

-   Explain the difference between negative reinforcement and punishment, and provide several examples of each based on your own experiences.
-   Think of a behavior that you have that you would like to change. How could you use behavior modification, specifically positive reinforcement, to change your behavior? What is your positive reinforcer?

### Glossary

**negative punishment:** taking away a pleasant stimulus to decrease or stop a behavior

**negative reinforcement:** taking away an undesirable stimulus to increase a behavior

**positive punishment:** adding an undesirable stimulus to stop or decrease a behavior

**positive reinforcement:** adding a desirable stimulus to increase a behavior

**primary reinforcer:** has innate reinforcing qualities (e.g., food, water, shelter, sex)

**punishment:** implementation of a consequence in order to decrease a behavior

**reinforcement:** implementation of a consequence in order to increase a behavior

**secondary reinforcer:** has no inherent value unto itself and only has reinforcing qualities when linked with something else (e.g., money, gold stars, poker chips)

**shaping:** rewarding successive approximations toward a target behavior

### Candela Citations

CC licensed content, Original

-   Modification and adaptation, addition of Big Bang Learning example. **Provided by**: Lumen Learning. **License**: _[CC BY: Attribution](https://creativecommons.org/licenses/by/4.0/)_
-   Operant conditioning interactive. **Authored by**: Jessica Traylor for Lumen Learning. **Provided by**: Lumen Learning. **License**: _[CC BY: Attribution](https://creativecommons.org/licenses/by/4.0/)_

CC licensed content, Shared previously

-   Operant Conditioning. **Authored by**: OpenStax College. **Located at**: [https://openstax.org/books/psychology-2e/pages/6-3-operant-conditioning](https://openstax.org/books/psychology-2e/pages/6-3-operant-conditioning). **License**: _[CC BY: Attribution](https://creativecommons.org/licenses/by/4.0/)_. **License Terms**: Download for free at https://openstax.org/books/psychology-2e/pages/1-introduction

All rights reserved content

-   BF Skinner Foundation - Pigeon Ping Pong Clip. **Provided by**: bfskinnerfoundation. **Located at**: [https://www.youtube.com/watch?v=vGazyH6fQQ4](https://www.youtube.com/watch?v=vGazyH6fQQ4). **License**: _Other_. **License Terms**: Standard YouTube License
-   Learning: Negative Reinforcement vs. Punishment. **Authored by**: ByPass Publishing. **Located at**: [https://www.youtube.com/watch?v=imkbuKomPXI](https://www.youtube.com/watch?v=imkbuKomPXI). **License**: _Other_. **License Terms**: Standard YouTube License
-   Operant Conditioning. **Authored by**: Dr. Mindy Rutherford. **Located at**: [https://www.youtube.com/watch?v=LSHJbIJK9TI](https://www.youtube.com/watch?v=LSHJbIJK9TI). **License**: _Other_. **License Terms**: Standard YouTube License

---

## Reinforcement Schedules | Introduction to Psychology

- url_title:: "Reinforcement Schedules | Introduction to Psychology"
  url_source:: https://courses.lumenlearning.com/waymaker-psychology/chapter/reading-reinforcement-schedules/
### Learning Objectives

-   Distinguish between reinforcement schedules

Remember, the best way to teach a person or animal a behavior is to use positive reinforcement. For example, Skinner used positive reinforcement to teach rats to press a lever in a Skinner box. At first, the rat might randomly hit the lever while exploring the box, and out would come a pellet of food. After eating the pellet, what do you think the hungry rat did next? It hit the lever again, and received another pellet of food. Each time the rat hit the lever, a pellet of food came out. When an organism receives a reinforcer each time it displays a behavior, it is called **continuous reinforcement**. This reinforcement schedule is the quickest way to teach someone a behavior, and it is especially effective in training a new behavior. Let’s look back at the dog that was learning to sit earlier in the module. Now, each time he sits, you give him a treat. Timing is important here: you will be most successful if you present the reinforcer immediately after he sits, so that he can make an association between the target behavior (sitting) and the consequence (getting a treat).

Once a behavior is trained, researchers and trainers often turn to another type of reinforcement schedule—partial reinforcement. In **partial reinforcement**, also referred to as intermittent reinforcement, the person or animal does not get reinforced every time they perform the desired behavior. There are several different types of partial reinforcement schedules (Table 1). These schedules are described as either fixed or variable, and as either interval or ratio. _Fixed_ refers to the number of responses between reinforcements, or the amount of time between reinforcements, which is set and unchanging. _Variable_ refers to the number of responses or amount of time between reinforcements, which varies or changes. _Interval_ means the schedule is based on the time between reinforcements, and _ratio_ means the schedule is based on the number of responses between reinforcements.

Table 1. Reinforcement Schedules
| Reinforcement Schedule | Description | Result | Example |
| --- | --- | --- | --- |
| Fixed interval | Reinforcement is delivered at predictable time intervals (e.g., after 5, 10, 15, and 20 minutes). | Moderate response rate with significant pauses after reinforcement | Hospital patient uses patient-controlled, doctor-timed pain relief |
| Variable interval | Reinforcement is delivered at unpredictable time intervals (e.g., after 5, 7, 10, and 20 minutes). | Moderate yet steady response rate | Checking Facebook |
| Fixed ratio | Reinforcement is delivered after a predictable number of responses (e.g., after 2, 4, 6, and 8 responses). | High response rate with pauses after reinforcement | Piecework—factory worker getting paid for every x number of items manufactured |
| Variable ratio | Reinforcement is delivered after an unpredictable number of responses (e.g., after 1, 4, 5, and 9 responses). | High and steady response rate | Gambling |

Now let’s combine these four terms. A **fixed interval reinforcement schedule** is when behavior is rewarded after a set amount of time. For example, June undergoes major surgery in a hospital. During recovery, she is expected to experience pain and will require prescription medications for pain relief. June is given an IV drip with a patient-controlled painkiller. Her doctor sets a limit: one dose per hour. June pushes a button when pain becomes difficult, and she receives a dose of medication. Since the reward (pain relief) only occurs on a fixed interval, there is no point in exhibiting the behavior when it will not be rewarded.

With a **variable interval reinforcement schedule**, the person or animal gets the reinforcement based on varying amounts of time, which are unpredictable. Say that Manuel is the manager at a fast-food restaurant. Every once in a while someone from the quality control division comes to Manuel’s restaurant. If the restaurant is clean and the service is fast, everyone on that shift earns a $20 bonus. Manuel never knows when the quality control person will show up, so he always tries to keep the restaurant clean and ensures that his employees provide prompt and courteous service. His productivity regarding prompt service and keeping a clean restaurant are steady because he wants his crew to earn the bonus.

With a **fixed ratio reinforcement schedule**, there are a set number of responses that must occur before the behavior is rewarded. Carla sells glasses at an eyeglass store, and she earns a commission every time she sells a pair of glasses. She always tries to sell people more pairs of glasses, including prescription sunglasses or a backup pair, so she can increase her commission. She does not care if the person really needs the prescription sunglasses, Carla just wants her bonus. The quality of what Carla sells does not matter because her commission is not based on quality; it’s only based on the number of pairs sold. This distinction in the quality of performance can help determine which reinforcement method is most appropriate for a particular situation. Fixed ratios are better suited to optimize the quantity of output, whereas a fixed interval, in which the reward is not quantity based, can lead to a higher quality of output.

In a **variable ratio reinforcement schedule**, the number of responses needed for a reward varies. This is the most powerful partial reinforcement schedule. An example of the variable ratio reinforcement schedule is gambling. Imagine that Sarah—generally a smart, thrifty woman—visits Las Vegas for the first time. She is not a gambler, but out of curiosity she puts a quarter into the slot machine, and then another, and another. Nothing happens. Two dollars in quarters later, her curiosity is fading, and she is just about to quit. But then, the machine lights up, bells go off, and Sarah gets 50 quarters back. That’s more like it! Sarah gets back to inserting quarters with renewed interest, and a few minutes later she has used up all her gains and is $10 in the hole. Now might be a sensible time to quit. And yet, she keeps putting money into the slot machine because she never knows when the next reinforcement is coming. She keeps thinking that with the next quarter she could win $50, or $100, or even more. Because the reinforcement schedule in most types of gambling has a variable ratio schedule, people keep trying and hoping that the next time they will win big. This is one of the reasons that gambling is so addictive—and so resistant to extinction.

In operant conditioning, extinction of a reinforced behavior occurs at some point after reinforcement stops, and the speed at which this happens depends on the reinforcement schedule. In a variable ratio schedule, the point of extinction comes very slowly, as described above. But in the other reinforcement schedules, extinction may come quickly. For example, if June presses the button for the pain relief medication before the allotted time her doctor has approved, no medication is administered. She is on a fixed interval reinforcement schedule (dosed hourly), so extinction occurs quickly when reinforcement doesn’t come at the expected time. Among the reinforcement schedules, variable ratio is the most productive and the most resistant to extinction. Fixed interval is the least productive and the easiest to extinguish (Figure 1).

[![](https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2016/11/30165008/ea1c52f0df8e41b841c11f16dc0c6c78c55a6123-300x171.jpeg)](https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2016/11/30165008/ea1c52f0df8e41b841c11f16dc0c6c78c55a6123.jpeg)

**Figure 1**. The four reinforcement schedules yield different response patterns. The variable ratio schedule is unpredictable and yields high and steady response rates, with little if any pause after reinforcement (e.g., gambler). A fixed ratio schedule is predictable and produces a high response rate, with a short pause after reinforcement (e.g., eyeglass saleswoman). The variable interval schedule is unpredictable and produces a moderate, steady response rate (e.g., restaurant manager). The fixed interval schedule yields a scallop-shaped response pattern, reflecting a significant pause after reinforcement (e.g., surgery patient).

### Connect the Concepts: Gambling and the Brain

Skinner (1953) stated, “If the gambling establishment cannot persuade a patron to turn over money with no return, it may achieve the same effect by returning part of the patron’s money on a variable-ratio schedule” (p. 397).

![A photograph shows four digital gaming machines.](https://s3-us-west-2.amazonaws.com/courses-images-archive-read-only/wp-content/uploads/sites/902/2015/02/23224810/CNX_Psych_06_03_Gambling.jpg)

**Figure 2**. Some research suggests that pathological gamblers use gambling to compensate for abnormally low levels of the hormone norepinephrine, which is associated with stress and is secreted in moments of arousal and thrill. (credit: Ted Murphy)

Skinner uses gambling as an example of the power of the variable-ratio reinforcement schedule for maintaining behavior even during long periods without any reinforcement. In fact, Skinner was so confident in his knowledge of gambling addiction that he even claimed he could turn a pigeon into a pathological gambler (“Skinner’s Utopia,” 1971). It is indeed true that variable-ratio schedules keep behavior quite persistent—just imagine the frequency of a child’s tantrums if a parent gives in even once to the behavior. The occasional reward makes it almost impossible to stop the behavior.

Recent research in rats has failed to support Skinner’s idea that training on variable-ratio schedules alone causes pathological gambling (Laskowski et al., 2019). However, other research suggests that gambling does seem to work on the brain in the same way as most addictive drugs, and so there may be some combination of brain chemistry and reinforcement schedule that could lead to problem gambling (Figure 6.14). Specifically, modern research shows the connection between gambling and the activation of the reward centers of the brain that use the neurotransmitter (brain chemical) dopamine (Murch & Clark, 2016). Interestingly, gamblers don’t even have to win to experience the “rush” of dopamine in the brain. “Near misses,” or almost winning but not actually winning, also have been shown to increase activity in the ventral striatum and other brain reward centers that use dopamine (Chase & Clark, 2010). These brain effects are almost identical to those produced by addictive drugs like cocaine and heroin (Murch & Clark, 2016). Based on the neuroscientific evidence showing these similarities, the DSM-5 now considers gambling an addiction, while earlier versions of the DSM classified gambling as an impulse control disorder.

In addition to dopamine, gambling also appears to involve other neurotransmitters, including norepinephrine and serotonin (Potenza, 2013). Norepinephrine is secreted when a person feels stress, arousal, or thrill. It may be that pathological gamblers use gambling to increase their levels of this neurotransmitter. Deficiencies in serotonin might also contribute to compulsive behavior, including a gambling addiction (Potenza, 2013).

It may be that pathological gamblers’ brains are different than those of other people, and perhaps this difference may somehow have led to their gambling addiction, as these studies seem to suggest. However, it is very difficult to ascertain the cause because it is impossible to conduct a true experiment (it would be unethical to try to turn randomly assigned participants into problem gamblers). Therefore, it may be that causation actually moves in the opposite direction—perhaps the act of gambling somehow changes neurotransmitter levels in some gamblers’ brains. It also is possible that some overlooked factor, or confounding variable, played a role in both the gambling addiction and the differences in brain chemistry.

### Glossary

**continuous reinforcement:** rewarding a behavior every time it occurs

**fixed interval reinforcement schedule:** behavior is rewarded after a set amount of time

**fixed ratio reinforcement schedule:** set number of responses must occur before a behavior is rewarded

**operant conditioning:** form of learning in which the stimulus/experience happens after the behavior is demonstrated

**variable interval reinforcement schedule:** behavior is rewarded after unpredictable amounts of time have passed

**variable ratio reinforcement schedule:** number of responses differ before a behavior is rewarded

### Candela Citations

---

## Psych in Real Life: Latent Learning

- url_title:: "Psych in Real Life: Latent Learning"
  url_source:: https://courses.lumenlearning.com/waymaker-psychology/chapter/psych-in-real-life-latent-learning/
### Learning Objectives

-   Describe Edward Tolman’s experiment on latent learning

Edward Tolman was studying traditional trial-and-error learning when he realized that some of his research subjects (rats) actually knew more than their behavior initially indicated. In one of Tolman’s classic experiments, he observed the behavior of three groups of hungry rats that were learning to navigate mazes.

The **first group** always received a food reward at the end of the maze, so the payoff for learning the maze was real and immediate. The **second group** never received any food reward, so there was no incentive to learn to navigate the maze effectively. The **third group** was like the second group for the first 10 days, but on the 11th day, food was now placed at the end of the maze.

As you might expect when considering the principles of conditioning, the rats in the first group quickly learned to navigate the maze, while the rats of the second group seemed to wander aimlessly through it. The rats in the third group, however, although they wandered aimlessly for the first 10 days, quickly learned to navigate to the end of the maze as soon as they received food on day 11. By the next day, the rats in the third group had caught up in their learning to the rats that had been rewarded from the beginning. It was clear to Tolman that the rats that had been allowed to experience the maze, even without any reinforcement, had nevertheless learned something, and Tolman called this latent learning. **Latent learning** is _learning that is not reinforced and not demonstrated until there is motivation to do so_. Tolman argued that the rats had formed a “cognitive map” of the maze but did not demonstrate this knowledge until they received reinforcement.

[![A sample maze showing blue doors and green curtains that made it even tricker for a rat to know how to navigate the maze.](https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2017/03/08034423/Screen-Shot-2017-03-07-at-9.43.56-PM.png)](https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2017/03/08034423/Screen-Shot-2017-03-07-at-9.43.56-PM.png)

**Figure 1**. The maze. As you can see from the map, the maze had lots of doors and curtains to make it difficult for the rats to master. The blue marks represent doors that swung both directions, which prevented the rat from seeing most of the junctions as it approached. This forced the rat to go through the door to discover what was on the other side. The green forms show curtains. These hung down and prevented the rat from getting a long distance perspective and it also meant that they could not see a wall at the end of a wrong turn until they had already made a choice and moved in that direction. The rat was always in a small area, unable to see beyond the next door or curtain, so learning the maze was a formidable task.

[![3 graphs depicting the three groups in Tolman's experiment: food on every trial group, the no food until trial 11 group, and the no food on any trial group. Each of the groups took 30 wrong turns on their first trial.](https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2017/03/14165855/Screen-Shot-2017-04-14-at-12.58.34-PM.png)](https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2017/03/14165855/Screen-Shot-2017-04-14-at-12.58.34-PM.png)

[![3 graphs depicting the three groups in Tolman's experiment: Group 1: food on every trial, Group 2: no food until trial 11, and Group 3: no food on any trial. There is a dotted horizontal line on each graph at number of wrong turns equal to 15. Group one shows the number of wrong turns decreasing with each additional trial down to 16 wrong turns on the sixth trial. Group two shows the number of wrong turns decreasing with each additional trial down to 21 wrong turns on the sixth trial. Group three shows the number of wrong turns decreasing with each additional trial down to 18 wrong turns by the sixth trial.](https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2017/03/14170238/Screen-Shot-2017-04-14-at-1.02.20-PM.png)](https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2017/03/14170238/Screen-Shot-2017-04-14-at-1.02.20-PM.png)

[![3 graphs depicting the three groups in Tolman's experiment: Group 1: food on every trial, Group 2: no food until trial 11, and Group 3: no food on any trial. This shows that group 1 continues to make fewer wrong turns with each additional trial, making only 8 wrong turns on trial 11. Group 2 makes 16 wrong turns on trial 11 and group 3 makes 16 wrong turns.](https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2017/03/14170618/Screen-Shot-2017-04-14-at-1.06.01-PM.png)](https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2017/03/14170618/Screen-Shot-2017-04-14-at-1.06.01-PM.png)

### Work It out

Your task here is to predict what is going to happen on Trial 12 for the “no food until Trial 11” group.

_Option A_: Notice that this result is the same as the “no food on any trial” group. So, if you choose option A, you think that they will not act differently now than they acted on the first 11 trials and they will continue to make a lot of wrong turns.

_Option B_: This option suggests that they are now motivated to learn the path to the food, but that they will do so in small steps, just as we have seen for all three groups up to this point. Option B says that they are moving in the direction of the “food on every trial” group, but that it will take some extra learning to get there.

_Option C_: This option says that they already know the path to the food and, now that they are motivated to get there, they will show that they already know just as much as the “food on every trial” group. Their performance on Trial 12 will be the same as the low-error performance of the “food on every trial” group.[![Three graphs depicting the options that the rats in the Group B: No Food until Trial 11 may choose for their 12th trial. Will they continue to make 16 wrong turns (graph A), will they improve and make 15 wrong turns (graph B), or will they improve dramatically and make just 5 wrong turns (graph C)?](https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2017/03/14170759/3-graphs.png)](https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2017/03/14170759/3-graphs.png)

[![3 graphs depicting the three groups in Tolman's experiment: Group 1: food on every trial, Group 2: no food until trial 11, and Group 3: no food on any trial. Group 1 makes 5 wrong turns on trial 12, group two makes 5 wrong turns on trial 12, and group 3 makes 16 wrong turns on trial 12.](https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2017/03/14170950/Screen-Shot-2017-04-14-at-1.09.29-PM.png)](https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2017/03/14170950/Screen-Shot-2017-04-14-at-1.09.29-PM.png)

[![3 graphs depicting the three groups in Tolman's experiment: Group 1: food on every trial, Group 2: no food until trial 11, and Group 3: no food on any trial. Group one shows the number of wrong turns decreasing down to 16 by the sixth trial. Group two gets slightly better, with about 21 wrong turns at the sixth trial, and Group 3 makes around 18 wrong turns at the sixth trial. By trial 15, group A and B improve to almost no wrong turns, while group 3 levels off at 16 wrong turns on trial 12, continuing to make 16 wrong turns in every additional trial.](https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2017/03/14171032/Screen-Shot-2017-04-14-at-1.10.18-PM.png)](https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2017/03/14171032/Screen-Shot-2017-04-14-at-1.10.18-PM.png)

### Candela Citations

---

## Psych in Real Life: The Bobo Doll Experiment

- url_title:: "Psych in Real Life: The Bobo Doll Experiment"
  url_source:: https://courses.lumenlearning.com/waymaker-psychology/chapter/psych-in-real-life-the-bobo-doll-experiment/
### Learning Objectives

-   Describe the process and results of Albert Bandura’s bobo doll experiment

Bandura studied the impact of an adult’s behavior on the behavior of children who saw them. One of his _independent variables_ was whether or not the adult was hostile or _aggressive_ toward the Bobo doll, so for some children the adults acted aggressively (treatment condition) and for others they did not (control condition 1) and for yet other children there were no adults at all (control condition 2). He was also interested to learn if the sex of the child and/or the sex of the adult model influenced what the child learned.

## Phase 1 of the Experiment: The Observation Phase

The observation phase of the experiment is when the children see the behavior of the adults. Each child was shown into a room where an adult was already sitting near the Bobo doll. The child was positioned so they could easily see the adult.

[![Image with clip art showing how the experimenter stood behind the glass of a see-through mirror to observe an adult who hit the bobo doll with the mallet, along with a child who played and observed in the same room.](https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2017/03/14172414/Screen-Shot-2017-04-14-at-1.23.51-PM.png)](https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2017/03/14172414/Screen-Shot-2017-04-14-at-1.23.51-PM.png)

**Figure 1**. Set-up of the Bobo Doll experiment.

## Phase 2 of the Experiment: Frustration

Dr. Bandura thought that the children might be a bit more likely to show aggressive behavior if they were frustrated. The second phase of the experiment was designed to produce this frustration. After a child had watched the adult in phase 1, they were taken to another room, one that also contained a lot of attractive, fun toys and was told that it was fine to play with the toys. As soon as the child started to enjoy playing with the toys, the experimenter said something.

## Phase 3 of the Experiment: The Testing Phase

After the child was told to stop playing with “the very best toys,” the experimenter said that they could play with _any_ of the toys in the _next_ room. Then the child was taken to a third room. This room contained a variety of toys. Many of the toys were engaging and interactive, but not the type that encouraged aggressive play. Critically, the Bobo doll and the hammer that the model had used in the first phase were now in this new playroom. The goal of this phase in the experiment was to see how the child would react without a model around.

The child was allowed to play freely for 20 minutes. Note that an adult did stay in the room so the child would not feel abandoned or frightened. However, this adult worked inconspicuously in a corner and interacted with the child as little as possible.

During the 20 minutes that the child played alone in the third room, the experimenters observed their behavior from behind a see-through mirror. Using a complex system that we won’t go into here, the experimenters counted the number of various types of behaviors that the child showed during this period. These behaviors included ones directed at the Bobo doll, as well as those involving any of the other toys. They were particularly interested in the number of behaviors the child showed that clearly imitated the actions of the adults that the child had observed earlier, in phase 1.

Below are the results for the number of _imitative physically aggressive_ acts the children showed on average toward the Bobo doll. These acts included hitting and punching the Bobo doll. On the left, you see the two modeling conditions: aggression by the model in phase 1 or no aggression by the model in phase 1. Note: Children in the no-model conditions showed very few physically aggressive acts and their results do not change the interpretation, so we will keep the results simple by leaving them out of the table.

Table 1. Physical aggression results from Bandura’s experiment

<table><tbody><tr><td aria-label="no value"></td><th scope="col"><strong>Male Model: Boys</strong></th><th scope="col"><strong>Male Model: Girls</strong></th><th scope="col"><strong>Female Model: Boys</strong></th><th scope="col"><strong>Female Model: Girls</strong></th></tr><tr><th scope="row"><strong>Aggression</strong></th><td>25.8</td><td>7.2</td><td>12.4</td><td>5.5</td></tr><tr><th scope="row"><strong>No Aggression</strong></th><td>1.5</td><td>0.0</td><td>0.2</td><td>2.5</td></tr></tbody></table>

The story is slightly, though not completely, different when we look at _imitative verbal_ aggression, rather than _physical_ aggression. The table below shows the number of _verbally aggressive_ statements by the boys and girls under different conditions in the experiment. Verbally aggressive statements were ones like the models had made: for example, “Sock him” and “Kick him down!”

Note: Just as was true for the physically aggressive acts, children in the no model conditions showed very few verbally aggressive acts either and their results do not change the interpretation, so we will keep the results simple by leaving them out of the table.

**Table 2**. Verbal aggression results from Bandura’s experiment

<table><tbody><tr><td aria-label="no value"></td><th scope="col"><strong>Male Model: Boys</strong></th><th scope="col"><strong>Male Model: Girls</strong></th><th scope="col"><strong>Female Model: Boys</strong></th><th scope="col"><strong>Female Model: Girls</strong></th></tr><tr><th scope="row"><strong>Aggression</strong></th><td>12.7</td><td>2.0</td><td>4.3</td><td>13.7</td></tr><tr><th scope="row"><strong>No Aggression</strong></th><td>0.0</td><td>0.0</td><td>1.1</td><td>0.3</td></tr></tbody></table>

### Candela Citations

---

## Putting It Together: Learning | Introduction to Psychology

- url_title:: "Putting It Together: Learning | Introduction to Psychology"
  url_source:: https://courses.lumenlearning.com/waymaker-psychology/chapter/putting-it-together-learning/
### Learning Objectives

In this module, you learned to

-   explain learning and the process of classical conditioning
-   explain operant conditioning, reinforcement, and punishment
-   describe latent learning and observational learning

Are you superstitious? If so, you are definitely not alone. There are quite a few famous athletes who have reported a long list of superstitious behaviors. Michael Jordan wore his University of North Carolina basketball shorts under his Chicago Bulls uniform, tennis superstar Serena Williams is known to bounce the ball five times before her first serve and two times before her second, basketballer Kevin Garnett (and many others since him) insist on eating peanut butter and jelly sandwiches before games. How might these behaviors be linked to the concepts you learned about conditioning in this module?

Curiously, even B.F. Skinner began to see signs of superstitious behavior in pigeons during his experiments. Pigeons, like humans, associate rewards with superstitious rituals when they see positive results. When pigeons looked over their left shoulder (operant conditioning), they were hopeful that a reward would come, just as an athlete who wears the same lucky socks comes to associate the special socks with superior performance.

### WAtch IT

Research into superstition has shown that, even if the behaviors seem silly, they can be effective in improving performance, most likely due to the increased confidence and security people feel when they engage in these rituals.  

You can [view the transcript for “Superstitious Behavior – Pidgin Reward” here (opens in new window)](https://oerfiles.s3-us-west-2.amazonaws.com/Psychology/Transcriptions/SuperstitiousBehaviorPidginReward.txt).

Hopefully, you can continue to see and find examples of all types of conditioning in your life. From classically conditioned food aversions, operantly conditioned rewards, or surprising latent learning, there are applications of learning all around you.\[1\]

### Candela Citations

* * *

1.  DeLessio, Joe (2015, June 15). Why Superstitions Help Athletes Perform Better. Retrieved from [http://nymag.com/scienceofus/2015/06/why-superstitions-help-athletes-perform-better.html](http://nymag.com/scienceofus/2015/06/why-superstitions-help-athletes-perform-better.html) [↵](https://courses.lumenlearning.com/waymaker-psychology/chapter/putting-it-together-learning/#return-footnote-3063-1)

---

## Discussion: Learning | Introduction to Psychology

- url_title:: "Discussion: Learning | Introduction to Psychology"
  url_source:: https://courses.lumenlearning.com/waymaker-psychology/chapter/discussion-learning/
**Step 1:** To view this discussion prompt, click on [Discussion: Learning.](https://courses.lumenlearning.com/waymaker-psychology/chapter/discussion-learning-2/)

**Step 2:** Read the prompt and instructions, then post your response and comments inside of the discussion forum.

### Candela Citations

CC licensed content, Original

-   Discussion: Learning. **Provided by**: Lumen Learning. **License**: _[CC BY: Attribution](https://creativecommons.org/licenses/by/4.0/)_

---

## Psych in Real Life: Habits

- url_title:: "Psych in Real Life: Habits"
  url_source:: https://courses.lumenlearning.com/waymaker-psychology/chapter/psychology-in-real-life-habits/
### Learning Objectives

-   Examine the importance of habitual behavior in our daily lives

## Habits: The Good, the Bad, and the Consequences

Think back across the last hour. What have you been doing?

Which of the last hour’s activities were habitual—done at particular times of the day on a predictable schedule? How much of the time were you “on automatic”, guided by well-practiced routines that require little thought? Often, as we drive a car or walk to our workplace, work out at the gym or shop for groceries, our actions are unconscious and stereotyped as we think about something unrelated to what we are doing.

Habits have gotten a bad reputation in popular literature. Eating too much and chatting online too much and so many other things we supposedly do too much are blamed on “bad habits”. And, in a world that prizes novelty and creativity, the idea that habits are “automatic” suggests that we may be going through life like zombies, not mindful and not experiencing our lives deeply enough.

But habits can be positive, too. Writer Gretchen Rubin notes that “habits are the invisible architecture of our daily lives…Our habits shape our existence, and our future. If we change our habits, we change our lives.”\[1\] Habits free us from always having to plan our next action and use willpower to get things done.

Habits may be “automatic” in the sense that they free up our conscious minds to think about other things, but they can be changed and they can be chosen. For millennia, religious teachers and moral philosophers have urged us to choose who we wish to be by shaping our own habits. We don’t become better by trying harder; we become better by eliminating the need to try—we just do it.

## How Much of Your Time is Guided by Habits?

One obvious way to find out what people do during the day is to ask them. In fact, pause to do that now. How much time do you think you spend in habit-driven activities? What percentage would you say, between 0 and 100%?

You probably found that it is not easy to come up with a number here. What counts as a “habit”? And how well can we remember how long we were engaged in one activity or another? It is easier to remember interesting things than dull things, so there may be built-in biases in our memories to recall the engaging activities rather than the repetitive, habitual ones.

### The Diary Method

Wood, Quinn, and Kashy (2002) used a different approach, one that did not rely so much on memory: the diary method. They didn’t invent this research approach, but they were the first to apply it to the study of habits. This method doesn’t really involve keeping a diary in the traditional sense. Instead, it involves periodically “sampling” people’s activities along with some personal reflections on what they are doing.

Here is how it worked. Wood and her colleagues recruited college students and provided each one with a programmed wristwatch that buzzed once every hour. When the wristwatch\[2\] buzzed, the student recorded what they were doing. Then, the student answered a series of questions about this activity:

-   How often they engaged in that behavior.
-   Their current physical location.
-   The physical location in which they generally performed the behavior.
-   Which other people—if any—were involved in the activity.
-   The amount of attention needed for successful performance (1 to 4: almost none to constant attention)
-   The degree of difficulty of the behavior (1 to 5: very easy to very difficult)
-   The intensity of emotions felt as they engaged in the activity (1 to 5: much more negative than normal to much more positive than normal)

They also answered an open-ended question: what were you thinking about while you were engaged in the activity?

### The Results of the Diary Study

The researchers analyzed the “diary” reports of 279 students across two version of this study. When they defined “habitual behaviors” as activities that regularly occurred at the same time and place, they found that 41% of the behaviors could be considered habitual. If this result actually generalizes the rest of us, then nearly half of our time is spent engaging in habit-driven activities.

In a separate analysis, the researchers approached the idea of a habit in a different way. They reasoned that if habits are somewhat automatic, then we can think about something else while we are engaged in the habitual behaviors. Because they asked the students what they were doing and what they were thinking about, the researchers were able to determine how often there was a mismatch between behavior and thoughts. Approximately 47% of the time, thoughts were about something other than what they were doing, a percentage very close to the 43% estimate from the previous paragraph. However, even though the data support the idea that we can and often do think about other things while engaging in habitual behaviors, we are not zombies—about 40% of the time, people were thinking about activities they labeled as habits while engaging in them. The experimenters explain that this is “consistent with the idea that this mode of behavior is best characterized by minimal or sporadic cognitive monitoring and not by the complete absence of thought.”\[3\]

The researchers report one other interesting finding about habitual behaviors. When people engaged in habitual behaviors they reported lower negative emotions than when they were performing non-habitual activities. Specifically, habitual behaviors were associated with lower stress, reduced likelihood of feeling overwhelmed, and lower probability of feeling out of control. Happily, people did not feel less interested or less motivated while engaging in habitual behaviors, so reduced emotional reactions were not caused by becoming disengaged or less attentive.

## Studying Habits by Changing Them

An important insight about habits is that they are activated by triggers in the environment. These triggers can be people or places, events or the time of day. The important idea is that we have learned to respond to something outside of us (i.e., the trigger) with a specific behavior (the habit). We will come back to this idea that the situation initiates the habitual behavior later when we talk about changing your own habits, but first we will look at a set of studies by Wendy Wood, David Neal, and their colleagues. This is just one of many studies of habits that these and other researchers have conducted. It will give you an idea of how we can learn more about psychological processes by manipulating the details of a common event to see how people’s behavior changes.

### The Popcorn Study

[![Popcorn in a popcorn holder.](https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2018/03/02203557/popcorn-in-box_800-300x225.jpg)](https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2018/03/02203557/popcorn-in-box_800.jpg)

**Figure 1**. Are you a habitual popcorn eater?

Movie theater attendance is on the decline in the United States, but going to the movies is still popular. Of course, we go to the theater to see the movie, but for many people the experience is just not complete without the right refreshments: popcorn, candy, and soft drinks. You may be too health-conscious to buy these snacks, but most movie theaters depend on their concession stands to stay open.\[4\] Eating popcorn in a movie theater is a great example of a habit: a behavior that is triggered by a particular setting—the movie theater.

In 2011, David Neal, Wendy Wood, and some of their students published a study in which they used the movie theater-popcorn connection to study habitual behaviors.\[5\] They looked for evidence that movie theaters really do trigger eating popcorn. But checking out the validity of that claim was just the starting point for studying the popcorn habit.

#### The Setup

[![The inside of a movie theater.](https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2018/03/02203904/Toyogeki-Movie_Toyooka002-300x199.jpg)](https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2018/03/02203904/Toyogeki-Movie_Toyooka002.jpg)

**Figure 2**. Researchers set out to test whether students would eat more popcorn in a movie-theater room, like this one, or in a regular meeting room.

The experiments were conducted on the campus of the University of Southern California (USC). The campus has a cinema that regularly shows films that are popular among students.\[6\] They recruited students and assigned them to one of two conditions. In the Cinema condition, the students went into the theater before the regular movie started and they watched and rated movie trailers. The important thing to understand is that the setting looked, sounded, smelled, and felt like a movie theater (which, of course, it was).

Other students were recruited to come, at the same time of day, to a meeting room near the movie theater. These students were asked to listen to watch and rate music videos. The music videos had been pretested to assure that they were as interesting and engaging as the movie trailers that the cinema group watched. For this meeting room condition, the room was as comfortable as the theater and the task was as engaging as the one in the theater, but the location did not look or sound, smell or feel like a movie theater. It was a meeting room.

Next came the critical prop for this experiment: a full box of popcorn was given to each person, along with a cup of water. No one made a big deal about the popcorn, but (unknown to the participants) the main question was: how much popcorn would people eat?

### Try It

Where do you think the participants ate more popcorn: in the cinema or in the meeting room? Move the bars below to give your estimate of the percentage of the box of popcorn (this is the percentage number on the Y-axis) that was eaten—on the average—by the participants in each location.

Click here to see the results.

The first question was the easy one. But we left out a crucial piece of information: half of the participants in each location had nice fresh popcorn, but the other half had rubbery, stale popcorn. Now, how much fresh or stale popcorn do you think participants ate in the two locations?

### Try It

Now adjust the bar graphs to give your estimate of the percentage of the box of popcorn that was eaten—on the average—by the participants in each location. Brown represents stale popcorn and yellow represents fresh popcorn.

Click here to see the results.

Now perhaps the people in the cinema just didn’t notice that the stale popcorn was stale. Fortunately, the experimenters anticipated that question, so they asked the students to rate the taste of the popcorn. Here is what they found:

[![Results of the question, "how much did you like the popcorn?" on a seven point scale? In the cinema, stale popcorn tasters gave it a 2.6, and the fresh popcorn eaters gave it a 3.5. In the meeting room, stale-eaters gave it a 3, and fresh eaters gave it a 3.5.](https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2018/03/29195926/Screen-Shot-2018-10-29-at-2.58.25-PM.png)](https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2018/03/29195926/Screen-Shot-2018-10-29-at-2.58.25-PM.png)

**Figure 3**. Researchers found that students in both conditions rated the popcorn pretty low, and many students who didn’t like the stale popcorn still ate it.

There was no statistically significant difference in the ratings between the cinema and meeting room groups. But notice that, if anything, the cinema subjects rated the stale popcorn tasted as being slightly worse than the meeting room subjects did. The subjects in the cinema knew that the stale popcorn tasted bad, but they still ate it.

Are we sure that habit had something to do with this behavior? The experimenters asked participants to rate the strength of their own habit of eating popcorn in movie theaters. Of course, some people didn’t like popcorn much, while others wouldn’t think of going to the movies and skipping the popcorn. The experimenters divided the participants into three groups, based on their ratings of the strength of their popcorn-at-the-movies habit. Here is what they found for the subjects in the cinema condition:

[![Bar graph showing popcorn eating habit strength of weak, medium, or strong on the x-axis and the percentage of popcorn eaten on the y-axis. Those with weak habits ate 45% of the stale popcorn and 70% fresh. With medium habits, they ate 50% of the stale and 60% of the fresh. And those with strong habits ate 65% of the stale and 60% of the fresh.](https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2018/03/29200137/Screen-Shot-2018-10-29-at-3.01.07-PM.png)](https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2018/03/29200137/Screen-Shot-2018-10-29-at-3.01.07-PM.png)

**Figure 4**. This shows those with either weak, medium, or strong popcorn-eating habits, and how much they ate in the cinema condition. Those with weak popcorn habits still ate a lot of fresh popcorn (the most, even!), but they ate the least amount of stale popcorn.

On the average, the three groups ate about the same amount of popcorn. But—once again—notice the difference between the brown (stale) and yellow (fresh) bars. Participants with weak movie-popcorn habits ate a lot of the fresh popcorn, but not much of the stale popcorn. The stale-fresh difference was smaller for the medium movie-popcorn habit group. And, for the students with a strong movie-popcorn habit, there was no significant difference in the amount of fresh versus stale popcorn consumed (with slightly more stale popcorn than fresh actually eaten!). The students with strong habits knew that the stale popcorn was nasty, but they still ate it as if it were fresh.

### Try It

What do you think happened in the meeting room? You already know that they ate less popcorn in general, and that they at less stale popcorn than fresh. But did habit strength affect them as much as it did for the folks in the cinema? Make your prediction using the bars below.

Click here to see the results.

These results are consistent with the idea that the cinema environment triggers the popcorn-eating habit. The habitual popcorn eater consumes popcorn in the triggering environment (here, the cinema setting) even if the popcorn is not worth eating. In a different environment (the meeting room) the habit is not triggered, so popcorn consumption is much more determined by its quality, regardless of the strength of that habit in the cinema setting.

## Breaking Bad Habits

The experimenters weren’t quite done. They had demonstrated that a habit cued by the right context can lead to behaviors that no one would consciously choose: like eating bad popcorn. However, they also wanted to know if interfering with the situation could reduce the power of the habit.

In a second study, the experimenters went back to the cinema. There was no meeting room condition. This time they wanted the cinema to trigger the popcorn habit, but they asked if changing some essential part of the habitual behavior would reduce its power.

Which hand do you use to hold the box of popcorn? Which hand do you use to grab a kernel or two and raise it (them) to your mouth? I hold the box with my left hand and feed myself with my right. Always.

For this study, the experimenters put a handle on the popcorn box and instructed half of the subjects to hold the box with their usual hand, and the other half to hold it with the other hand—the one they usually don’t use.\[7\]

The theory here is simple: If we change something about the habit, then we reduce its power. In turn, we become more aware of what we are doing—more guided by our conscious goals and less by our automatic sequences of behavior. Is that what happened?

### Results

As with the first study, the experimenters divided the subjects into those with weak, medium, and strong movie-popcorn habits. The participants ate less popcorn in this experiment than in the first one,\[8\] but the pattern of results was still interesting. Here is what happened when participants used their usual hands for holding the box and eating.

[![Figure showing popcorn eating behavior when using the typical hand in the cinema condition of the study. Those with weak habits ate about 15% of the stale popcorn and 30% of the fresh popcorn. Those with medium habits ate 30% of the stale popcorn and 33% of the fresh popcorn. Those with strong habits ate 45% of the stale popcorn and 40% of the fresh.](https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2018/03/30034303/Screen-Shot-2018-10-29-at-10.42.39-PM.png)](https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2018/03/30034303/Screen-Shot-2018-10-29-at-10.42.39-PM.png)

**Figure 5**. Those who used their typical hand when eating popcorn in the cinema condition were more likely to eat popcorn if they had strong popcorn-eating habits.

Notice that these results are very similar to the results of the first experiment, except that habit strength had a stronger influence on amount of popcorn consumed. Most importantly, at low habit strength, students ate less stale popcorn than fresh. At stronger habit strengths, the quality of the popcorn didn’t matter. They just ate a lot of it.

### Try It

But what happens in the cinema, with all of its cues for eating popcorn, when an important part of the habit is altered? Make your prediction by moving the bars in the figure below. Remember that the opposite hand condition is supposed to reduce the power of the habit. It just doesn’t feel the same.

Click here to see the results.

The second study is important for a practical reason. It suggests that the strength of a habit can be influenced by minor changes to our routine. Habits can be weakened and they can be eliminated. And that leads us to our final topic.

## How to Create Good Habits

Let’s imagine that you want to start a new habit. For example, maybe it is time to get into shape, so you decide that you want to run every afternoon before dinner.

No one can give you a guaranteed system for creating a new habit—or for breaking an unwanted habit. However, habit experts, like Dr. Wood and Dr. Neal—have some advice that comes from their research.

-   **Don’t believe simple formulas about making or breaking habits.** In 1960, a popular self-help book claimed that forming a habit takes 21 days.\[9\] If this is true, then you just need to be sure to run before dinner every day for three weeks and you’ve done it! In 2010, psychologist Pippa Lally found that this timeframe for creating a new habit takes, on the average 66 days. But Dr. Lally’s more important point is that many factors determine how long habit formation takes. Her research showed a range of times from 18 days to 254, estimates based on self-reports. New behaviors vary in complexity and people have a variety of motivations and goals, different personalities and social support systems. True habit formation is a long-term commitment, so plan to make a conscious effort for many months.
-   **Make your habit the default behavior for a particular time or place.** Habits are created from actions that are repeated frequently and in a particular context. This is particularly important on those days when your motivation is low—when you would rather sit at home than go out and run. But your brain is on your side in this. In a 2013 study, Neal and Wood found that, when we are tired or distracted, we avoid making decisions.\[10\] In other words, we go with the decision that is easier. If you make your new habit (running before dinner) your default behavior, it will be easier to just go out and run than to put in the effort to decide to do something else.
-   **New habits require effort**.
-   **Choose your cues**. This point is related to the previous one about creating a routine. Habits are associated with cues. This is very obvious with “bad habits” where we know that a particular smell makes us want to eat or just hearing the cellphone ring can take our attention away from something important that we are doing. If you want to create a habit, use cues to take over some of the effort. For the person wanting to run each day, let the ritual of changing out of your work clothes create a set of associations—the drawer with your running shorts or the closet with your shoes—that help you get out of the house and onto the trail.
-   **Make a habit to break a habit**. Old habits are hard to break. New habits can be hard to learn, but in general—assuming you stay motivated—it is easier to get rid of an unwanted habit by replacing it with something you want to do. You may like to drink a beer (or a soda or something else that isn’t water) when you get home from work. If taking that drink is a habit, you may find it hard to resist. But if you start your new running regimen, running as you get home from work, the unwanted habit will need to move aside. And every day that you don’t engage in the unwanted habit (because you are on your 5-mile run) it becomes weaker and easier to resist.

## Final Thoughts

At the beginning of this activity, we suggested that “habits are the invisible architecture of our daily lives.” A lot of our time is spent engaging in habitual activities, some good, some bad, and most of them useful for getting ourselves through the day. But we have also suggested that old habits can be changed and new habits can be chosen and learned. In fact, this area of psychology says that you can decide what kind of person you want to be, and there is a reasonable chance you can become that person. But it isn’t easy and it won’t happen over night.

### Candela Citations

* * *

1.  The quotation comes from her book about changing habits: Better than Before. [↵](https://courses.lumenlearning.com/waymaker-psychology/chapter/psychology-in-real-life-habits/#return-footnote-4860-1)
2.  Today, cell phones are likely to be used for diary studies, but in 2002, only about 60 of students had clamshell-style cell phones, and the “smart phones” were still 5 years in the future. [↵](https://courses.lumenlearning.com/waymaker-psychology/chapter/psychology-in-real-life-habits/#return-footnote-4860-2)
3.  Wood, Quinn, & Kashy (2002), page 1281. [↵](https://courses.lumenlearning.com/waymaker-psychology/chapter/psychology-in-real-life-habits/#return-footnote-4860-3)
4.  According to research reported in Stanford Business, 20% of theater revenue comes from food sales, but a whopping 40% of profits come from food. They suggest that the high price of these snacks helps keep ticket prices down. [https://www.gsb.stanford.edu/insights/why-does-movie-popcorn-cost-so-much](https://www.gsb.stanford.edu/insights/why-does-movie-popcorn-cost-so-much) [↵](https://courses.lumenlearning.com/waymaker-psychology/chapter/psychology-in-real-life-habits/#return-footnote-4860-4)
5.  David T. Neal, Wendy Wood, Mengju Wu, & David Kurlander (2011). The pull of the past: When do habits persist despite conflict with motives? Personality and Social Psychology Bulletin, 37(11), 1428-1437. [↵](https://courses.lumenlearning.com/waymaker-psychology/chapter/psychology-in-real-life-habits/#return-footnote-4860-5)
6.  This study was conducted in 2011. Habits change as social conventions change, so we can’t guarantee that the USC cinema is still a popular attraction on campus. [↵](https://courses.lumenlearning.com/waymaker-psychology/chapter/psychology-in-real-life-habits/#return-footnote-4860-6)
7.  Reports collected after the experiment indicated that most participants followed these instructions almost all of the time, and no one violated the instructions very often. Happily, most college students are willing to cooperate with researchers. [↵](https://courses.lumenlearning.com/waymaker-psychology/chapter/psychology-in-real-life-habits/#return-footnote-4860-7)
8.  This difference in average consumption is not discussed in the research article, and it might be nice to know why popcorn consumption was down in the second study. Nevertheless, the more important results was the difference between stale and fresh popcorn consumption in the three habit levels. [↵](https://courses.lumenlearning.com/waymaker-psychology/chapter/psychology-in-real-life-habits/#return-footnote-4860-8)
9.  Maxwell Maltz (1960) Psycho-Cybernetics. Prentice-Hall. [↵](https://courses.lumenlearning.com/waymaker-psychology/chapter/psychology-in-real-life-habits/#return-footnote-4860-9)
10.  David T. Neal, Wendy Wood, & A. Drolet. (2013). How do people adhere to goals when willpower is low? The profits (and pitfalls) of strong habits. Journal of Personality and Social Psychology, 10(4), 959-975. [↵](https://courses.lumenlearning.com/waymaker-psychology/chapter/psychology-in-real-life-habits/#return-footnote-4860-10)

---

