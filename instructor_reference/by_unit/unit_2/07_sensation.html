<!DOCTYPE html>
<html>
<head>
<title>07_sensation.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<h1 id="07sensation">07_sensation</h1>
<hr>
<h2 id="why-it-matters-sensation-and-perception">Why It Matters: Sensation and Perception</h2>
<ul>
<li>url_title:: &quot;Why It Matters: Sensation and Perception&quot;
url_source:: https://courses.lumenlearning.com/waymaker-psychology/chapter/introduction-12/
<img src="https://s3-us-west-2.amazonaws.com/courses-images-archive-read-only/wp-content/uploads/sites/902/2015/02/23224703/CNX_Psych_05_00_Senses.jpg" alt="A person playing a piano on the sidewalk near a busy intersection in a city."></li>
</ul>
<p><strong>Figure 1</strong>. If you were standing in the midst of this street scene, you would be absorbing and processing numerous pieces of sensory input. (credit: modification of work by Cory Zanker)</p>
<p>Imagine standing on a city street corner. You might be struck by movement everywhere as cars and people go about their business, by the sound of a street musician’s melody or a horn honking in the distance, by the smell of exhaust fumes or of food being sold by a nearby vendor, and by the sensation of hard pavement under your feet.</p>
<p>We rely on our sensory systems to provide important information about our surroundings. We use this information to successfully navigate and interact with our environment so that we can find nourishment, seek shelter, maintain social relationships, and avoid potentially dangerous situations. But while sensory information is critical to our survival, there is so much information available at any given time that we would be overwhelmed if we were forced to attend to all of it. In fact, we are aware of only a fraction of the sensory information taken in by our sensory systems at any given time.</p>
<p>This module will provide an overview of how sensory information is received and processed by the nervous system and how that affects our conscious experience of the world. We begin by learning the distinction between sensation and perception. Then we consider the physical properties of light and sound stimuli, along with an overview of the basic structure and function of the major sensory systems. The module will close with a discussion of a historically important theory of perception called the Gestalt theory. This theory attempts to explain some underlying principles of perception.</p>
<p>Module References</p>
<h3 id="candela-citations">Candela Citations</h3>
<hr>
<h2 id="introduction-to-hearing--introduction-to-psychology">Introduction to Hearing | Introduction to Psychology</h2>
<ul>
<li>url_title:: &quot;Introduction to Hearing | Introduction to Psychology&quot;
url_source:: https://courses.lumenlearning.com/waymaker-psychology/chapter/outcome-hearing/</li>
</ul>
<h2 id="what-youll-learn-to-do-explain-the-basics-of-hearing">What you’ll learn to do: explain the basics of hearing</h2>
<p><a href="https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2017/01/27190240/christian-1157044_1280.jpg"><img src="https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2017/01/27190240/christian-1157044_1280-1024x683.jpg" alt="Picture from a rock concert. A band plays on the stage with blue and purple lights shining down. Fans raise their hands in the audience."></a></p>
<p>Our auditory system converts pressure waves into meaningful sounds. This translates into our ability to hear the sounds of nature, to appreciate the beauty of music, and to communicate with one another through spoken language. This section will provide an overview of the basic anatomy and function of the auditory system. It will include a discussion of how the sensory stimulus is translated into neural impulses, where in the brain that information is processed, how we perceive pitch, and how we know where sound is coming from.</p>
<h3 id="learning-objectives">Learning Objectives</h3>
<ul>
<li>Describe the basic anatomy and function of the auditory system</li>
<li>Show how physical properties of sound waves are associated with perceptual experience</li>
<li>Explain how we encode and perceive pitch and localize sound</li>
<li>Describe types of hearing loss</li>
</ul>
<h3 id="candela-citations">Candela Citations</h3>
<hr>
<h2 id="introduction-to-other-senses--introduction-to-psychology">Introduction to Other Senses | Introduction to Psychology</h2>
<ul>
<li>url_title:: &quot;Introduction to Other Senses | Introduction to Psychology&quot;
url_source:: https://courses.lumenlearning.com/waymaker-psychology/chapter/outcome-other-senses/</li>
</ul>
<h2 id="what-youll-learn-to-do-describe-the-basic-anatomy-and-functions-of-taste-smell-touch-pain-and-the-vestibular-sense">What you’ll learn to do: describe the basic anatomy and functions of taste, smell, touch, pain, and the vestibular sense</h2>
<p><a href="https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2017/01/31152803/3027430438_02821f919d_z.jpg"><img src="https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2017/01/31152803/3027430438_02821f919d_z.jpg" alt="Image of a hand reaching out to touch a floating piece of flower or dust, in front of a blue sky background."></a></p>
<p>Vision and hearing have received an incredible amount of attention from researchers over the years. While there is still much to be learned about how these sensory systems work, we have a much better understanding of them than of our other sensory modalities. In this section, we will explore our chemical senses (taste and smell) and our body senses (touch, temperature, pain, balance, and body position).</p>
<h3 id="learning-objectives">Learning Objectives</h3>
<ul>
<li>Summarize the chemical process of taste and smell</li>
<li>Explain the receptors that respond to touch</li>
<li>Examine the experience of pain, including how expectations and context affect pain and touch experiences</li>
<li>Describe the basic functions of the vestibular, proprioceptive, and kinesthetic sensory systems</li>
</ul>
<h3 id="candela-citations">Candela Citations</h3>
<p>CC licensed content, Original</p>
<ul>
<li>The Other Senses. <strong>Authored by</strong>: OpenStax College. <strong>Located at</strong>: <a href="https://openstax.org/books/psychology-2e/pages/5-5-the-other-senses">https://openstax.org/books/psychology-2e/pages/5-5-the-other-senses</a>. <strong>License</strong>: <em><a href="https://creativecommons.org/licenses/by/4.0/">CC BY: Attribution</a></em>. <strong>License Terms</strong>: Download for free at https://openstax.org/books/psychology-2e/pages/1-introduction</li>
<li>Modification, adaptation, and original content. <strong>Provided by</strong>: Lumen Learning. <strong>License</strong>: <em><a href="https://creativecommons.org/licenses/by/4.0/">CC BY: Attribution</a></em></li>
</ul>
<p>CC licensed content, Shared previously</p>
<ul>
<li>Touch photo. <strong>Authored by</strong>: Wendy Longo. <strong>Located at</strong>: <a href="https://www.google.com/search?q=5+senses&amp;rlz=1C5CHFA_enUS727US727&amp;source=lnms&amp;tbm=isch&amp;sa=X&amp;ved=0ahUKEwjCwNPv1-zRAhUJj1QKHdLfC-EQ_AUICCgB&amp;biw=1255&amp;bih=743#tbs=sur:fc&amp;tbm=isch&amp;q=touch&amp;imgrc=D65TnqDgRi27_M%3A">https://www.google.com/search?q=5+senses&amp;rlz=1C5CHFA_enUS727US727&amp;source=lnms&amp;tbm=isch&amp;sa=X&amp;ved=0ahUKEwjCwNPv1-zRAhUJj1QKHdLfC-EQ_AUICCgB&amp;biw=1255&amp;bih=743#tbs=sur:fc&amp;tbm=isch&amp;q=touch&amp;imgrc=D65TnqDgRi27_M%3A</a>. <strong>License</strong>: <em><a href="https://creativecommons.org/licenses/by-nd/4.0/">CC BY-ND: Attribution-NoDerivatives</a></em></li>
</ul>
<hr>
<h2 id="introduction-to-sensation-and-perception">Introduction to Sensation and Perception</h2>
<ul>
<li>url_title:: &quot;Introduction to Sensation and Perception&quot;
url_source:: https://courses.lumenlearning.com/waymaker-psychology/chapter/outcome-sensation-and-perception/</li>
</ul>
<h2 id="what-youll-learn-to-do-differentiate-between-sensation-and-perception">What you’ll learn to do: differentiate between sensation and perception</h2>
<p><a href="https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2017/02/02212759/Signac_-_Portrait_de_Fe%CC%81lix_Fe%CC%81ne%CC%81on.jpg"><img src="https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2017/02/02212759/Signac_-_Portrait_de_Félix_Fénéon.jpg" alt="1890, Portrait of Félix Fénéon, Opus 217. Against the Enamel of a Background Rhythmic with Beats and Angles, Tones, and Tints, oil on canvas, 73.5 x 92.5 cm, Museum of Modern Art, New York City. Man in a suit holding a top hat is reaching out with a flower in his hand. The background is multicolored swirls."></a></p>
<p>Sensation and perception are two separate processes that are very closely related. Sensation is input about the physical world obtained by our sensory receptors, and perception is the process by which the brain selects, organizes, and interprets these sensations. In other words, senses are the physiological basis of perception. Perception of the same senses may vary from one person to another because each person’s brain interprets stimuli differently based on that individual’s learning, memory, emotions, and expectations.</p>
<h3 id="learning-objectives">LEARNING OBJECTIVES</h3>
<ul>
<li>Define sensation and explain its connection to the concepts of absolute threshold, difference threshold, and subliminal messages</li>
<li>Discuss the roles attention, motivation, and sensory adaptation play in perception</li>
</ul>
<h3 id="candela-citations">Candela Citations</h3>
<p>CC licensed content, Original</p>
<ul>
<li>Modification, adaptation, and original content. <strong>Provided by</strong>: Lumen Learning. <strong>License</strong>: <em><a href="https://creativecommons.org/licenses/by/4.0/">CC BY: Attribution</a></em></li>
</ul>
<p>CC licensed content, Shared previously</p>
<ul>
<li>Sensation versus Perception. <strong>Authored by</strong>: OpenStax College. <strong>Located at</strong>: <a href="https://openstax.org/books/psychology-2e/pages/5-1-sensation-versus-perception">https://openstax.org/books/psychology-2e/pages/5-1-sensation-versus-perception</a>. <strong>License</strong>: <em><a href="https://creativecommons.org/licenses/by/4.0/">CC BY: Attribution</a></em>. <strong>License Terms</strong>: Download for free at https://openstax.org/books/psychology-2e/pages/1-introduction</li>
<li>Introduction to Sensation. <strong>Provided by</strong>: Boundless. <strong>Located at</strong>: <a href="https://www.boundless.com/psychology/textbooks/boundless-psychology-textbook/sensation-and-perception-5/introduction-to-sensation-37/introduction-to-sensation-157-12692/">https://www.boundless.com/psychology/textbooks/boundless-psychology-textbook/sensation-and-perception-5/introduction-to-sensation-37/introduction-to-sensation-157-12692/</a>. <strong>Project</strong>: Boundless Psychology. <strong>License</strong>: <em><a href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA: Attribution-ShareAlike</a></em></li>
</ul>
<p>Public domain content</p>
<ul>
<li>Painting. <strong>Authored by</strong>: Paul Signac. <strong>Provided by</strong>: Wikimedia. <strong>Located at</strong>: <a href="https://en.wikipedia.org/wiki/Soci%C3%A9t%C3%A9_des_Artistes_Ind%C3%A9pendants#/media/File:Signac_-_Portrait_de_F%C3%A9lix_F%C3%A9n%C3%A9on.jpg">https://en.wikipedia.org/wiki/Soci%C3%A9t%C3%A9_des_Artistes_Ind%C3%A9pendants#/media/File:Signac_-_Portrait_de_F%C3%A9lix_F%C3%A9n%C3%A9on.jpg</a>. <strong>License</strong>: <em><a href="https://creativecommons.org/about/pdm">Public Domain: No Known Copyright</a></em></li>
</ul>
<hr>
<h2 id="introduction-to-vision--introduction-to-psychology">Introduction to Vision | Introduction to Psychology</h2>
<ul>
<li>url_title:: &quot;Introduction to Vision | Introduction to Psychology&quot;
url_source:: https://courses.lumenlearning.com/waymaker-psychology/chapter/outcome-vision/</li>
</ul>
<h2 id="what-youll-learn-to-do-explain-the-process-of-vision-and-how-people-see-color-and-depth">What you’ll learn to do: explain the process of vision and how people see color and depth</h2>
<p><img src="https://s3-us-west-2.amazonaws.com/courses-images-archive-read-only/wp-content/uploads/sites/902/2015/02/23224717/CNX_Psych_05_03_Eyes.jpg" alt="Several photographs of peoples’ eyes are shown."></p>
<p><strong>Figure 1</strong>. Our eyes take in sensory information that helps us understand the world around us. (credit “top left”: modification of work by “rajkumar1220″/Flickr”; credit “top right”: modification of work by Thomas Leuthard; credit “middle left”: modification of work by Demietrich Baker; credit “middle right”: modification of work by “kaybee07″/Flickr; credit “bottom left”: modification of work by “Isengardt”/Flickr; credit “bottom right”: modification of work by Willem Heerbaart)</p>
<p>The visual system constructs a mental representation of the world around us. This contributes to our ability to successfully navigate through physical space and interact with important individuals and objects in our environments. This section will provide an overview of the basic anatomy and function of the visual system. In addition, you’ll explore our ability to perceive color and depth.</p>
<h3 id="learning-objectives">Learning Objectives</h3>
<ul>
<li>Describe the basic anatomy of the visual system</li>
<li>Describe how light waves enable vision</li>
<li>Describe the trichromatic theory of color vision and the opponent-process theory</li>
<li>Describe how monocular and binocular cues are used in the perception of depth</li>
</ul>
<h3 id="candela-citations">Candela Citations</h3>
<hr>
<h2 id="what-is-sensation--introduction-to-psychology">What is Sensation? | Introduction to Psychology</h2>
<ul>
<li>url_title:: &quot;What is Sensation? | Introduction to Psychology&quot;
url_source:: https://courses.lumenlearning.com/waymaker-psychology/chapter/sensation-versus-perception/</li>
</ul>
<h3 id="learning-objectives">Learning Objectives</h3>
<ul>
<li>Define sensation and explain its connection to the concepts of absolute threshold, difference threshold, and subliminal messages</li>
</ul>
<p>What does it mean to sense something? Sensory receptors are specialized neurons that respond to specific types of stimuli. When sensory information is detected by a sensory receptor, <strong>sensation</strong> has occurred. For example, light that enters the eye causes chemical changes in cells that line the back of the eye. These cells relay messages, in the form of action potentials (as you learned when studying biopsychology), to the central nervous system. The conversion from sensory stimulus energy to action potential is known as <strong>transduction</strong>.</p>
<p>You have probably known since elementary school that we have five senses: vision, hearing (audition), smell (olfaction), taste (gustation), and touch (somatosensation). It turns out that this notion of five senses is oversimplified. We also have sensory systems that provide information about balance (the vestibular sense), body position and movement (proprioception and kinesthesia), pain (nociception), and temperature (thermoception).</p>
<p><a href="https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2017/01/26190242/3631956828_1a4c9c4d93_z.jpg"><img src="https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2017/01/26190242/3631956828_1a4c9c4d93_z-200x300.jpg" alt="small candlelight with black background."></a></p>
<p><strong>Figure 1</strong>. The absolute threshold for detecting light is greater than you probably imagined—the human eye can see a candle on a clear night up to 30 miles away!</p>
<p>The sensitivity of a given sensory system to the relevant stimuli can be expressed as an absolute threshold. <strong>Absolute threshold</strong> refers to the minimum amount of stimulus energy that must be present for the stimulus to be detected 50% of the time. Another way to think about this is by asking how dim can a light be or how soft can a sound be and still be detected half of the time. The sensitivity of our sensory receptors can be quite amazing. It has been estimated that on a clear night, the most sensitive sensory cells in the back of the eye can detect a candle flame 30 miles away (Okawa &amp; Sampath, 2007). Under quiet conditions, the hair cells (the receptor cells of the inner ear) can detect the tick of a clock 20 feet away (Galanter, 1962).</p>
<p>It is also possible for us to get messages that are presented below the threshold for conscious awareness—these are called <strong>subliminal messages</strong>. A stimulus reaches a physiological threshold when it is strong enough to excite sensory receptors and send nerve impulses to the brain: this is an absolute threshold. A message below that threshold is said to be subliminal: we receive it, but we are not consciously aware of it. Therefore, the message is sensed, but for whatever reason, it has not been selected for processing in working or short-term memory. Over the years there has been a great deal of speculation about the use of subliminal messages in advertising, rock music, and self-help audio programs. Research evidence shows that in laboratory settings, people can process and respond to information outside of awareness. But this does not mean that we obey these messages like zombies; in fact, hidden messages have little effect on behavior outside the laboratory (Kunst-Wilson &amp; Zajonc, 1980; Rensink, 2004; Nelson, 2008; Radel, Sarrazin, Legrain, &amp; Gobancé, 2009; Loersch, Durso, &amp; Petty, 2013).</p>
<h3 id="dig-deeper-nonconscious1-perception">Dig Deeper: NonCONscious[1] Perception</h3>
<p><a href="https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2017/01/26185844/prof.jpg"><img src="https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2017/01/26185844/prof-300x200.jpg" alt="Male professor with a graying beard writing on a whiteboard, wearing a sweater and glasses."></a></p>
<p><strong>Figure 2</strong>. Priming can be used to improve intellectual test performance. Research subjects primed with the stereotype of a professor – a sort of intellectual role model – outperformed those primed with an anti-intellectual stereotype. [Photo: Jeremy Wilburn]</p>
<p>These days, most scientific research on nonconscious processes (processing that occurs while we are awake, but unaware) is aimed at showing that people do not need consciousness for certain psychological processes or behaviors. One such example is attitude formation. The most basic process of attitude formation is through mere exposure (Zajonc, 1968). Merely perceiving a stimulus repeatedly, such as a brand on a billboard one passes every day or a song that is played on the radio frequently, renders it more positive. Interestingly, mere exposure does not require conscious awareness of the object of an attitude. In fact, <strong>mere-exposure effects</strong> occur even when novel stimuli are presented subliminally for extremely brief durations (e.g., Kunst-Wilson &amp; Zajonc, 1980). Intriguingly, in such subliminal mere-exposure experiments, participants indicate a preference for, or a positive attitude towards, stimuli they do not consciously remember being exposed to. Another example of modern research on nonconscious processes is research on <strong>priming</strong>. Priming generally relies on supraliminal stimuli, which means that the messaging may occur out of awareness, but it is still perceived, unlike subliminal messaging. Supraliminal messages are perceived by the conscious mind. For example, in one study, shoppers listened to either French or German music (the supraliminal messaging) while buying wine, and sales originating from either country were higher when music from that same country was played overhead.[2]In a well-known experiment by a research team led by the American psychologist John Bargh (Bargh, Chen, &amp; Burrows, 1996), half the participants were primed with the stereotype of the elderly by doing a language task (they had to make sentences on the basis of lists of words). These lists contained words commonly associated with the elderly (e.g., “old,” “bingo,” “walking stick,” “Florida”). The remaining participants received a language task in which the critical words were replaced by words not related to the elderly. After participants had finished they were told the experiment was over, but they were secretly monitored to see how long they took to walk to the nearest elevator. The primed participants took significantly longer. That is, after being exposed to words typically associated with being old, they behaved in line with the stereotype of old people: being slow. Such priming effects have been shown in other domains as well. For example, Dijksterhuis and van Knippenberg (1998) demonstrated that priming can improve intellectual performance. They asked their participants to answer 42 general knowledge questions taken from the game Trivial Pursuit. Under normal conditions, participants answered about 50% of the questions correctly. However, participants primed with the stereotype of professors—who are by most people seen as intelligent—managed to answer 60% of the questions correctly. Conversely, the performance of participants primed with the “dumb” stereotype of hooligans dropped to 40%. Both of these studies have had difficult times replicating, so it is worth noting that the conclusions reached may not be as powerful as originally reported.</p>
<p>Absolute thresholds are generally measured under incredibly controlled conditions in situations that are optimal for sensitivity. Sometimes, we are more interested in how much difference in stimuli is required to detect a difference between them. This is known as the <strong>just noticeable difference (jnd)</strong> or <strong>difference threshold</strong>. Unlike the absolute threshold, the difference threshold changes depending on the stimulus intensity. As an example, imagine yourself in a very dark movie theater. If an audience member were to receive a text message on her cell phone which caused her screen to light up, chances are that many people would notice the change in illumination in the theater. However, if the same thing happened in a brightly lit arena during a basketball game, very few people would notice. The cell phone brightness does not change, but its ability to be detected as a change in illumination varies dramatically between the two contexts. Ernst Weber proposed this theory of change in difference threshold in the 1830s, and it has become known as <strong>Weber’s law</strong>: The difference threshold is a constant fraction of the original stimulus, as the example illustrates. It is the idea that bigger stimuli require larger differences to be noticed. For example, it will be much harder for your friend to reliably tell the difference between 10 and 11 lbs. (or 5 versus 5.5 kg) than it is for 1 and 2 lbs.</p>
<h3 id="glossary">Glossary</h3>
<p><strong>absolute threshold:</strong> minimum amount of stimulus energy that must be present for the stimulus to be detected 50% of the time</p>
<p><strong>just noticeable difference:</strong> difference in stimuli required to detect a difference between the stimuli</p>
<p><strong>mere-exposure effects</strong>: the result of developing a more positive attitude towards a stimulus after repeated instances of mere exposure to it.</p>
<p><strong>priming</strong>: the process by which recent experiences increase a trait’s accessibility.</p>
<p><strong>sensation:</strong> what happens when sensory information is detected by a sensory receptor</p>
<p><strong>signal detection theory:</strong> change in stimulus detection as a function of current mental state</p>
<p><strong>subliminal message:</strong> message presented below the threshold of conscious awareness</p>
<p><strong>transduction:</strong> conversion from sensory stimulus energy to action potential</p>
<p><strong>Weber’s law</strong>: Ernst Weber’s discovery that the difference threshold is a constant fraction of the original stimulus and bigger stimuli require larger differences to be noticed</p>
<h3 id="candela-citations">Candela Citations</h3>
<p>CC licensed content, Original</p>
<ul>
<li>Modification, adaptation, addition of Dig Deeper. <strong>Provided by</strong>: Lumen Learning. <strong>License</strong>: <em><a href="https://creativecommons.org/licenses/by/4.0/">CC BY: Attribution</a></em></li>
<li>Details on nonconsciousness. <strong>Authored by</strong>: Cynthia Golledge. <strong>Provided by</strong>: Portland Community College. <strong>License</strong>: <em><a href="https://creativecommons.org/licenses/by/4.0/">CC BY: Attribution</a></em></li>
</ul>
<p>CC licensed content, Shared previously</p>
<ul>
<li>Sensation versus Perception. <strong>Authored by</strong>: OpenStax College. <strong>Located at</strong>: <a href="https://openstax.org/books/psychology-2e/pages/5-1-sensation-versus-perception">https://openstax.org/books/psychology-2e/pages/5-1-sensation-versus-perception</a>. <strong>License</strong>: <em><a href="https://creativecommons.org/licenses/by/4.0/">CC BY: Attribution</a></em>. <strong>License Terms</strong>: Download for free at https://openstax.org/books/psychology-2e/pages/1-introduction</li>
<li>Dig Deeper on the Unconscious and image. <strong>Authored by</strong>: Ap Dijksterhuis Radboud. <strong>Provided by</strong>: University Nijmegen. <strong>Located at</strong>: <a href="http://nobaproject.com/modules/the-unconscious">http://nobaproject.com/modules/the-unconscious</a>. <strong>Project</strong>: The Noba Project. <strong>License</strong>: <em><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA: Attribution-NonCommercial-ShareAlike</a></em></li>
<li>Sensation and Perception, last example on Weber's Law. <strong>Authored by</strong>: Adam John Privitera . <strong>Provided by</strong>: Chemeketa Community College. <strong>Located at</strong>: <a href="http://nobaproject.com/modules/sensation-and-perception">http://nobaproject.com/modules/sensation-and-perception</a>. <strong>Project</strong>: The Noba Project. <strong>License</strong>: <em><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA: Attribution-NonCommercial-ShareAlike</a></em></li>
<li>Candle in the dark. <strong>Authored by</strong>: pratanti. <strong>Located at</strong>: <a href="https://www.flickr.com/photos/pratanti/3631956828">https://www.flickr.com/photos/pratanti/3631956828</a>. <strong>Project</strong>: Flickr. <strong>License</strong>: <em><a href="https://creativecommons.org/licenses/by/4.0/">CC BY: Attribution</a></em></li>
</ul>
<hr>
<ol>
<li>Note that the term &quot;conscious&quot; generally refers to processing that occurs when we are awake. &quot;Nonconscious&quot; processing also occurs while awake, but below the level of awareness. This is similar to &quot;unconscious&quot; processing, which also occurs below the awareness threshold, but is more often used to describe those who are also not awake, as in, &quot;She was unconscious after the car crash.&quot; The terms nonconscious and unconscious are sometimes used interchangeably, however. <a href="https://courses.lumenlearning.com/waymaker-psychology/chapter/sensation-versus-perception/#return-footnote-142-1">↵</a></li>
<li>North, A &amp; Hargreaves, David &amp; McKendrick, Jennifer. (1999). The Influence of In-Store Music on Wine Selections. Journal of Applied Psychology. 84. 271-276. 10.1037/0021-9010.84.2.271. <a href="https://courses.lumenlearning.com/waymaker-psychology/chapter/sensation-versus-perception/#return-footnote-142-2">↵</a></li>
</ol>
<hr>
<h2 id="color-and-depth-perception--introduction-to-psychology">Color and Depth Perception | Introduction to Psychology</h2>
<ul>
<li>url_title:: &quot;Color and Depth Perception | Introduction to Psychology&quot;
url_source:: https://courses.lumenlearning.com/waymaker-psychology/chapter/reading-color-and-depth-perception/</li>
</ul>
<h3 id="learning-objectives">Learning Objectives</h3>
<ul>
<li>Describe the trichromatic theory of color vision and the opponent-process theory</li>
<li>Describe how monocular and binocular cues are used in the perception of depth</li>
</ul>
<p>We do not see the world in black and white; neither do we see it as two-dimensional (2-D) or flat (just height and width, no depth). Let’s look at how color vision works and how we perceive three dimensions (height, width, and depth).</p>
<h2 id="color-vision">Color Vision</h2>
<p>Normal-sighted individuals have three different types of cones that mediate <strong>color vision</strong>. Each of these cone types is maximally sensitive to a slightly different wavelength of light. According to the Young-Helmholtz <strong>trichromatic theory of color vision</strong>, shown in Figure 1, all colors in the spectrum can be produced by combining red, green, and blue. The three types of cones are each receptive to one of the colors.</p>
<p><a href="https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2016/10/29215942/a64eff29d4c7d338b9a588b7e5e195747c9e2c4b.jpeg"><img src="https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2016/10/29215942/a64eff29d4c7d338b9a588b7e5e195747c9e2c4b-300x209.jpeg" alt="A graph is shown with “sensitivity” plotted on the y-axis and “Wavelength” in nanometers plotted along the x-axis with measurements of 400, 500, 600, and 700. Three lines in different colors move from the base to the peak of the y axis, and back to the base. The blue line begins at 400 nm and hits its peak of sensitivity around 455 nanometers, before the sensitivity drops off at roughly the same rate at which it increased, returning to the lowest sensitivity around 530 nm . The green line begins at 400 nm and reaches its peak of sensitivity around 535 nanometers. Its sensitivity then decreases at roughly the same rate at which it increased, returning to the lowest sensitivity around 650 nm. The red line follows the same pattern as the first two, beginning at 400 nm, increasing and decreasing at the same rate, and it hits its height of sensitivity around 580 nanometers. Below this graph is a horizontal bar showing the colors of the visible spectrum."></a></p>
<p><strong>Figure 1</strong>. This figure illustrates the different sensitivities for the three cone types found in a normal-sighted individual. (credit: modification of work by Vanessa Ezekowitz)</p>
<h3 id="connect-the-concepts">Connect the concepts</h3>
<h2 id="colorblindness-a-personal-story"><strong>Colorblindness: A Personal Story</strong></h2>
<p>Several years ago, I dressed to go to a public function and walked into the kitchen where my 7-year-old daughter sat. She looked up at me, and in her most stern voice, said, “You can’t wear that.” I asked, “Why not?” and she informed me the colors of my clothes did not match. She had complained frequently that I was bad at matching my shirts, pants, and ties, but this time, she sounded especially alarmed. As a single father with no one else to ask at home, I drove us to the nearest convenience store and asked the store clerk if my clothes matched. She said my pants were a bright green color, my shirt was a reddish orange, and my tie was brown. She looked at my quizzically and said, “No way do your clothes match.” Over the next few days, I started asking my coworkers and friends if my clothes matched. After several days of being told that my coworkers just thought I had “a really unique style,” I made an appointment with an eye doctor and was tested (Figure 5.15). It was then that I found out that I was colorblind. I cannot differentiate between most greens, browns, and reds. Fortunately, other than unknowingly being badly dressed, my colorblindness rarely harms my day-to-day life.</p>
<p><a href="https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2016/10/10221122/21632351cd15e26896aa4e56c6f36100c9b380d4.jpeg"><img src="https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2016/10/10221122/21632351cd15e26896aa4e56c6f36100c9b380d4.jpeg" alt="The figure includes three large circles that are made up of smaller circles of varying shades and sizes. Inside each large circle is a number that is made visible only by its different color. The first circle has an orange number 12 in a background of green. The second color has a green number 74 in a background of orange. The third circle has a red and brown number 42 in a background of black and gray."></a></p>
<p><strong>Figure 2</strong>. The Ishihara test evaluates color perception by assessing whether individuals can discern numbers that appear in a circle of dots of varying colors and sizes.</p>
<p>Some forms of color deficiency are rare. Seeing in grayscale (only shades of black and white) is extremely rare, and people who do so only have rods, which means they have very low visual acuity and cannot see very well. The most common X-linked inherited abnormality is red-green color blindness (Birch, 2012). Approximately 8% of males with European Caucasian decent, 5% of Asian males, 4% of African males, and less than 2% of indigenous American males, Australian males, and Polynesian males have red-green color deficiency (Birch, 2012). Comparatively, only about 0.4% in females from European Caucasian descent have red-green color deficiency (Birch, 2012).</p>
<p>The trichromatic theory of color vision is not the only theory—another major theory of color vision is known as the <strong>opponent-process theory</strong>. According to this theory, color is coded in opponent pairs: black-white, yellow-blue, and green-red. The basic idea is that some cells of the visual system are excited by one of the opponent colors and inhibited by the other. So, a cell that was excited by wavelengths associated with green would be inhibited by wavelengths associated with red, and vice versa. One of the implications of opponent processing is that we do not experience greenish-reds or yellowish-blues as colors. Another implication is that this leads to the experience of negative afterimages. An <strong>afterimage</strong> describes the continuation of a visual sensation after removal of the stimulus. For example, when you stare briefly at the sun and then look away from it, you may still perceive a spot of light although the stimulus (the sun) has been removed. When color is involved in the stimulus, the color pairings identified in the opponent-process theory lead to a negative afterimage. You can test this concept using the flag in Figure 2.</p>
<p><img src="https://s3-us-west-2.amazonaws.com/courses-images-archive-read-only/wp-content/uploads/sites/902/2015/02/23224727/CNX_Psych_05_03_Afterimage.jpg" alt="An illustration shows a green flag with a thick, black-bordered yellow lines meeting slightly to the left of the center. A small white dot sits within the yellow space in the exact center of the flag."></p>
<p><strong>Figure 3</strong>. Stare at the white dot for 30–60 seconds and then move your eyes to a blank piece of white paper. What do you see? This is known as a negative afterimage, and it provides empirical support for the opponent-process theory of color vision.</p>
<p>But these two theories—the trichromatic theory of color vision and the opponent-process theory—are not mutually exclusive. Research has shown that they just apply to different levels of the nervous system. For visual processing on the retina, trichromatic theory applies: the cones are responsive to three different wavelengths that represent red, blue, and green. But once the signal moves past the retina on its way to the brain, the cells respond in a way consistent with opponent-process theory (Land, 1959; Kaiser, 1997).</p>
<h2 id="depth-perception">Depth Perception</h2>
<p>Our ability to perceive spatial relationships in three-dimensional (3-D) space is known as <strong>depth perception</strong>. With depth perception, we can describe things as being in front, behind, above, below, or to the side of other things.</p>
<p>Our world is three-dimensional, so it makes sense that our mental representation of the world has three-dimensional properties. We use a variety of cues in a visual scene to establish our sense of depth. Some of these are <strong>binocular cues</strong>, which means that they rely on the use of both eyes. One example of a binocular depth cue is <strong>binocular disparity</strong>, the slightly different view of the world that each of our eyes receives. To experience this slightly different view, do this simple exercise: extend your arm fully and extend one of your fingers and focus on that finger. Now, close your left eye without moving your head, then open your left eye and close your right eye without moving your head. You will notice that your finger seems to shift as you alternate between the two eyes because of the slightly different view each eye has of your finger.</p>
<p>A 3-D movie works on the same principle: the special glasses you wear allow the two slightly different images projected onto the screen to be seen separately by your left and your right eye. As your brain processes these images, you have the illusion that the leaping animal or running person is coming right toward you.</p>
<p>Although we rely on binocular cues to experience depth in our 3-D world, we can also perceive depth in 2-D arrays. Think about all the paintings and photographs you have seen. Generally, you pick up on depth in these images even though the visual stimulus is 2-D. When we do this, we are relying on a number of <strong>monocular cues</strong>, or cues that require only one eye. If you think you can’t see depth with one eye, note that you don’t bump into things when using only one eye while walking—and, in fact, we have more monocular cues than binocular cues.</p>
<h3 id="watch-it">Watch It</h3>
<p>The following video of anamorphic art demonstrates how we rely on these monocular cues to see depth, even when the depth is only imagined.</p>
<p>You can view the <a href="https://oerfiles.s3-us-west-2.amazonaws.com/Psychology/Transcriptions/AmazingAnamophicIllusions_alternative.txt">text alternative for “Amazing Anamorphic Illusions!” (opens in new window).</a></p>
<p>An example of a monocular cue would be what is known as <strong>linear perspective</strong>. Linear perspective refers to the fact that we perceive depth when we see two parallel lines that seem to converge in an image (Figure 3). Some other monocular depth cues are interposition, the partial overlap of objects, the relative size and closeness of images to the horizon, relative size, and the variation between light and shadow.</p>
<p><img src="https://s3-us-west-2.amazonaws.com/courses-images-archive-read-only/wp-content/uploads/sites/902/2015/02/23224729/CNX_Psych_05_03_LinPerspec.jpg" alt="A photograph shows an empty road that continues toward the horizon."></p>
<p><strong>Figure 4</strong>. We perceive depth in a two-dimensional figure like this one through the use of monocular cues like linear perspective, like the parallel lines converging as the road narrows in the distance. (credit: Marc Dalmulder)</p>
<h3 id="dig-deeper-stereoblindness">Dig Deeper: Stereoblindness</h3>
<p>Bruce Bridgeman was born with an extreme case of lazy eye that resulted in him being stereoblind, or unable to respond to binocular cues of depth. He relied heavily on monocular depth cues, but he never had a true appreciation of the 3-D nature of the world around him. This all changed one night in 2012 while Bruce was seeing a movie with his wife.</p>
<p>The movie the couple was going to see was shot in 3-D, and even though he thought it was a waste of money, Bruce paid for the 3-D glasses when he purchased his ticket. As soon as the film began, Bruce put on the glasses and experienced something completely new. For the first time in his life he appreciated the true depth of the world around him. Remarkably, his ability to perceive depth persisted outside of the movie theater.</p>
<p>There are cells in the nervous system that respond to binocular depth cues. Normally, these cells require activation during early development in order to persist, so experts familiar with Bruce’s case (and others like his) assume that at some point in his development, Bruce must have experienced at least a fleeting moment of binocular vision. It was enough to ensure the survival of the cells in the visual system tuned to binocular cues. The mystery now is why it took Bruce nearly 70 years to have these cells activated (Peck, 2012).</p>
<h2 id="integration-with-other-modalities">Integration with Other Modalities</h2>
<p>Vision is not an encapsulated system. It interacts with and depends on other sensory modalities. For example, when you move your head in one direction, your eyes reflexively move in the opposite direction to compensate, allowing you to maintain your gaze on the object that you are looking at. This reflex is called the <strong>vestibulo-ocular reflex</strong>. It is achieved by integrating information from both the visual and the vestibular system (which knows about body motion and position). You can experience this compensation quite simply. First, while you keep your head still and your gaze looking straight ahead, wave your finger in front of you from side to side. Notice how the image of the finger appears blurry. Now, keep your finger steady and look at it while you move your head from side to side. Notice how your eyes reflexively move to compensate the movement of your head and how the image of the finger stays sharp and stable. Vision also interacts with your proprioceptive system, to help you find where all your body parts are, and with your auditory system, to help you understand the sounds people make when they speak. You can learn more about this in the multimodal module.</p>
<p>Finally, vision is also often implicated in a blending-of-sensations phenomenon known as <strong>synesthesia</strong>. Synesthesia occurs when one sensory signal gives rise to two or more sensations. The most common type is <em>grapheme-color</em> synesthesia. About 1 in 200 individuals experience a sensation of color associated with specific letters, numbers, or words: the number 1 might always be seen as red, the number 2 as orange, etc. But the more fascinating forms of synesthesia blend sensations from entirely different sensory modalities, like taste and color or music and color: the taste of chicken might elicit a sensation of green, for example, and the timbre of violin a deep purple.</p>
<h3 id="sensation-and-perception">Sensation and PErception</h3>
<p>All of this talk about vision may have you wondering what this has to do with psychology. Remember that sensation is input about the physical world obtained by our sensory receptors, and perception is the process by which the brain selects, organizes, and interprets these sensations. In other words, senses are the physiological basis of perception. Perception of the same senses may vary from one person to another because each person’s brain interprets stimuli differently based on that individual’s learning, memory, emotions, and expectations. It is for this reason that psychologists study sensation—in order to understand perception, which is clearly a component of behavior and mental processes (the definition of psychology).</p>
<h3 id="think-it-over">Think It Over</h3>
<p>Take a look at a few of your photos or personal works of art. Can you find examples of linear perspective as a potential depth cue?</p>
<h3 id="glossary">Glossary</h3>
<p><strong>afterimage:</strong> continuation of a visual sensation after removal of the stimulus</p>
<p><strong>binocular cue:</strong> cue that relies on the use of both eyes</p>
<p><strong>binocular disparity:</strong> slightly different view of the world that each eye receives</p>
<p><strong>depth perception:</strong> ability to perceive depth</p>
<p><strong>linear perspective:</strong> perceive depth in an image when two parallel lines seem to converge</p>
<p><strong>monocular cue:</strong> cue that requires only one eye</p>
<p><strong>opponent-process theory of color perception:</strong> color is coded in opponent pairs: black-white, yellow-blue, and red-green</p>
<p><strong>synesthesia</strong>: the blending of two or more sensory experiences, or the automatic activation of a secondary (indirect) sensory experience due to certain aspects of the primary (direct) sensory stimulation.</p>
<p><strong>trichromatic theory of color perception:</strong> color vision is mediated by the activity across the three groups of cones</p>
<p><strong>vestibulo-ocular reflex:</strong> coordination of motion information with visual information that allows you to maintain your gaze on an object while you move.</p>
<h3 id="candela-citations">Candela Citations</h3>
<p>CC licensed content, Original</p>
<ul>
<li>Modification, adaptation, and original content. <strong>Provided by</strong>: Lumen Learning. <strong>License</strong>: <em><a href="https://creativecommons.org/licenses/by/4.0/">CC BY: Attribution</a></em>. <strong>License Terms</strong>: Download for free at http://cnx.org/contents/4abf04bf-93a0-45c3-9cbc-2cefd46e68cc@5.48</li>
</ul>
<p>CC licensed content, Shared previously</p>
<ul>
<li>Vision. <strong>Authored by</strong>: OpenStax College. <strong>Located at</strong>: <a href="https://openstax.org/books/psychology-2e/pages/5-3-vision">https://openstax.org/books/psychology-2e/pages/5-3-vision</a>. <strong>License</strong>: <em><a href="https://creativecommons.org/licenses/by/4.0/">CC BY: Attribution</a></em>. <strong>License Terms</strong>: Download for free at https://openstax.org/books/psychology-2e/pages/1-introduction</li>
<li>Integration with Other Modalities. <strong>Authored by</strong>: Simona Buetti and Alejandro Lleras. <strong>Provided by</strong>: University of Illinois. <strong>Located at</strong>: <a href="http://nobaproject.com/modules/vision">http://nobaproject.com/modules/vision</a>. <strong>Project</strong>: The Noba Project. <strong>License</strong>: <em><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA: Attribution-NonCommercial-ShareAlike</a></em></li>
<li>Introduction to Sensation. <strong>Provided by</strong>: Boundless. <strong>Located at</strong>: <a href="https://www.boundless.com/psychology/textbooks/alternative-to-study-guide-for-psychology-9th-david-g-myers-richard-o-straub-1429225343-9781429225342/sensation-and-perception-7/sensation-44/introduction-to-sensation-198-12692/">https://www.boundless.com/psychology/textbooks/alternative-to-study-guide-for-psychology-9th-david-g-myers-richard-o-straub-1429225343-9781429225342/sensation-and-perception-7/sensation-44/introduction-to-sensation-198-12692/</a>. <strong>License</strong>: <em><a href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA: Attribution-ShareAlike</a></em></li>
<li>Questions for perception activity. <strong>Provided by</strong>: Open Learning Initiative. <strong>Located at</strong>: <a href="https://oli.cmu.edu/jcourse/workbook/activity/page?context=df3e710c0a0001dc3d30772377a4018e">https://oli.cmu.edu/jcourse/workbook/activity/page?context=df3e710c0a0001dc3d30772377a4018e</a>. <strong>License</strong>: <em><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA: Attribution-NonCommercial-ShareAlike</a></em></li>
</ul>
<p>All rights reserved content</p>
<ul>
<li>Amazing Anamorphic Illusions. <strong>Authored by</strong>: brusspup. <strong>Located at</strong>: <a href="https://www.youtube.com/watch?v=tBNHPk-Lnkk">https://www.youtube.com/watch?v=tBNHPk-Lnkk</a>. <strong>License</strong>: <em>Other</em>. <strong>License Terms</strong>: Standard YouTube License</li>
</ul>
<hr>
<h2 id="how-we-hear--introduction-to-psychology">How We Hear | Introduction to Psychology</h2>
<ul>
<li>url_title:: &quot;How We Hear | Introduction to Psychology&quot;
url_source:: https://courses.lumenlearning.com/waymaker-psychology/chapter/hearing/</li>
</ul>
<h3 id="learning-objectives">Learning Objectives</h3>
<ul>
<li>Describe the basic anatomy and function of the auditory system</li>
<li>Explain how we encode and perceive pitch and localize sound</li>
</ul>
<p>Our auditory system converts pressure waves into meaningful sounds. This translates into our ability to hear the sounds of nature, to appreciate the beauty of music, and to communicate with one another through spoken language. This section will provide an overview of the basic anatomy and function of the auditory system. It will include a discussion of how the sensory stimulus is translated into neural impulses, where in the brain that information is processed, how we perceive pitch, and how we know where sound is coming from.</p>
<h2 id="anatomy-of-the-auditory-system">Anatomy of the Auditory System</h2>
<p>The ear can be separated into multiple sections. The outer ear includes the <strong>pinna</strong>, which is the visible part of the ear that protrudes from our heads, the auditory canal, and the <strong>tympanic membrane</strong>, or eardrum. The middle ear contains three tiny bones known as the <strong>ossicles</strong>, which are named the <strong>malleus</strong> (or hammer), <strong>incus</strong> (or anvil), and the <strong>stapes</strong> (or stirrup). The inner ear contains the semi-circular canals, which are involved in balance and movement (the vestibular sense), and the cochlea. The <strong>cochlea</strong> is a fluid-filled, snail-shaped structure that contains the sensory receptor cells (hair cells) of the auditory system (Figure 1).</p>
<p><img src="https://s3-us-west-2.amazonaws.com/courses-images-archive-read-only/wp-content/uploads/sites/902/2015/02/23224731/CNX_Psych_05_04_Ear.jpg" alt="An illustration shows sound waves entering the “auditory canal” and traveling to the inner ear. The locations of the “pinna,” “tympanic membrane (eardrum)” are labeled, as well as parts of the inner ear: the “ossicles” and its subparts, the “malleus,” “incus,” and “stapes.” A callout leads to a close-up illustration of the inner ear that shows the locations of the “semicircular canals,” “urticle,” “oval window,” “saccule,” “cochlea,” and the “basilar membrane and hair cells.”"></p>
<p><strong>Figure 1</strong>. The ear is divided into outer (pinna and tympanic membrane), middle (the three ossicles: malleus, incus, and stapes), and inner (cochlea and basilar membrane) divisions.</p>
<p>Sound waves travel along the auditory canal and strike the tympanic membrane, causing it to vibrate. This vibration results in movement of the three ossicles. As the ossicles move, the stapes presses into a thin membrane of the cochlea known as the oval window. As the stapes presses into the oval window, the fluid inside the cochlea begins to move, which in turn stimulates <strong>hair cells</strong>, which are auditory receptor cells of the inner ear embedded in the basilar membrane. The <strong>basilar membrane</strong> is a thin strip of tissue within the cochlea. Sitting on the basilar membrane is the organ of Corti, which runs the entire length of the basilar membrane from the base (by the oval window) to the apex (the “tip” of the spiral). The organ of Corti includes three rows of outer hair cells and one row of inner hair cells. The hair cells sense the vibrations by way of their tiny hairs, or stereocillia. The outer hair cells seem to function to mechanically amplify the sound-induced vibrations, whereas the inner hair cells form synapses with the auditory nerve and transduce those vibrations into action potentials, or neural spikes, which are transmitted along the auditory nerve to higher centers of the auditory pathways.</p>
<p>The activation of hair cells is a mechanical process: the stimulation of the hair cell ultimately leads to activation of the cell. As hair cells become activated, they generate neural impulses that travel along the auditory nerve to the brain. Auditory information is shuttled to the inferior colliculus, the medial geniculate nucleus of the thalamus, and finally to the auditory cortex in the temporal lobe of the brain for processing. Like the visual system, there is also evidence suggesting that information about auditory recognition and localization is processed in parallel streams (Rauschecker &amp; Tian, 2000; Renier et al., 2009).</p>
<h2 id="sound-waves">Sound Waves</h2>
<p>As mentioned above, the vibration of the tympanic membrane is what triggers the sequence of events that lead to our perception of sound. Sound waves travel into our ears at various speeds and amplitudes. Like light waves, the physical properties of sound waves are associated with various aspects of our perception of sound. The frequency of a sound wave is associated with our perception of that sound’s <strong>pitch</strong>. High-frequency sound waves are perceived as high-pitched sounds, while low-frequency sound waves are perceived as low-pitched sounds. The audible range of sound frequencies is between 20 and 20000 Hz, with greatest sensitivity to those frequencies that fall in the middle of this range.</p>
<p>As was the case with the visible spectrum, other species show differences in their audible ranges. For instance, chickens have a very limited audible range, from 125 to 2000 Hz. Mice have an audible range from 1000 to 91000 Hz, and the beluga whale’s audible range is from 1000 to 123000 Hz. Our pet dogs and cats have audible ranges of about 70–45000 Hz and 45–64000 Hz, respectively (Strain, 2003).</p>
<p>The loudness of a given sound is closely associated with the amplitude of the sound wave. Higher amplitudes are associated with louder sounds. Loudness is measured in terms of decibels (dB), a logarithmic unit of sound intensity. A typical conversation would correlate with 60 dB; a rock concert might check in at 120 dB (Figure 5.9). A whisper 5 feet away or rustling leaves are at the low end of our hearing range; sounds like a window air conditioner, a normal conversation, and even heavy traffic or a vacuum cleaner are within a tolerable range. However, there is the potential for hearing damage from about 80 dB to 130 dB: These are sounds of a food processor, power lawnmower, heavy truck (25 feet away), subway train (20 feet away), live rock music, and a jackhammer. About one-third of all hearing loss is due to noise exposure, and the louder the sound, the shorter the exposure needed to cause hearing damage (Le, Straatman, Lea, &amp; Westerberg, 2017). Listening to music through earbuds at maximum volume (around 100–105 decibels) can cause noise-induced hearing loss after 15 minutes of exposure. Although listening to music at maximum volume may not seem to cause damage, it increases the risk of age-related hearing loss (Kujawa &amp; Liberman, 2006). The threshold for pain is about 130 dB, a jet plane taking off or a revolver firing at close range (Dunkle, 1982).</p>
<p><a href="https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2015/02/29193758/255ec68e0303670d7d90ced1985b7a4f83cf1373.jpeg"><img src="https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2015/02/29193758/255ec68e0303670d7d90ced1985b7a4f83cf1373-300x261.jpeg" alt="This illustration has a vertical bar in the middle labeled Decibels (dB) numbered 0 to 150 in intervals from the bottom to the top. To the left of the bar, the “sound intensity” of different sounds is labeled: “Hearing threshold” is 0; “Whisper” is 30, “soft music” is 40, “Refrigerator” is 45, “Safe” and “normal conversation” is 60, “Heavy city traffic” with “permanent damage after 8 hours of exposure” is 85, “Motorcycle” with “permanent damage after 6 hours exposure” is 95, “Earbuds max volume” with “permanent damage after 15 miutes exposure” is 105, “Risk of hearing loss” is 110, “pain threshold” is 130, “harmful” is 140, and “firearms” with “immediate permanent damage” is 150. To the right of the bar are photographs depicting “common sound”: At 20 decibels is a picture of rustling leaves; At 60 is two people talking, at 85 is traffic, at 105 is ear buds, at 120 is a music concert, and at 130 are jets."></a></p>
<p><strong>Figure 2</strong>. This figure illustrates the loudness of common sounds. (credit “planes”: modification of work by Max Pfandl; credit “crowd”: modification of work by Christian Holmér; credit: “earbuds”: modification of work by “Skinny Guy Lover_Flickr”/Flickr; credit “traffic”: modification of work by “quinntheislander_Pixabay”/Pixabay; credit “talking”: modification of work by Joi Ito; credit “leaves”: modification of work by Aurelijus Valeiša)</p>
<p>Although wave amplitude is generally associated with loudness, there is some interaction between frequency and amplitude in our perception of loudness within the audible range. For example, a 10 Hz sound wave is inaudible no matter the amplitude of the wave. A 1000 Hz sound wave, on the other hand, would vary dramatically in terms of perceived loudness as the amplitude of the wave increased.</p>
<p>Of course, different musical instruments can play the same musical note at the same level of loudness, yet they still sound quite different. This is known as the timbre of a sound. <strong>Timbre</strong> refers to a sound’s purity, and it is affected by the complex interplay of frequency, amplitude, and timing of sound waves.</p>
<h3 id="glossary">Glossary</h3>
<p><strong>basilar membrane:</strong> thin strip of tissue within the cochlea that contains the hair cells which serve as the sensory receptors for the auditory system</p>
<p><strong>cochlea:</strong> a fluid-filled, snail-shaped structure that contains the sensory receptor cells (hair cells) of the auditory system</p>
<p><strong>hair cell:</strong> auditory receptor cell of the inner ear</p>
<p><strong>incus:</strong> middle ear ossicle; also known as the anvil</p>
<p><strong>malleus:</strong> middle ear ossicle; also known as the hammer</p>
<p><strong>pinna:</strong> visible part of the ear that protrudes from the head</p>
<p><strong>stapes:</strong> middle ear ossicle; also known as the stirrup</p>
<p><strong>tympanic membrane:</strong> eardrum</p>
<h3 id="candela-citations">Candela Citations</h3>
<p>CC licensed content, Shared previously</p>
<ul>
<li>Psychology. <strong>Authored by</strong>: OpenStax College. <strong>Located at</strong>: <a href="https://openstax.org/books/psychology-2e/pages/5-4-hearing">https://openstax.org/books/psychology-2e/pages/5-4-hearing</a>. <strong>License</strong>: <em><a href="https://creativecommons.org/licenses/by/4.0/">CC BY: Attribution</a></em>. <strong>License Terms</strong>: Download for free at https://openstax.org/books/psychology-2e/pages/1-introduction</li>
<li>Information on corti. <strong>Authored by</strong>: Andrew J. Oxenham . <strong>Provided by</strong>: University of Minnesota. <strong>Located at</strong>: <a href="http://nobaproject.com/modules/hearing">http://nobaproject.com/modules/hearing</a>. <strong>Project</strong>: The Noba Project. <strong>License</strong>: <em><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA: Attribution-NonCommercial-ShareAlike</a></em></li>
</ul>
<p>All rights reserved content</p>
<ul>
<li>Process of Hearing. <strong>Authored by</strong>: psy1113. <strong>Located at</strong>: <a href="https://www.youtube.com/watch?v=pCCcFDoyBxM">https://www.youtube.com/watch?v=pCCcFDoyBxM</a>. <strong>License</strong>: <em>Other</em>. <strong>License Terms</strong>: Standard YouTube License</li>
</ul>
<hr>
<h2 id="how-we-see--introduction-to-psychology">How We See | Introduction to Psychology</h2>
<ul>
<li>url_title:: &quot;How We See | Introduction to Psychology&quot;
url_source:: https://courses.lumenlearning.com/waymaker-psychology/chapter/vision/</li>
</ul>
<h3 id="learning-objectives">Learning Objectives</h3>
<ul>
<li>Describe the basic anatomy of the visual system</li>
<li>Describe how light waves enable vision</li>
</ul>
<h2 id="anatomy-of-the-visual-system">Anatomy of the Visual System</h2>
<p>The eye is the major sensory organ involved in <strong>vision</strong> (Figure 1). There are several parts of the eye from the front to the back side, including the cornea, pupil, iris, lens, retina, fovea, and optic nerve. The cornea, pupil, iris, and lens are situated toward the front of the eye. At the back are the retina, fovea, and optic nerve. The slideshow (in Figure 1) below shows those parts, one at a time, along with a brief description. You will get to practice at the end of the slide.</p>
<p><strong>Figure 1.</strong> The anatomy of the eye is illustrated in this activity.</p>
<p>Now let us dive into each of the parts in detail.</p>
<h3 id="cornea">Cornea</h3>
<p>The <strong>cornea</strong> is the transparent covering over the eye. It serves as a barrier between the inner eye and the outside world, and it is involved in focusing light waves that enter the eye. Light waves are transmitted across the cornea and enter the eye through the pupil.</p>
<h3 id="pupil">Pupil</h3>
<p>The <strong>pupil</strong> is the small opening in the eye through which light passes, and the size of the pupil can change as a function of light levels as well as emotional arousal. When light levels are low, the pupil will become dilated, or expanded, to allow more light to enter the eye. When light levels are high, the pupil will constrict, or become smaller, to reduce the amount of light that enters the eye.</p>
<h3 id="iris">Iris</h3>
<p>The <strong>iris</strong> is the colored portion of the eye. It is connected to the muscles that control the pupil’s size.</p>
<h3 id="lens">Lens</h3>
<p>The <strong>lens</strong> is a curved, transparent structure that serves to provide additional focus for light entering the eye. Light crosses the lens after passing through the pupil. The lens is attached to muscles that can change its shape to aid in focusing light that is reflected from near or far objects.</p>
<h3 id="retina">Retina</h3>
<p>The <strong>retina</strong> is the light-sensitive lining of the eye located at the back of the eye.</p>
<h3 id="fovea">Fovea</h3>
<p>The <strong>fovea</strong>, which is part of the retina, is a small indentation in the back of the eye. In a normal-sighted individual, the lens will focus images perfectly on fovea. The fovea contains densely packed specialized <strong>photoreceptor</strong> cells, known as <strong>cones</strong>, which are light-detecting cells. Another type of photoreceptor is rods. See Figure 2.</p>
<p><a href="https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2015/02/29194236/7092854136b856409f1dbe9f76d123492b979928.jpeg"><img src="https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2015/02/29194236/7092854136b856409f1dbe9f76d123492b979928-300x262.jpeg" alt="This illustration shows light reaching the optic nerve, beneath which are Ganglion cells, and then rods and cones."></a></p>
<p><strong>Figure 2</strong>. The two types of photoreceptors are shown in this image. Cones are colored green and rods are blue.</p>
<p>The cones are specialized types of photoreceptors that work best in bright light conditions. Cones are very sensitive to acute detail and provide tremendous spatial resolution. They also are directly involved in our ability to perceive color.</p>
<p>While cones are concentrated in the fovea, where images tend to be focused, rods, another type of photoreceptor, are located throughout the remainder of the retina. <strong>Rods</strong> are specialized photoreceptors that work well in low light conditions, and while they lack the spatial resolution and color function of the cones, they are involved in our vision in dimly lit environments as well as in our perception of movement on the periphery of our visual field.</p>
<p>We have all experienced the different sensitivities of rods and cones when making the transition from a brightly lit environment to a dimly lit environment. Imagine going to see a blockbuster movie on a clear summer day. As you walk from the brightly lit lobby into the dark theater, you notice that you immediately have difficulty seeing much of anything. After a few minutes, you begin to adjust to the darkness and can see the interior of the theater. In the bright environment, your vision was dominated primarily by cone activity. As you move to the dark environment, rod activity dominates, but there is a delay in transitioning between the phases. If your rods do not transform light into nerve impulses as easily and efficiently as they should, you will have difficulty seeing in dim light, a condition known as night blindness.</p>
<p>Rods and cones are connected (via several interneurons) to retinal ganglion cells. Axons from the retinal ganglion cells converge and exit through the back of the eye to form the optic nerve.</p>
<h3 id="optic-nerve">Optic Nerve</h3>
<p>Rods and cones are connected (via several interneurons) to retinal ganglion cells (see Figure 2 again). Axons from the retinal ganglion cells converge and exit through the back of the eye to form the optic nerve. The <strong>optic nerve</strong> carries visual information from the retina to the brain. There is a point in the visual field called the blind spot (not shown in Figure 1): Even when light from a small object is focused on the blind spot, we do not see it. We are not consciously aware of our blind spots for two reasons: First, each eye gets a slightly different view of the visual field; therefore, the blind spots do not overlap. Second, our visual system fills in the blind spot so that although we cannot respond to visual information that occurs in that portion of the visual field, we are also not aware that information is missing.</p>
<p>The eye is the major sensory organ involved in <strong>vision</strong> (Figure 1). Light waves are transmitted across the cornea and enter the eye through the pupil. The <strong>cornea</strong> is the transparent covering over the eye. It serves as a barrier between the inner eye and the outside world, and it is involved in focusing light waves that enter the eye. The <strong>pupil</strong> is the small opening in the eye through which light passes, and the size of the pupil can change as a function of light levels as well as emotional arousal. When light levels are low, the pupil will become dilated, or expanded, to allow more light to enter the eye. When light levels are high, the pupil will constrict, or become smaller, to reduce the amount of light that enters the eye. The pupil’s size is controlled by muscles that are connected to the <strong>iris</strong>, which is the colored portion of the eye.</p>
<p><img src="https://s3-us-west-2.amazonaws.com/courses-images-archive-read-only/wp-content/uploads/sites/902/2015/02/23224718/CNX_Psych_05_03_Eye.jpg" alt="Different parts of the eye are labeled in this illustration. The cornea, pupil, iris, and lens are situated toward the front of the eye, and at the back are the optic nerve, fovea, and retina."></p>
<p><strong>Figure 1</strong>. The anatomy of the eye is illustrated in this diagram.</p>
<p>After passing through the pupil, light crosses the <strong>lens</strong>, a curved, transparent structure that serves to provide additional focus. The lens is attached to muscles that can change its shape to aid in focusing light that is reflected from near or far objects. In a normal-sighted individual, the lens will focus images perfectly on a small indentation in the back of the eye known as the <strong>fovea</strong>, which is part of the <strong>retina</strong>, the light-sensitive lining of the eye. The fovea contains densely packed specialized photoreceptor cells (Figure 2). These <strong>photoreceptor</strong> cells, known as <strong>cones</strong>, are light-detecting cells. The cones are specialized types of photoreceptors that work best in bright light conditions. Cones are very sensitive to acute detail and provide tremendous spatial resolution. They also are directly involved in our ability to perceive color.</p>
<p>While cones are concentrated in the fovea, where images tend to be focused, rods, another type of photoreceptor, are located throughout the remainder of the retina. <strong>Rods</strong> are specialized photoreceptors that work well in low light conditions, and while they lack the spatial resolution and color function of the cones, they are involved in our vision in dimly lit environments as well as in our perception of movement on the periphery of our visual field.</p>
<p><a href="https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2015/02/29194236/7092854136b856409f1dbe9f76d123492b979928.jpeg"><img src="https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2015/02/29194236/7092854136b856409f1dbe9f76d123492b979928-300x262.jpeg" alt="This illustration shows light reaching the optic nerve, beneath which are Ganglion cells, and then rods and cones."></a></p>
<p><strong>Figure 2</strong>. The two types of photoreceptors are shown in this image. Cones are colored green and rods are blue.</p>
<p>We have all experienced the different sensitivities of rods and cones when making the transition from a brightly lit environment to a dimly lit environment. Imagine going to see a blockbuster movie on a clear summer day. As you walk from the brightly lit lobby into the dark theater, you notice that you immediately have difficulty seeing much of anything. After a few minutes, you begin to adjust to the darkness and can see the interior of the theater. In the bright environment, your vision was dominated primarily by cone activity. As you move to the dark environment, rod activity dominates, but there is a delay in transitioning between the phases. If your rods do not transform light into nerve impulses as easily and efficiently as they should, you will have difficulty seeing in dim light, a condition known as night blindness.</p>
<p>Rods and cones are connected (via several interneurons) to retinal ganglion cells. Axons from the retinal ganglion cells converge and exit through the back of the eye to form the optic nerve. The <strong>optic nerve</strong> carries visual information from the retina to the brain. There is a point in the visual field called the <strong>blind spot</strong>: Even when light from a small object is focused on the blind spot, we do not see it. We are not consciously aware of our blind spots for two reasons: First, each eye gets a slightly different view of the visual field; therefore, the blind spots do not overlap. Second, our visual system fills in the blind spot so that although we cannot respond to visual information that occurs in that portion of the visual field, we are also not aware that information is missing.</p>
<p>The optic nerve from each eye merges just below the brain at a point called the <strong>optic chiasm</strong>. As Figure 3 shows, the optic chiasm is an X-shaped structure that sits just below the cerebral cortex at the front of the brain. At the point of the optic chiasm, information from the right visual field (which comes from both eyes) is sent to the left side of the brain, and information from the left visual field is sent to the right side of the brain.</p>
<p><img src="https://s3-us-west-2.amazonaws.com/courses-images-archive-read-only/wp-content/uploads/sites/902/2015/02/23224723/CNX_Psych_05_03_OpticChias.jpg" alt="Visual stimuli enter the eyes, pass through the optic nerve and into the optic chiasm, then back to the occipital lobe at the back of the brain."></p>
<p><strong>Figure 3</strong>. This illustration shows the optic chiasm at the front of the brain and the pathways to the occipital lobe at the back of the brain, where visual sensations are processed into meaningful perceptions.</p>
<p>Once inside the brain, visual information is sent via a number of structures to the occipital lobe at the back of the brain for processing. Visual information might be processed in parallel pathways which can generally be described as the “what pathway” (the ventral pathway) and the “where/how” pathway (the dorsal pathway). The “what pathway” is involved in object recognition and identification, while the “where/how pathway” is involved with location in space and how one might interact with a particular visual stimulus (Milner &amp; Goodale, 2008; Ungerleider &amp; Haxby, 1994). For example, when you see a ball rolling down the street, the “what pathway” identifies what the object is, and the “where/how pathway” identifies its location or movement in space.</p>
<p><a href="https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2016/10/26200309/visualpathways.png"><img src="https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2016/10/26200309/visualpathways.png" alt="Areas of the brain showing the ventral pathway, along the side of the brain closer to the temporal lobes, and the dorsal pathway in the back of the brain. It also shows the visual cortex areas at the back of the brain: V1/V2, V3, V3A, and V4 (associated with color), and the faces and object recognition areas (next to V4)."></a></p>
<p><strong>Figure 4</strong>. Visual areas in the brain.</p>
<h3 id="what-do-you-think">what do you think?</h3>
<h2 id="the-ethics-of-research-using-animals"><strong>The Ethics of Research Using Animals</strong></h2>
<p>David Hubel and Torsten Wiesel were awarded the Nobel Prize in Medicine in 1981 for their research on the visual system. They collaborated for more than twenty years and made significant discoveries about the neurology of visual perception (Hubel &amp; Wiesel, 1959, 1962, 1963, 1970; Wiesel &amp; Hubel, 1963). They studied animals, mostly cats and monkeys. Although they used several techniques, they did considerable single-unit recordings, during which tiny electrodes were inserted in the animal’s brain to determine when a single cell was activated. Among their many discoveries, they found that specific brain cells respond to lines with specific orientations (called ocular dominance), and they mapped the way those cells are arranged in areas of the visual cortex known as columns and hypercolumns.</p>
<p>In some of their research, they sutured one eye of newborn kittens closed and followed the development of the kittens’ vision. They discovered there was a critical period of development for vision. If kittens were deprived of input from one eye, other areas of their visual cortex filled in the area that was normally used by the eye that was sewn closed. In other words, neural connections that exist at birth can be lost if they are deprived of sensory input.</p>
<p>What do you think about sewing a kitten’s eye closed for research? To many animal advocates, this would seem brutal, abusive, and unethical. What if you could do research that would help ensure babies and children born with certain conditions could develop normal vision instead of becoming blind? Would you want that research done? Would you conduct that research, even if it meant causing some harm to cats? Would you think the same way if you were the parent of such a child? What if you worked at the animal shelter?</p>
<p>Like virtually every other industrialized nation, the United States permits medical experimentation on animals, with few limitations (assuming sufficient scientific justification). The goal of any laws that exist is not to ban such tests but rather to limit unnecessary animal suffering by establishing standards for the humane treatment and housing of animals in laboratories.</p>
<p>As explained by Stephen Latham, the director of the Interdisciplinary Center for Bioethics at Yale (2012), possible legal and regulatory approaches to animal testing vary on a continuum from strong government regulation and monitoring of all experimentation at one end, to a self-regulated approach that depends on the ethics of the researchers at the other end. The United Kingdom has the most significant regulatory scheme, whereas Japan uses the self-regulation approach. The U.S. approach is somewhere in the middle, the result of a gradual blending of the two approaches.</p>
<p>There is no question that medical research is a valuable and important practice. The question is whether the use of animals is a necessary or even best practice for producing the most reliable results. Alternatives include the use of patient-drug databases, virtual drug trials, computer models and simulations, and noninvasive imaging techniques such as magnetic resonance imaging and computed tomography scans (“Animals in Science/Alternatives,” n.d.). Other techniques, such as microdosing, use humans not as test animals but as a means to improve the accuracy and reliability of test results. In vitro methods based on human cell and tissue cultures, stem cells, and genetic testing methods are also increasingly available.</p>
<p>Today, at the local level, any facility that uses animals and receives federal funding must have an Institutional Animal Care and Use Committee (IACUC) that ensures that the NIH guidelines are being followed. The IACUC must include researchers, administrators, a veterinarian, and at least one person with no ties to the institution: that is, a concerned citizen. This committee also performs inspections of laboratories and protocols.</p>
<h2 id="amplitude-and-wavelength">Amplitude and Wavelength</h2>
<p>As mentioned above, light enters your eyes as a wave. It is important to understand some basic properties of waves to see how they impact what we see. Two physical characteristics of a wave are <strong>amplitude</strong> and wavelength (Figure 5). The amplitude of a wave is the height of a wave as measured from the highest point on the <strong>wave</strong> (<strong>peak</strong> or <strong>crest</strong>) to the lowest point on the wave (trough). <strong>Wavelength</strong> refers to the length of a wave from one peak to the next.</p>
<p><img src="https://s3-us-west-2.amazonaws.com/courses-images-archive-read-only/wp-content/uploads/sites/902/2015/02/23224709/CNX_Psych_05_02_Wave.jpg" alt="A diagram illustrates the basic parts of a wave. Moving from left to right, the wavelength line begins above a straight horizontal line and falls and rises equally above and below that line. One of the areas where the wavelength line reaches its highest point is labeled “Peak.” A horizontal bracket, labeled “Wavelength,” extends from this area to the next peak. One of the areas where the wavelength reaches its lowest point is labeled “Trough.” A vertical bracket, labeled “Amplitude,” extends from a “Peak” to a “Trough.”"></p>
<p><strong>Figure 5</strong>. The amplitude or height of a wave is measured from the peak to the trough. The wavelength is measured from peak to peak.</p>
<p>Wavelength is directly related to the frequency of a given waveform. <strong>Frequency</strong> refers to the number of waves that pass a given point in a given time period and is often expressed in terms of <strong>hertz (Hz</strong>), or cycles per second. Longer wavelengths will have lower frequencies, and shorter wavelengths will have higher frequencies (Figure 6).</p>
<p><img src="https://s3-us-west-2.amazonaws.com/courses-images-archive-read-only/wp-content/uploads/sites/902/2015/02/23224710/CNX_Psych_05_02_Frequencies.jpg" alt="Stacked vertically are 5 waves of different colors and wavelengths. The top wave is red with a long wavelengths, which indicate a low frequency. Moving downward, the color of each wave is different: orange, yellow, green, and blue. Also moving downward, the wavelengths become shorter as the frequencies increase."></p>
<p><strong>Figure 6</strong>. This figure illustrates waves of differing wavelengths/frequencies. At the top of the figure, the red wave has a long wavelength/short frequency. Moving from top to bottom, the wavelengths decrease and frequencies increase.</p>
<h2 id="light-waves">Light Waves</h2>
<p>The <strong>visible spectrum</strong> is the portion of the larger electromagnetic spectrum that we can see. As Figure 7 shows, the <strong>electromagnetic spectrum</strong> encompasses all of the electromagnetic radiation that occurs in our environment and includes gamma rays, x-rays, ultraviolet light, visible light, infrared light, microwaves, and radio waves. The visible spectrum in humans is associated with wavelengths that range from 380 to 740 nm—a very small distance since a nanometer (nm) is one-billionth of a meter. Other species can detect other portions of the electromagnetic spectrum. For instance, honeybees can see light in the ultraviolet range (Wakakuwa, Stavenga, &amp; Arikawa, 2007), and some snakes can detect infrared radiation in addition to more traditional visual light cues (Chen, Deng, Brauth, Ding, &amp; Tang, 2012; Hartline, Kass, &amp; Loop, 1978).</p>
<p><img src="https://s3-us-west-2.amazonaws.com/courses-images-archive-read-only/wp-content/uploads/sites/902/2015/02/23224712/CNX_Psych_05_02_Spectrum.jpg" alt="This illustration shows the wavelength, frequency, and size of objects across the electromagnetic spectrum.. At the top, various wavelengths are given in sequence from small to large, with a parallel illustration of a wave with increasing frequency. These are the provided wavelengths, measured in meters: “Gamma ray 10 to the negative twelfth power,” “x-ray 10 to the negative tenth power,” ultraviolet 10 to the negative eighth power,” “visible .5 times 10 to the negative sixth power,” “infrared 10 to the negative fifth power,” microwave 10 to the negative second power,” and “radio 10 cubed.”Another section is labeled “About the size of” and lists from left to right: “Atomic nuclei,” “Atoms,” “Molecules,” “Protozoans,” “Pinpoints,” “Honeybees,” “Humans,” and “Buildings” with an illustration of each . At the bottom is a line labeled “Frequency” with the following measurements in hertz: 10 to the powers of 20, 18, 16, 15, 12, 8, and 4. From left to right the line changes in color from purple to red with the remaining colors of the visible spectrum in between, occurring roughly between 10 to the power of 15 and 10 to the power of 12."></p>
<p><strong>Figure 7</strong>. Light that is visible to humans makes up only a small portion of the electromagnetic spectrum.</p>
<p>In humans, light wavelength is associated with perception of color (Figure 8). Within the visible spectrum, our experience of red is associated with longer wavelengths, greens are intermediate, and blues and violets are shorter in wavelength. (An easy way to remember this is the mnemonic ROYGBIV: <strong>r</strong>ed, <strong>o</strong>range, <strong>y</strong>ellow, <strong>g</strong>reen, <strong>b</strong>lue, <strong>i</strong>ndigo, <strong>v</strong>iolet.) The amplitude of light waves is associated with our experience of brightness or intensity of color, with larger amplitudes appearing brighter.</p>
<p><img src="https://s3-us-west-2.amazonaws.com/courses-images-archive-read-only/wp-content/uploads/sites/902/2015/02/23224713/CNX_Psych_05_02_VisSpec.jpg" alt="Wavelengths from low to high as measured in nanometers. Below the visible spectrum, in increasing order, are “Cosmic radiation,” “Gamma rays,” “X-rays,” and “Ultraviolet,”. The visible wavelengths of light are between 400 and 700 nanometers. Wavelengths above the visible spectrum, in increasing order, are “Infrared,” “Terahertz radiation,” “Radar,” “Television and radio broadcasting,” and “AC circuits.”"></p>
<p><strong>Figure 8</strong>. Different wavelengths of light are associated with our perception of different colors. (credit: modification of work by Johannes Ahlmann)</p>
<h3 id="glossary">Glossary</h3>
<p><strong>amplitude:</strong> height of a wave</p>
<p><strong>blind spot:</strong> point where we cannot respond to visual information in that portion of the visual field</p>
<p><strong>cone:</strong> specialized photoreceptor that works best in bright light conditions and detects color</p>
<p><strong>cornea:</strong> transparent covering over the eye</p>
<p><strong>electromagnetic spectrum:</strong> all the electromagnetic radiation that occurs in our environment</p>
<p><strong>fovea:</strong> small indentation in the retina that contains cones</p>
<p><strong>frequency:</strong> number of waves that pass a given point in a given time period</p>
<p><strong>hertz (Hz):</strong> cycles per second; measure of frequency</p>
<p><strong>iris:</strong> colored portion of the eye</p>
<p><strong>lens:</strong> curved, transparent structure that provides additional focus for light entering the eye</p>
<p><strong>optic chiasm:</strong> X-shaped structure that sits just below the brain’s ventral surface; represents the merging of the optic nerves from the two eyes and the separation of information from the two sides of the visual field to the opposite side of the brain</p>
<p><strong>optic nerve:</strong> carries visual information from the retina to the brain</p>
<p><strong>peak:</strong> (also, crest) highest point of a wave</p>
<p><strong>photoreceptor:</strong> light-detecting cell</p>
<p><strong>pupil:</strong> small opening in the eye through which light passes</p>
<p><strong>retina:</strong> light-sensitive lining of the eye</p>
<p><strong>rod:</strong> specialized photoreceptor that works well in low light conditions</p>
<p><strong>trough:</strong> lowest point of a wave</p>
<p><strong>visible spectrum:</strong> portion of the electromagnetic spectrum that we can see</p>
<p><strong>wavelength:</strong> length of a wave from one peak to the next peak</p>
<h3 id="candela-citations">Candela Citations</h3>
<p>CC licensed content, Shared previously</p>
<ul>
<li>Vision, Waves and Wavelengths. <strong>Authored by</strong>: OpenStax College. <strong>Located at</strong>: <a href="https://openstax.org/books/psychology-2e/pages/5-3-vision">https://openstax.org/books/psychology-2e/pages/5-3-vision</a>. <strong>License</strong>: <em><a href="https://creativecommons.org/licenses/by/4.0/">CC BY: Attribution</a></em>. <strong>License Terms</strong>: Download for free at https://openstax.org/books/psychology-2e/pages/1-introduction</li>
<li>Vision, information on ventral and dorsal pathways. <strong>Authored by</strong>: Simona Buetti and Alejandro Lleras . <strong>Provided by</strong>: University of Illinois at Urbana-Champaign. <strong>Located at</strong>: <a href="http://nobaproject.com/modules/vision">http://nobaproject.com/modules/vision</a>. <strong>License</strong>: <em><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA: Attribution-NonCommercial-ShareAlike</a></em></li>
<li>Waves and Wavelengths. <strong>Authored by</strong>: OpenStax College. <strong>Located at</strong>: <a href="http://cnx.org/contents/Sr8Ev5Og@5.52:1Cicp6CO@8/Waves-and-Wavelengths">http://cnx.org/contents/Sr8Ev5Og@5.52:1Cicp6CO@8/Waves-and-Wavelengths</a>. <strong>License</strong>: <em><a href="https://creativecommons.org/licenses/by/4.0/">CC BY: Attribution</a></em>. <strong>License Terms</strong>: Download for free at http://cnx.org/contents/4abf04bf-93a0-45c3-9cbc-2cefd46e68cc@5.48</li>
</ul>
<hr>
<h2 id="pitch-perception-and-hearing-loss">Pitch Perception and Hearing Loss</h2>
<ul>
<li>url_title:: &quot;Pitch Perception and Hearing Loss&quot;
url_source:: https://courses.lumenlearning.com/waymaker-psychology/chapter/reading-pitch-perception-and-hearing-loss/</li>
</ul>
<h3 id="learning-objectives">Learning Objectives</h3>
<ul>
<li>Explain how we encode and perceive pitch and localize sound</li>
<li>Describe types of hearing loss</li>
</ul>
<h2 id="pitch-perception">Pitch Perception</h2>
<p>We know that different frequencies of sound waves are associated with differences in our perception of the pitch of those sounds. Low-frequency sounds are lower pitched, and high-frequency sounds are higher pitched. But how does the auditory system differentiate among various pitches? Several theories have been proposed to account for pitch perception. We’ll discuss two of them here: temporal theory and place theory. The <strong>temporal theory</strong> of pitch perception asserts that frequency is coded by the activity level of a sensory neuron. This would mean that a given hair cell would fire action potentials related to the frequency of the sound wave. While this is a very intuitive explanation, we detect such a broad range of frequencies (20–20,000 Hz) that the frequency of action potentials fired by hair cells cannot account for the entire range. Because of properties related to sodium channels on the neuronal membrane that are involved in action potentials, there is a point at which a cell cannot fire any faster (Shamma, 2001). The <strong>place theory</strong> of pitch perception suggests that different portions of the basilar membrane are sensitive to sounds of different frequencies. More specifically, the base of the basilar membrane responds best to high frequencies and the tip of the basilar membrane responds best to low frequencies. Therefore, hair cells that are in the base portion would be labeled as high-pitch receptors, while those in the tip of basilar membrane would be labeled as low-pitch receptors (Shamma, 2001). In reality, both theories explain different aspects of pitch perception. At frequencies up to about 4000 Hz, it is clear that both the rate of action potentials and place contribute to our perception of pitch. However, much higher frequency sounds can only be encoded using place cues (Shamma, 2001).</p>
<h2 id="sound-localization">Sound Localization</h2>
<p>The ability to locate sound in our environments is an important part of <strong>hearing</strong>. Localizing sound could be considered similar to the way that we perceive depth in our visual fields. Like the monocular and binocular cues that provided information about depth, the auditory system uses both <strong>monaural</strong> (one-eared) and <strong>binaural</strong> (two-eared) cues to localize sound.</p>
<p>Each pinna interacts with incoming sound waves differently, depending on the sound’s source relative to our bodies. This interaction provides a monaural cue that is helpful in locating sounds that occur above or below and in front or behind us. The sound waves received by your two ears from sounds that come from directly above, below, in front, or behind you would be identical; therefore, monaural cues are essential (Grothe, Pecka, &amp; McAlpine, 2010).</p>
<p>Binaural cues, on the other hand, provide information on the location of a sound along a horizontal axis by relying on differences in patterns of vibration of the eardrum between our two ears. If a sound comes from an off-center location, it creates two types of binaural cues: interaural level differences and interaural timing differences. <strong>Interaural level difference</strong> refers to the fact that a sound coming from the right side of your body is more intense at your right ear than at your left ear because of the attenuation of the sound wave as it passes through your head. <strong>Interaural timing difference</strong> refers to the small difference in the time at which a given sound wave arrives at each ear (Figure 1). Certain brain areas monitor these differences to construct where along a horizontal axis a sound originates (Grothe et al., 2010).</p>
<p><img src="https://s3-us-west-2.amazonaws.com/courses-images-archive-read-only/wp-content/uploads/sites/902/2015/02/23224732/CNX_Psych_05_04_MonInt.jpg" alt="A photograph of jets has an illustration of arced waves labeled “sound” coming from the jets. These extend to an outline of a human head, with arrows from the jets identifying the location of each ear."></p>
<p><strong>Figure 1</strong>. Localizing sound involves the use of both monaural and binaural cues. (credit “plane”: modification of work by Max Pfandl)</p>
<h2 id="hearing-loss">Hearing Loss</h2>
<p><strong>Deafness</strong> is the partial or complete inability to hear. Some people are born without hearing, which is known as <strong>congenital deafness</strong>. Other people suffer from <strong>conductive hearing loss</strong>, which is due to a problem delivering sound energy to the cochlea. Causes for conductive hearing loss include blockage of the ear canal, a hole in the tympanic membrane, problems with the ossicles, or fluid in the space between the eardrum and cochlea. Another group of people suffer from sensorineural hearing loss, which is the most common form of hearing loss. Sensorineural hearing loss can be caused by many factors, such as aging, head or acoustic trauma, infections and diseases (such as measles or mumps), medications, environmental effects such as noise exposure (noise-induced hearing loss, as shown in Figure 5.20), tumors, and toxins (such as those found in certain solvents and metals).</p>
<p><a href="https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2016/10/29221028/9eb390d075658d14e8907a047adbb361829177fb.jpeg"><img src="https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2016/10/29221028/9eb390d075658d14e8907a047adbb361829177fb-300x153.jpeg" alt="Photograph A shows Beyoncé performing at a concert. Photograph B shows a construction worker operating a jackhammer."></a></p>
<p><strong>Figure 2</strong>. Environmental factors that can lead to sensorineural hearing loss include regular exposure to loud music or construction equipment. (a) Musical performers and (b) construction workers are at risk for this type of hearing loss. (credit a: modification of work by “GillyBerlin_Flickr”/Flickr; credit b: modification of work by Nick Allen)</p>
<p>Given the mechanical nature by which the sound wave stimulus is transmitted from the eardrum through the ossicles to the oval window of the cochlea, some degree of hearing loss is inevitable. With conductive hearing loss, hearing problems are associated with a failure in the vibration of the eardrum and/or movement of the ossicles. These problems are often dealt with through devices like hearing aids that amplify incoming sound waves to make vibration of the eardrum and movement of the ossicles more likely to occur.</p>
<p>When the hearing problem is associated with a failure to transmit neural signals from the cochlea to the brain, it is called <strong>sensorineural hearing loss</strong>. This type of loss accelerates with age and can be caused by prolonged exposure to loud noises, which causes damage to the hair cells within the cochlea. One disease that results in sensorineural hearing loss is <strong>Ménière’s disease</strong>. Although not well understood, Ménière’s disease results in a degeneration of inner ear structures that can lead to hearing loss, tinnitus (constant ringing or buzzing), <strong>vertigo</strong> (a sense of spinning), and an increase in pressure within the inner ear (Semaan &amp; Megerian, 2011). This kind of loss cannot be treated with hearing aids, but some individuals might be candidates for a cochlear implant as a treatment option. <strong>Cochlear implants</strong> are electronic devices that consist of a microphone, a speech processor, and an electrode array. The device receives incoming sound information and directly stimulates the auditory nerve to transmit information to the brain.</p>
<h3 id="what-do-you-think-deaf-culture">What Do You Think?: Deaf Culture</h3>
<p>In the United States and other places around the world, deaf people have their own language, schools, and customs. This is called deaf culture. In the United States, deaf individuals often communicate using American Sign Language (ASL); ASL has no verbal component and is based entirely on visual signs and gestures. The primary mode of communication is signing. One of the values of deaf culture is to continue traditions like using sign language rather than teaching deaf children to try to speak, read lips, or have cochlear implant surgery.</p>
<p>When a child is diagnosed as deaf, parents have difficult decisions to make. Should the child be enrolled in mainstream schools and taught to verbalize and read lips? Or should the child be sent to a school for deaf children to learn ASL and have significant exposure to deaf culture? Do you think there might be differences in the way that parents approach these decisions depending on whether or not they are also deaf?</p>
<h3 id="think-it-over">Think It Over</h3>
<p>If you had to choose to lose either your vision or your hearing, which would you choose and why?</p>
<h3 id="glossary">Glossary</h3>
<p><strong>binaural cue:</strong> two-eared cue to localize sound</p>
<p><strong>cochlear implant:</strong> electronic device that consists of a microphone, a speech processor, and an electrode array to directly stimulate the auditory nerve to transmit information to the brain</p>
<p><strong>conductive hearing loss:</strong> failure in the vibration of the eardrum and/or movement of the ossicles</p>
<p><strong>congenital deafness:</strong> deafness from birth</p>
<p><strong>deafness:</strong> partial or complete inability to hear</p>
<p><strong>interaural level difference:</strong> sound coming from one side of the body is more intense at the closest ear because of the attenuation of the sound wave as it passes through the head</p>
<p><strong>interaural timing difference:</strong> small difference in the time at which a given sound wave arrives at each ear</p>
<p><strong>Ménière’s disease:</strong> results in a degeneration of inner ear structures that can lead to hearing loss, tinnitus, vertigo, and an increase in pressure within the inner ear</p>
<p><strong>monaural cue:</strong> one-eared cue to localize sound</p>
<p><strong>place theory of pitch perception:</strong> different portions of the basilar membrane are sensitive to sounds of different frequencies</p>
<p><strong>sensorineural hearing loss:</strong> failure to transmit neural signals from the cochlea to the brain</p>
<p><strong>temporal theory of pitch perception:</strong> sound’s frequency is coded by the activity level of a sensory neuron</p>
<p><strong>vertigo:</strong> spinning sensation</p>
<h3 id="candela-citations">Candela Citations</h3>
<hr>
<h2 id="taste-and-smell--introduction-to-psychology">Taste and Smell | Introduction to Psychology</h2>
<ul>
<li>url_title:: &quot;Taste and Smell | Introduction to Psychology&quot;
url_source:: https://courses.lumenlearning.com/waymaker-psychology/chapter/reading-taste-and-smell/</li>
</ul>
<h3 id="learning-objectives">Learning Objectives</h3>
<ul>
<li>Summarize the chemical process of taste and smell</li>
</ul>
<h2 id="chemical-senses">Chemical Senses</h2>
<p>Taste (gustation) and smell (olfaction) are called chemical senses because both have sensory receptors that respond to molecules in the food we eat or in the air we breathe. There is a pronounced interaction between our chemical senses. For example, when we describe the flavor of a given food, we are really referring to both gustatory and olfactory properties of the food working in combination.</p>
<h2 id="taste-gustation">Taste (Gustation)</h2>
<p>You have learned since elementary school that there are four basic groupings of <strong>taste</strong>: sweet, salty, sour, and bitter. Research demonstrates, however, that we have at least six taste groupings. <strong>Umami</strong> is our fifth taste. Umami is actually a Japanese word that roughly translates to yummy, and it is associated with a taste for monosodium glutamate (Kinnamon &amp; Vandenbeuch, 2009). There is also a growing body of experimental evidence suggesting that we possess a taste for the fatty content of a given food (Mizushige, Inoue, &amp; Fushiki, 2007).</p>
<p>Molecules from the food and beverages we consume dissolve in our saliva and interact with taste receptors on our tongue and in our mouth and throat. <strong>Taste buds</strong> are formed by groupings of taste receptor cells with hair-like extensions that protrude into the central pore of the taste bud (Figure 1). Taste buds have a life cycle of ten days to two weeks, so even destroying some by burning your tongue won’t have any long-term effect; they just grow right back. Taste molecules bind to receptors on this extension and cause chemical changes within the sensory cell that result in neural impulses being transmitted to the brain via different nerves, depending on where the receptor is located. Taste information is transmitted to the medulla, thalamus, and limbic system, and to the gustatory cortex, which is tucked underneath the overlap between the frontal and temporal lobes (Maffei, Haley, &amp; Fontanini, 2012; Roper, 2013).</p>
<p><img src="https://s3-us-west-2.amazonaws.com/courses-images-archive-read-only/wp-content/uploads/sites/902/2015/02/23224736/CNX_Psych_05_05_TasteBud.jpg" alt="Illustration A shows a taste bud in an opening of the tongue, with the “tongue surface,” “taste pore,” “taste receptor cell” and “nerves” labeled. Part B is a micrograph showing taste buds on a human tongue."></p>
<p><strong>Figure 1</strong>. (a) Taste buds are composed of a number of individual taste receptors cells that transmit information to nerves. (b) This micrograph shows a close-up view of the tongue’s surface. (credit a: modification of work by Jonas Töle; credit b: scale-bar data from Matt Russell)</p>
<h2 id="smell-olfaction">Smell (Olfaction)</h2>
<p><strong>Olfactory receptor</strong> cells are located in a mucous membrane at the top of the nose. Small hair-like extensions from these receptors serve as the sites for odor molecules dissolved in the mucus to interact with chemical receptors located on these extensions (Figure 2). Once an odor molecule has bound a given receptor, chemical changes within the cell result in signals being sent to the <strong>olfactory bulb</strong>: a bulb-like structure at the tip of the frontal lobe where the olfactory nerves begin. From the olfactory bulb, information is sent to regions of the limbic system and to the primary olfactory cortex, which is located very near the gustatory cortex (Lodovichi &amp; Belluscio, 2012; Spors et al., 2013).</p>
<p><img src="https://s3-us-west-2.amazonaws.com/courses-images-archive-read-only/wp-content/uploads/sites/902/2015/02/23224737/CNX_Psych_05_05_OlfacRecep.jpg" alt="An illustration shows a side view of a human head and the location of the “nasal cavity,” “olfactory receptors,” and “olfactory bulb.”"></p>
<p><strong>Figure 2</strong>. Olfactory receptors are the hair-like parts that extend from the olfactory bulb into the mucous membrane of the nasal cavity.</p>
<p>Olfactory receptors are complex proteins called G protein-coupled receptors (GPCRs). These structures are proteins that weave back and forth across the membranes of olfactory cells seven times, forming structures outside the cell that sense odorant molecules and structures inside the cell that activate the neural message ultimately conveyed to the brain by olfactory neurons. The structures that sense odorants can be thought of as tiny binding pockets with sites that respond to active parts of molecules (e.g., carbon chains). There are about 350 functional olfactory genes in humans; each gene expresses a particular kind of olfactory receptor. All olfactory receptors of a given kind project to structures called glomeruli (paired clusters of cells found on both sides of the brain). For a single molecule, the pattern of activation across the glomeruli paints a picture of the chemical structure of the molecule. Thus, the olfactory system can identify a vast array of chemicals present in the environment. Most of the odors we encounter are actually mixtures of chemicals (e.g., bacon odor). The olfactory system creates an image for the mixture and stores it in memory just as it does for the odor of a single molecule (Shepherd, 2005).</p>
<p>There is tremendous variation in the sensitivity of the olfactory systems of different species. We often think of dogs as having far superior olfactory systems than our own, and indeed, dogs can do some remarkable things with their noses. There is some evidence to suggest that dogs can “smell” dangerous drops in blood glucose levels as well as cancerous tumors (Wells, 2010). Dogs’ extraordinary olfactory abilities may be due to the increased number of functional genes for olfactory receptors (between 800 and 1200), compared to the fewer than 400 observed in humans and other primates (Niimura &amp; Nei, 2007).</p>
<p>Many species respond to chemical messages, known as <strong>pheromones</strong>, sent by another individual (Wysocki &amp; Preti, 2004). Pheromonal communication often involves providing information about the reproductive status of a potential mate. So, for example, when a female rat is ready to mate, she secretes pheromonal signals that draw attention from nearby male rats. Pheromonal activation is actually an important component in eliciting sexual behavior in the male rat (Furlow, 1996, 2012; Purvis &amp; Haynes, 1972; Sachs, 1997). There has also been a good deal of research (and controversy) about pheromones in humans (Comfort, 1971; Russell, 1976; Wolfgang-Kimball, 1992; Weller, 1998).</p>
<h3 id="learning-objectives">Learning Objectives</h3>
<p>As mentioned earlier, a food’s flavor represents an interaction of both gustatory and olfactory information. Think about the last time you were seriously congested due to a cold or the flu. What changes did you notice in the flavors of the foods that you ate during this time?</p>
<h3 id="glossary">Glossary</h3>
<p><strong>olfactory bulb:</strong> bulb-like structure at the tip of the frontal lobe, where the olfactory nerves begin</p>
<p><strong>olfactory receptor:</strong> sensory cell for the olfactory system<br>
<strong>pheromone:</strong> chemical message sent by another individual<br>
<strong>taste bud:</strong> grouping of taste receptor cells with hair-like extensions that protrude into the central pore of the taste bud<br>
<strong>umami:</strong> taste for monosodium glutamate</p>
<h3 id="candela-citations">Candela Citations</h3>
<p>CC licensed content, Shared previously</p>
<ul>
<li>The Other Senses. <strong>Authored by</strong>: OpenStax College. <strong>Located at</strong>: <a href="https://openstax.org/books/psychology-2e/pages/5-5-the-other-senses">https://openstax.org/books/psychology-2e/pages/5-5-the-other-senses</a>. <strong>License</strong>: <em><a href="https://creativecommons.org/licenses/by/4.0/">CC BY: Attribution</a></em>. <strong>License Terms</strong>: Download for free at https://openstax.org/books/psychology-2e/pages/1-introduction</li>
<li>Paragraph on olfactory receptors. <strong>Authored by</strong>: Linda Bartoshuk and Derek Snyder . <strong>Provided by</strong>: University of Florida. <strong>Located at</strong>: <a href="http://nobaproject.com/modules/taste-and-smell?r=LDIzOTky">http://nobaproject.com/modules/taste-and-smell?r=LDIzOTky</a>. <strong>Project</strong>: The Noba Project. <strong>License</strong>: <em><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA: Attribution-NonCommercial-ShareAlike</a></em></li>
</ul>
<hr>
<h2 id="the-vestibular-sense--introduction-to-psychology">The Vestibular Sense | Introduction to Psychology</h2>
<ul>
<li>url_title:: &quot;The Vestibular Sense | Introduction to Psychology&quot;
url_source:: https://courses.lumenlearning.com/waymaker-psychology/chapter/reading-the-vestibular-sense/</li>
</ul>
<h3 id="learning-objectives">Learning Objectives</h3>
<ul>
<li>Describe the basic functions of the vestibular, proprioceptive, and kinesthetic sensory systems</li>
</ul>
<h2 id="the-vestibular-sense-proprioception-and-kinesthesia">The Vestibular Sense, Proprioception, and Kinesthesia</h2>
<p>The <strong>vestibular sense</strong> contributes to our ability to maintain balance and body posture. As Figure 1 shows, the major sensory organs (utricle, saccule, and the three semicircular canals) of this system are located next to the cochlea in the inner ear. The vestibular organs are fluid-filled and have hair cells, similar to the ones found in the auditory system, which respond to movement of the head and gravitational forces. When these hair cells are stimulated, they send signals to the brain via the vestibular nerve. Although we may not be consciously aware of our vestibular system’s sensory information under normal circumstances, its importance is apparent when we experience motion sickness and/or dizziness related to infections of the inner ear (Khan &amp; Chang, 2013).</p>
<p><img src="https://s3-us-west-2.amazonaws.com/courses-images-archive-read-only/wp-content/uploads/sites/902/2015/02/23224740/CNX_Psych_05_05_Vestibular.jpg" alt="An illustration of the vestibular system shows the locations of the three canals (“posterior canal,” “horizontal canal,” and “superior canal”) and the locations of the “urticle,” “oval window,” “cochlea,” “basilar membrane and hair cells,” “saccule,” and “vestibule.”"></p>
<p><strong>Figure 1</strong>. The major sensory organs of the vestibular system are located next to the cochlea in the inner ear. These include the utricle, saccule, and the three semicircular canals (posterior, superior, and horizontal).</p>
<p>In addition to maintaining balance, the vestibular system collects information critical for controlling movement and the reflexes that move various parts of our bodies to compensate for changes in body position. Therefore, both <strong>proprioception</strong> (perception of body position) and <strong>kinesthesia</strong> (perception of the body’s movement through space) interact with information provided by the vestibular system.</p>
<p>These sensory systems also gather information from receptors that respond to stretch and tension in muscles, joints, skin, and tendons (Lackner &amp; DiZio, 2005; Proske, 2006; Proske &amp; Gandevia, 2012). Proprioceptive and kinesthetic information travels to the brain via the spinal column. Several cortical regions in addition to the cerebellum receive information from and send information to the sensory organs of the proprioceptive and kinesthetic systems.</p>
<table><caption>Vestibular Sense, Proprioception, and Kinesthesia</caption><tbody><tr><th scope="col">Name</th><th scope="col"><strong>Definition</strong></th><th scope="col"><strong>Application</strong></th></tr><tr><td><strong>Vestibular Sense</strong></td><td>Sensory system that contributes to balance and the sense of spatial orientation.</td><td>You have an ear infection and frequently feel dizzy. Or if you were to experience vertigo, you might feel like your entire body was spinning in space and be unable to walk.</td></tr><tr><td><strong>Proprioception</strong></td><td>The sense of the position of parts of the body, relative to other neighboring parts of the body. Focuses on the body’s <em>cognitive</em>&nbsp;<em>awareness</em> of movement.</td><td>You step off a curb and know where to put your foot. You push an elevator button and control how hard you have to press down with your fingers.</td></tr><tr><td><strong>Kinesthesia</strong></td><td>Awareness of the position and movement of the parts of the body using sensory organs in joints and muscles. Kinesthesia is a key component in muscle memory and hand-eye coordination. It is more <em>behavioral</em> than proprioception.</td><td>You are aware of your arm movement&nbsp;while swinging a golf club. Focuses on the body’s movements and not on equilibrium or balance.</td></tr></tbody></table>
<h3 id="watch-it">Watch It</h3>
<p>Review the things you learned about the senses in the following CrashCourse video.</p>
<p>You can <a href="https://oerfiles.s3-us-west-2.amazonaws.com/Psychology/Transcriptions/HomunculusCrashCoursePsychology6.txt">view the transcript for “Homunculus: Crash Course Psychology #6” here (opens in new window)</a>.</p>
<h3 id="glossary">Glossary</h3>
<p><strong>kinesthesia:</strong> perception of the body’s movement through space</p>
<p><strong>proprioception:</strong> perception of body position</p>
<p><strong>vestibular sense:</strong> contributes to our ability to maintain balance and body posture</p>
<h3 id="candela-citations">Candela Citations</h3>
<p>CC licensed content, Original</p>
<ul>
<li>Modification, adaptation, and original content. <strong>Provided by</strong>: Lumen Learning. <strong>License</strong>: <em><a href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA: Attribution-ShareAlike</a></em></li>
</ul>
<p>CC licensed content, Shared previously</p>
<ul>
<li>The Other Senses. <strong>Authored by</strong>: OpenStax College. <strong>Located at</strong>: <a href="https://openstax.org/books/psychology-2e/pages/5-5-the-other-senses">https://openstax.org/books/psychology-2e/pages/5-5-the-other-senses</a>. <strong>License</strong>: <em><a href="https://creativecommons.org/licenses/by/4.0/">CC BY: Attribution</a></em>. <strong>License Terms</strong>: Download for free at https://openstax.org/books/psychology-2e/pages/1-introduction</li>
<li>Homunculus - Crash Course Psychology #6. <strong>Provided by</strong>: CrashCourse. <strong>Located at</strong>: <a href="https://www.youtube.com/watch?v=fxZWtc0mYpQ">https://www.youtube.com/watch?v=fxZWtc0mYpQ</a>. <strong>License</strong>: <em>Other</em>. <strong>License Terms</strong>: Standard YouTube License</li>
<li>Additional Sensory Systems, information for chart. <strong>Provided by</strong>: Boundless. <strong>Located at</strong>: <a href="https://www.boundless.com/psychology/textbooks/boundless-psychology-textbook/sensation-and-perception-5/sensory-processes-38/additional-sensory-systems-166-12701/">https://www.boundless.com/psychology/textbooks/boundless-psychology-textbook/sensation-and-perception-5/sensory-processes-38/additional-sensory-systems-166-12701/</a>. <strong>Project</strong>: Boundless Psychology. <strong>License</strong>: <em><a href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA: Attribution-ShareAlike</a></em></li>
</ul>
<hr>
<h2 id="touch-and-pain--introduction-to-psychology">Touch and Pain | Introduction to Psychology</h2>
<ul>
<li>url_title:: &quot;Touch and Pain | Introduction to Psychology&quot;
url_source:: https://courses.lumenlearning.com/waymaker-psychology/chapter/reading-touch-and-pain/</li>
</ul>
<h3 id="learning-objectives">Learning Objectives</h3>
<ul>
<li>Explain the receptors that respond to touch</li>
<li>Examine the experience of pain, including how expectations and context affect pain and touch experiences</li>
</ul>
<h2 id="touch-thermoception-and-noiception">Touch, Thermoception, and Noiception</h2>
<p>A number of receptors are distributed throughout the skin to respond to various touch-related stimuli (Figure 1). These receptors include Meissner’s corpuscles, Pacinian corpuscles, Merkel’s disks, and Ruffini corpuscles. <strong>Meissner’s corpuscles</strong> respond to pressure and lower frequency vibrations, and <strong>Pacinian corpuscle</strong>s detect transient pressure and higher frequency vibrations. <strong>Merkel’s disks</strong> respond to light pressure, while <strong>Ruffini corpuscles</strong> detect stretch (Abraira &amp; Ginty, 2013).</p>
<p><img src="https://s3-us-west-2.amazonaws.com/courses-images-archive-read-only/wp-content/uploads/sites/902/2015/02/23224739/CNX_Psych_05_05_Touch.jpg" alt="An illustration shows “skin surface” underneath which different receptors are identified: the “pacinian corpuscle,” “ruffini corpuscle,” “merkel’s disk,” and “meissner’s corpuscle.”"></p>
<p><strong>Figure 1</strong>. There are many types of sensory receptors located in the skin, each attuned to specific touch-related stimuli.</p>
<p>The skin can convey many sensations, such as the biting cold of a wind, the comfortable pressure of a hand holding yours, or the irritating itch from a woolen scarf. The different types of information activate specific receptors that convert the stimulation of the skin to electrical nerve impulses, a process called transduction. There are three main groups of receptors in our skin: <em>mechanoreceptors</em>, responding to mechanical stimuli, such as stroking, stretching, or vibration of the skin; <strong><em>thermoreceptors</em></strong>, responding to cold or hot temperatures; and <em>chemoreceptors</em>, responding to certain types of chemicals either applied externally or released within the skin (such as histamine from an inflammation). For an overview of the different receptor types and their properties, see Table 1.</p>
<p>The experience of <em>pain</em> usually starts with activation of <strong>nociceptors</strong>_—_receptors that fire specifically to potentially tissue-damaging stimuli. Most of the nociceptors are subtypes of either chemoreceptors or mechanoreceptors. When tissue is damaged or inflamed, certain chemical substances are released from the cells, and these substances activate the chemosensitive nociceptors. Mechanoreceptive nociceptors have a high threshold for activation—they respond to mechanical stimulation that is so intense it might damage the tissue. Sensory information collected from the receptors and free nerve endings travels up the spinal cord and is transmitted to regions of the medulla, thalamus, and ultimately to somatosensory cortex, which is located in the postcentral gyrus of the parietal lobe.</p>
<table><caption>Table 1. Categories of low-threshold mechanoreceptors*</caption><tbody><tr><th scope="col"><strong>Identity of receptor</strong></th><th scope="col"><strong>Size of receptor*</strong></th><th scope="col"><strong>Type of skin where found</strong></th><th scope="col"><strong>Speed of adaptation*</strong></th><th scope="col"><strong>Adequate stimulus*</strong></th></tr><tr><td>Merkel’s disks</td><td>small, sharp borders</td><td>glabrous*</td><td>slow</td><td>pressure</td></tr><tr><td>Meissner’s corpusles</td><td>small, sharp borders</td><td>glabrous</td><td>rapid</td><td>indentation</td></tr><tr><td>Ruffini corpuscles</td><td>large, diffuse borders</td><td>hairy + glabrous</td><td>slow</td><td>stretching</td></tr><tr><td>Pacinian corpuscles</td><td>large, diffuse borders</td><td>hairy + glabrous</td><td>rapid</td><td>vibration</td></tr></tbody></table>
<p>*Terms:</p>
<p><strong>Adequate stimulus</strong>-the type of stimulus that the receptor is specialized to receive and respond to.</p>
<p><strong>Glabrous skin</strong>-the hairless skin found on our palms and the soles of our feet. This skin has a higher density of receptors of a more complex range, which reflects the fact that we use these areas of our body to actively explore our surroundings and to discriminate tactile properties of objects we’re interacting with.</p>
<p>**Low-threshold mechanoreceptors-**mechanoreceptors that respond to stimulus that is so light it doesn’t threaten to damage the tissue around it. high-threshold mechanoreceptors respond to stimulation of higher intensity, and are a type of nociceptor.</p>
<p><strong>Receptive field</strong>-the space of skin or tissue in which stimulation will elicit a response in the receptor. Smaller receptive fields make the receptor more sensitive to details.</p>
<p><strong>Speed adaptation</strong>-slowly adapting mechanoreceptors continue to fire action potentials during sustained stimulation. Rapidly adapting mechanoreceptors continue to fire action potentials in response to stimulus onset and offset (i.e. to stimuli changes), and help detect stimulus movement on the skin.</p>
<h2 id="pain-perception">Pain Perception</h2>
<p>Pain is an unpleasant experience that involves both physical and psychological components. Feeling pain is quite adaptive because it makes us aware of an injury, and it motivates us to remove ourselves from the cause of that injury. In addition, pain also makes us less likely to suffer additional injury because we will be gentler with our injured body parts.</p>
<h3 id="life-without-pain">Life Without Pain?</h3>
<p>Imagine a life free of pain. How would it be—calm, fearless, serene? Would you feel invulnerable, invincible? Getting rid of pain is a popular quest—a quick search for “pain-free life” on Google returns well over 4 million hits—including links to various bestselling self-help guides promising a pain-free life in only 7 steps, 6 weeks, or 3 minutes. Pain management is a billion-dollar market, and involves much more than just pharmaceuticals. Surely a life with no pain would be a better one?</p>
<p>Well, consider one of the “lucky few”: 12-year-old “Thomas” has never felt deep pain. Not even when a fracture made him walk around with one leg shorter than the other, so that the bones of his healthy leg were slowly crushed to destruction underneath the knee joint. For Thomas and other members of a large Swedish family, life without pain is a harsh reality because of a mutated gene that affects the growth of the nerves conducting deep pain. Most of those affected suffer from joint damage and frequent fractures to bones in their feet and hands; some end up in wheelchairs even before they reach puberty (Minde et al., 2004). It turns out pain—generally—serves us well.</p>
<p>Living without a sense of touch sounds less attractive than being free of pain—touch is a source of pleasure and essential to how we feel. Losing the sense of touch has severe implications—something patient G. L. experienced when an antibiotics treatment damaged the type of nerves that signal touch from her skin and the position of her joints and muscles. She reported feeling like she’d lost her physical self from her nose down, making her “disembodied”—like she no longer had any connection to the body attached to her head. If she didn’t look at her arms and legs they could just “wander off” without her knowing—initially she was unable to walk, and even after she relearned this skill she was so dependent on her visual attention that closing her eyes would cause her to land in a hopeless heap on the floor. Only light caresses like those from her children’s hands can make her feel she has a body, but even these sensations remain vague and elusive (Olausson et al., 2002; Sacks, 1985).</p>
<p>Generally speaking, pain can be considered to be neuropathic or inflammatory in nature. Pain that signals some type of tissue damage is known as <strong>inflammatory pain</strong>. In some situations, pain results from damage to neurons of either the peripheral or central nervous system. As a result, pain signals that are sent to the brain get exaggerated. This type of pain is known as <strong>neuropathic pain</strong>. Multiple treatment options for pain relief range from relaxation therapy to the use of analgesic medications to deep brain stimulation. The most effective treatment option for a given individual will depend on a number of considerations, including the severity and persistence of the pain and any medical/psychological conditions.</p>
<p>Some individuals are born without the ability to feel pain. This very rare genetic disorder is known as <strong>congenital insensitivity to pain</strong> (or <strong>congenital analgesia</strong>). While those with congenital analgesia can detect differences in temperature and pressure, they cannot experience pain. As a result, they often suffer significant injuries. Young children have serious mouth and tongue injuries because they have bitten themselves repeatedly. Not surprisingly, individuals suffering from this disorder have much shorter life expectancies due to their injuries and secondary infections of injured sites (U.S. National Library of Medicine, 2013).</p>
<h3 id="action-potentials-in-the-receptor-cells-travel-as-nerve-impulses-with-different-speeds">Action Potentials in the Receptor Cells Travel as Nerve Impulses with Different Speeds</h3>
<p>When you step on a pin, this activates a host of mechanoreceptors, many of which are nociceptors. You may have noticed that the sensation changes over time. First you feel a sharp stab that propels you to remove your foot, and only then you feel a wave of more aching pain. The sharp stab is signaled via fast-conducting A-fibers, which project to the somatosensory cortex. This part of the cortex is somatotopically organized—that is, the sensory signals are represented according to where in the body they stem from (see Figure 2). The unpleasant ache you feel after the sharp pin stab is a separate, simultaneous signal sent from the nociceptors in your foot via thin C-pain or Aδ-fibers to the insular cortex and other brain regions involved in the processing of emotion and interoception (see Figure 3 for a schematic representation of this pathway). The experience of stepping on a pin is, in other words, composed by two separate signals: one discriminatory signal allowing us to localize the touch stimulus and distinguish whether it’s a blunt or a sharp stab; and one affective signal that lets us know that stepping on the pin is bad. It is common to divide pain into sensory–discriminatory and affective–motivational aspects (Auvray, Myin, &amp; Spence, 2010). This distinction corresponds, at least partly, to how this information travels from the peripheral to the central nervous system and how it is processed in the brain (Price, 2000).</p>
<p><img src="https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2016/10/09154839/somatosensory.png" alt="Somatosensory map, showing the areas in the sensory cortex that respond with the greatest sensitivity to touch. Hands, faces, and genitals are particularly sensitive."></p>
<p><strong>Figure 2</strong>. The body parts are represented in specific locations on the somatosensory cortex. Representations map out somatotopically, with the feet located medially and shoulders and arms laterally to the interhemispheric fissure. Facial structures are represented in a different location to the scalp and head; the face oriented “upside-down” with the forehead pointing towards the shoulders.</p>
<h2 id="pain-is-necessary-for-survival-but-our-brain-can-stop-it-if-it-needs-to">Pain Is Necessary for Survival, but Our Brain Can Stop It if It Needs To</h2>
<p>In April 2003, the climber Aron Ralston found himself at the floor of Blue John Canyon in Utah, forced to make an appalling choice: face a slow but certain death—or amputate his right arm. Five days earlier he fell down the canyon—since then he had been stuck with his right arm trapped between an 800-lb boulder and the steep sandstone wall. Weak from lack of food and water and close to giving up, it occurred to him like an epiphany that if he broke the two bones in his forearm he could manage to cut off the rest with his pocket knife. The thought of freeing himself and surviving made him so exited he spent the next 40 minutes completely engrossed in the task: first snapping his bones using his body as a lever, then sticking his fingers into the arm, pinching bundles of muscle fibers and severing them one by one, before cutting the blue arteries and the pale “noodle-like” nerves. The pain was unimportant. Only cutting through the thick white main nerve made him stop for a minute—the flood of pain, he describes, was like thrusting his entire arm “into a cauldron of magma.” Finally free, he rappelled down a cliff and walked another 7 miles until he was rescued by some hikers (Ralston, 2010).</p>
<p>How is it possible to do something so excruciatingly painful to yourself, as Aron Ralston did, and still manage to walk, talk, and think rationally afterwards? The answer lies within the brain, where signals from the body are interpreted. When we perceive somatosensory and nociceptive signals from the body, the experience is highly subjective and malleable by motivation, attention, emotion, and context.</p>
<p><img src="http://nobaproject.com/images/shared/images/000/000/213/original.png" alt="Cross sections of the cortex, midbrain, medulla, and spinal cord and the pain processing pathways traveling through them."></p>
<p><strong>Figure 3.</strong> Pain processing pathways. Left – Ascending pain pathways: An injury is signaled simultaneously via fast-conducting Aα or Aβ-fibres and slow-conducting C-pain or Aδ-fibres. The fast A-fibres signal pressure, stretching and other tissue movements to the somatosensory cortex via the dorsal column nuclei. The C-pain and Aδ-fibres sends pain information from nociceptors in the tissue or skin, and transmits these signals to second order neurons in the dorsal horn of the spinal cord. The second order neurons then cross over to the opposite side, where they form the ascending spinothalamic tract. This tract projects signals to nuclei in the medulla and midbrain on the way up to the thalamus (T). The thalamus relays the information to the somatosensory and insular cortex, as well as cortical regions mediating different aspects of the pain experience such as affective responses in the cingulate cortex. Right – Descending pain modulation pathways: Information from the environment and certain motivational states can activate this top–down pathway. Several areas in the limbic forebrain including the anterior cingulate and insular cortex, nuclei in the amygdala and the hypothalamus (H), project to the midbrain periaqueductal grey (PAG), which then modulates ascending pain transmission from the afferent pain system indirectly through the rostral ventromedial medulla (RVM) in the brainstem. This modulating system produces analgesia by the release of endogenous opioids, and uses ON- and OFF-cells to exert either inhibitory (green) or facilitatory (red) control of nociceptive signals at the spinal dorsal horn.</p>
<h2 id="motivation%E2%80%93decision-model-and-descending-modulation-of-pain">Motivation–Decision Model and Descending Modulation of Pain</h2>
<p>According to <em>the motivation–decision model</em>, the brain automatically and continuously evaluates the pros and cons of any situation—weighing impending threats and available rewards (Fields, 2004, 2006). Anything more important for survival than avoiding the pain activates the brain’s descending pain modulatory system—a top-down system involving several parts of the brain and brainstem, which inhibits nociceptive signaling so that the more important actions can be attended to.</p>
<p>In Aron’s extreme case, his actions were likely based on such an unconscious decision process—taking into account his homeostatic state (his hunger, thirst, the inflammation and decay of his crushed hand slowly affecting the rest of his body), the sensory input available (the sweet smell of his dissolving skin, the silence around him indicating his solitude), and his knowledge about the threats facing him (death, or excruciating pain that won’t kill him) versus the potential rewards (survival, seeing his family again). Aron’s story illustrates the evolutionary advantage to being able to shut off pain: The descending pain modulatory system allows us to go through with potentially life-saving actions.</p>
<p>However, when one has reached safety or obtained the reward, healing is more important. The very same descending system can then “crank up” nociception from the body to promote healing and motivate us to avoid potentially painful actions. To facilitate or inhibit nociceptive signals from the body, the descending pain modulatory system uses a set of ON- or OFF-cells in the brainstem, which regulates how much of the nociceptive signal reaches the brain. The descending system is dependent on opioid signaling, and analgesics like morphine relieve pain via this circuit (Petrovic, Kalso, Petersson, &amp; Ingvar, 2002).</p>
<h2 id="analgesic-power-of-reward">Analgesic Power of Reward</h2>
<p>Thinking about the good things, like his loved ones and the life ahead of him, was probably pivotal to Aron’s survival. The promise of a reward can be enough to relieve pain. Expecting pain relief (getting less pain is often the best possible outcome if you’re in pain, i.e., it is a reward) from a medical treatment contributes to the placebo effect—where pain relief is due at least partly to your brain’s descending modulation circuit, and such relief depends on the brain’s own opioid system (Eippert et al., 2009; Eippert, Finsterbusch, Bingel, &amp; Buchel, 2009; Levine, Gordon, &amp; Fields, 1978). Eating tasty food, listening to good music, or feeling pleasant touch on your skin also decreases pain in both animals and humans, presumably through the same mechanism in the brain (Leknes &amp; Tracey, 2008).</p>
<p>In a now classic experiment, Dum and Herz (1984) either fed rats normal rat food or let them feast on highly rewarding chocolate-covered candy (rats love sweets) while standing on a metal plate until they learned exactly what to expect when placed there. When the plate was heated up to a noxious/painful level, the rats that expected candy endured the temperature for twice as long as the rats expecting normal chow. Moreover, this effect was completely abolished when the rats’ opioid (endorphin) system was blocked with a drug, indicating that the analgesic effect of reward anticipation was caused by endorphin release.</p>
<p>For Aron the climber, both the stress from knowing that death was impending and the anticipation of the reward it would be to survive probably flooded his brain with endorphins, contributing to the wave of excitement and euphoria he experienced while he carried out the amputation “like a five-year-old unleashed on his Christmas presents” (Ralston, 2010). This altered his experience of the pain from the extreme tissue damage he was causing and enabled him to focus on freeing himself. Our brain, it turns out, can modulate the perception of how unpleasant pain is, while still retaining the ability to experience the intensity of the sensation (Rainville, Duncan, Price, Carrier, &amp; Bushnell, 1997; Rainville, Feine, Bushnell, &amp; Duncan, 1992). Social rewards, like holding the hand of your boyfriend or girlfriend, have pain-reducing effects. Even looking at a picture of him/her can have similar effects—in fact, seeing a picture of a person we feel close to not only reduces subjective pain ratings, but also the activity in pain-related brain areas (Eisenberger et al., 2011). The most common things to do when wanting to help someone through a painful experience—being present and holding the person’s hand—thus seems to have a measurably positive effect.</p>
<h2 id="power-of-the-mind">Power of the Mind</h2>
<p>The context of pain and touch has a great impact on how we interpret it. Just imagine how different it would feel to Aron if someone amputated his hand against his will and for no discernible reason. Prolonged pain from injuries can be easier to bear if the incident causing them provides a positive context—like a war wound that testifies to a soldier’s courage and commitment—or phantom pain from a hand that was cut off to enable life to carry on.</p>
<p>The relative meaning of pain is illustrated by a recent experiment, where the same moderately painful heat was administered to participants in two different contexts—one control context where the alternative was a non-painful heat; and another where the alternative was an intensely painful heat. In the control context, where the moderate heat was the least preferable outcome, it was (unsurprisingly) rated as painful. In the other context it was the best possible outcome, and here the exact same moderately painful heat was actually rated as <em>pleasant</em>—because it meant the intensely painful heat had been avoided. This somewhat surprising change in perception—where pain becomes pleasant because it represents relief from something worse—highlights the importance of the meaning individuals ascribe to their pain, which can have decisive effects in pain treatment (Leknes et al., 2013). In the case of touch, knowing who or what is stroking your skin can make all the difference—try thinking about slugs the next time someone strokes your skin if you want an illustration of this point.</p>
<p>Pain and pleasure not only share modulatory systems—another common attribute is that we don’t need to be on the receiving end of it ourselves in order to experience it. How did you feel when you read about Aron cutting through his own tissue, or “Thomas” destroying his own bones unknowingly? Did you cringe? It’s quite likely that some of your brain areas processing affective aspects of pain were active even though the nociceptors in your skin and deep tissue were not firing. Pain can be experienced vicariously, as can itch, pleasurable touch, and other sensations. Tania Singer and her colleagues found in an fMRI study that some of the same brain areas that were active when participants felt pain on their own skin (anterior cingulate and insula) were also active when they were given a signal that a loved one was feeling the pain. Those who were most “empathetic” also showed the largest brain responses (Singer et al., 2004). A similar effect has been found for pleasurable touch: The posterior insula of participants watching videos of someone else’s arm being gently stroked shows the same activation as if they were receiving the touch themselves (Morrison, Bjornsdotter, &amp; Olausson, 2011).</p>
<h3 id="glossary">Glossary</h3>
<p><strong>congenital insensitivity to pain (congenital analgesia):</strong> genetic disorder that results in the inability to experience pain</p>
<p><strong>inflammatory pain:</strong> signal that some type of tissue damage has occurred</p>
<p><strong>Meissner’s corpuscle:</strong> touch receptor that responds to pressure and lower frequency vibrations</p>
<p><strong>Merkel’s disk:</strong> touch receptor that responds to light touch</p>
<p><strong>neuropathic pain:</strong> pain from damage to neurons of either the peripheral or central nervous system</p>
<p><strong>nociception:</strong> sensory signal indicating potential harm and maybe pain</p>
<p><strong>Pacinian corpuscle:</strong> touch receptor that detects transient pressure and higher frequency vibrations</p>
<p><strong>Ruffini corpuscle:</strong> touch receptor that detects stretch</p>
<p><strong>vestibular sense:</strong> contributes to our ability to maintain balance and body posture</p>
<h3 id="candela-citations">Candela Citations</h3>
<p>CC licensed content, Original</p>
<ul>
<li>Modification and adaptation, addition of Noba Link to Learning and CrashCourse video. <strong>Provided by</strong>: Lumen Learning. <strong>License</strong>: <em><a href="https://creativecommons.org/licenses/by/4.0/">CC BY: Attribution</a></em></li>
</ul>
<p>CC licensed content, Shared previously</p>
<ul>
<li>The Other Senses. <strong>Authored by</strong>: OpenStax College. <strong>Located at</strong>: <a href="https://openstax.org/books/psychology-2e/pages/5-5-the-other-senses">https://openstax.org/books/psychology-2e/pages/5-5-the-other-senses</a>. <strong>License</strong>: <em><a href="https://creativecommons.org/licenses/by/4.0/">CC BY: Attribution</a></em>. <strong>License Terms</strong>: Download for free at https://openstax.org/books/psychology-2e/pages/1-introduction</li>
<li>Touch and Pain, information on mechanoreceptors through the power of the mind. <strong>Authored by</strong>: Guro E. Loseth, Dan-Mikael Ellingson, and Siri Leknes . <strong>Provided by</strong>: University of Oslo, University of Gothenburg. <strong>Located at</strong>: <a href="http://nobaproject.com/modules/touch-and-pain">http://nobaproject.com/modules/touch-and-pain</a>. <strong>Project</strong>: The Noba Project. <strong>License</strong>: <em><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA: Attribution-NonCommercial-ShareAlike</a></em></li>
</ul>
<hr>
<h2 id="putting-it-together-sensation-and-perception">Putting It Together: Sensation and Perception</h2>
<ul>
<li>url_title:: &quot;Putting It Together: Sensation and Perception&quot;
url_source:: https://courses.lumenlearning.com/waymaker-psychology/chapter/putting-it-together-sensation-and-perception/</li>
</ul>
<h3 id="learning-objectives">Learning Objectives</h3>
<p>In this module, you learned to</p>
<ul>
<li>differentiate between sensation and perception</li>
<li>explain the process of vision and how people see color and depth</li>
<li>explain the basics of hearing</li>
<li>describe the basic anatomy and functions of taste, smell, touch, pain, and the vestibular sense</li>
<li>define perception and give examples of gestalt principles and multimodal perception</li>
</ul>
<p>In this module, you learned about the way our senses work and the impact they have on our perception of the world. Our impressive sensory abilities allow us to experience the most enjoyable and most miserable experiences, as well as everything in between. Our eyes, ears, nose, tongue and skin provide an interface for the brain to interact with the world around us. While there is simplicity in covering each sensory modality independently, we are organisms that have evolved the ability to process multiple modalities as a unified experience.</p>
<p>While the information covered in this module may initially seem straightforward and stagnant, you saw in the example from Jessica Witt’s research on perception that a person’s perception of the size of a golf hole can impact their performance. The ways that perception can alter our behavior and the impact this has on mental processes is of particular interest to psychologists.</p>
<p><a href="https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2016/11/26142949/Google-Cardboard.jpg"><img src="https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2016/11/26142949/Google-Cardboard.jpg" alt="Photograph of a Google Cardboard viewer, a small cardboard box with two eye holes and lens that let the viewer look inside of the box to see their smartphone."></a></p>
<p><strong>Figure 1</strong>. Google Cardboard.</p>
<p>One current area of interest is the influence of psychological principles on virtual reality design. Think about it. How can designers create a 3-dimensional world on a 2-dimensional plane? They must first consider the way that we interpret visual cues and how we see depth. Consider <a href="https://vr.google.com/cardboard/">Google Cardboard</a>. In 2014, two Google engineers created a cardboard viewer lens that allows users to place their smartphones inside and view the world as if they entered a virtual reality. This was a huge leap forward in reducing the cost of and increasing access to virtual reality. But how did they do it? In order to feel like you are immersed in the gaming world, you need to remove the distractions that exist outside of the immediate visual field. Hence, the box around the phone. You also need to feel like you are inside of the world, so the box includes lenses that adjust your focal point and magnify the picture on the screen (Figure 1).</p>
<p>You also need the world to be 3-dimensional. As you learned, your eyes rely on several monocular and binocular cues in order to see depth. Binocular disparity describes the slightly unique view of the world we see from each of our two eyes (which explains why if you hold an object near your face and close one eye, then open it and close the other, that object appears to move). To create this effect, developers put a barrier between the left and right visual fields and split the screen in two, so that the image on the screen is slightly different. The picture on your phone shows up like this:</p>
<p><a href="https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2016/11/26144856/16905172090_360p.mp4">https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2016/11/26144856/16905172090_360p.mp4</a></p>
<p><a href="https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2016/11/26150327/768px-Pincushion_distortion.svg_.png"><img src="https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2016/11/26150327/768px-Pincushion_distortion.svg_.png" alt="An image of gridlines show the grid get more stretched toward the corners."></a></p>
<p><strong>Figure 2</strong>. Pincushion distortion.</p>
<p>Because you are viewing the image through magnified lenses, there is a distortion called the pincushion distortion, which stretches the image in the corners of the view. To counteract that and make the work appear normal, developers apply a barrel distortion to the viewer, which explains why you see the image in the video with the pinched corners.</p>
<p><img src="https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/855/2016/11/26150553/768px-Barrel_distortion.svg_.png" alt="Image of gridlines show a bulging center and pinched corners."></p>
<p><strong>Figure 3</strong>. Barrel distortion.</p>
<p>Advances in virtual reality are also important to psychology because virtual reality is a treatment method used to help those with psychological disorders. Consider PTSD or phobias, for example. In a virtual world, a counselor can create situations and experiences designed to recreate the triggers for specific behaviors and assist the client in using coping mechanisms to deal with threatening situations. Virtual reality therapy can be used in numerous ways as a type of exposure therapy, even assisting people with autism as they practice recognizing and interpreting social cues or helping those with depression to make choices to help them prevent negative thoughts.</p>
<h3 id="candela-citations">Candela Citations</h3>
<p>CC licensed content, Original</p>
<ul>
<li>Putting It Together: Sensation and Perception. <strong>Provided by</strong>: Lumen Learning. <strong>License</strong>: <em><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA: Attribution-NonCommercial-ShareAlike</a></em></li>
</ul>
<p>CC licensed content, Shared previously</p>
<ul>
<li>Google Cardboard VR with Camera Viewer. <strong>Authored by</strong>: sndrv. <strong>Provided by</strong>: Flickr. <strong>Located at</strong>: <a href="https://www.flickr.com/photos/sndrv/16905172090">https://www.flickr.com/photos/sndrv/16905172090</a>. <strong>License</strong>: <em><a href="https://creativecommons.org/licenses/by/4.0/">CC BY: Attribution</a></em></li>
<li>Distortion images. <strong>Authored by</strong>: WolfWings. <strong>Provided by</strong>: Wikimedia. <strong>Located at</strong>: <a href="https://en.wikipedia.org/wiki/Distortion_(optics)">https://en.wikipedia.org/wiki/Distortion_(optics)</a>. <strong>License</strong>: <em><a href="https://creativecommons.org/about/pdm">Public Domain: No Known Copyright</a></em></li>
<li>Google Cardboard. <strong>Provided by</strong>: Wikipedia. <strong>Located at</strong>: <a href="https://en.wikipedia.org/wiki/Google_Cardboard">https://en.wikipedia.org/wiki/Google_Cardboard</a>. <strong>License</strong>: <em><a href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA: Attribution-ShareAlike</a></em></li>
<li>Introductory Paragraph. <strong>Authored by</strong>: Adam John Privitera . <strong>Provided by</strong>: Chemeketa Community College. <strong>Located at</strong>: <a href="http://nobaproject.com/modules/sensation-and-perception">http://nobaproject.com/modules/sensation-and-perception</a>. <strong>Project</strong>: The Noba Project. <strong>License</strong>: <em><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA: Attribution-NonCommercial-ShareAlike</a></em></li>
</ul>
<p>Public domain content</p>
<ul>
<li>Google Cardboard image. <strong>Authored by</strong>: Evan Amos. <strong>Located at</strong>: <a href="https://en.wikipedia.org/wiki/Google_Cardboard#/media/File:Google-Cardboard.jpg">https://en.wikipedia.org/wiki/Google_Cardboard#/media/File:Google-Cardboard.jpg</a>. <strong>License</strong>: <em><a href="https://creativecommons.org/about/pdm">Public Domain: No Known Copyright</a></em></li>
</ul>
<hr>
<h2 id="discussion-sensation-and-perception--introduction-to-psychology">Discussion: Sensation and Perception | Introduction to Psychology</h2>
<ul>
<li>url_title:: &quot;Discussion: Sensation and Perception | Introduction to Psychology&quot;
url_source:: https://courses.lumenlearning.com/waymaker-psychology/chapter/discussion-sensation-and-perception/
<strong>Step 1:</strong> To view this discussion prompt, click on <a href="https://courses.lumenlearning.com/waymaker-psychology/chapter/discussion-sensation-and-perception-2/">Discussion: Sensation and Perception.</a></li>
</ul>
<p><strong>Step 2:</strong> Read the prompt and instructions, then post your response and comments inside of the discussion forum.</p>
<h3 id="candela-citations">Candela Citations</h3>
<p>CC licensed content, Original</p>
<ul>
<li>Discussion: Sensation and Perception. <strong>Provided by</strong>: Lumen Learning. <strong>License</strong>: <em><a href="https://creativecommons.org/licenses/by/4.0/">CC BY: Attribution</a></em></li>
</ul>
<p>CC licensed content, Shared previously</p>
<ul>
<li>Discussion idea. <strong>Authored by</strong>: Terry Davis . <strong>Provided by</strong>: Wiley College. <strong>License</strong>: <em><a href="https://creativecommons.org/licenses/by/4.0/">CC BY: Attribution</a></em></li>
</ul>
<hr>

</body>
</html>
